# id;timestamp;commentText;codeText;commentWords;codeWords
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1488276808;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1488305808;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1489164945;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1490628047;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1491385557;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1493401220;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1495464939;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1496173247;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1498211968;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1498493279;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1501592283;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1503588494;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1506689437;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1507293223;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1508093641;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1508494390;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1508945414;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1509045960;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1509287653;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1511291153;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1518245533;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1522154703;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1527089094;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1529585865;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1529586951;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1531820069;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1539371200;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1540216840;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1542192035;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1542279564;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay);1550075375;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,return,env,get,stream,graph,get,job,graph
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1448992027;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			final ApplicationID expectedAppId = savepoint.getApplicationId()__			final CompletedCheckpoint expectedCheckpoint = savepoint.getCompletedCheckpoint()___			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			errMsg = "Application ID mismatch after redeployment."__			for (TaskDeploymentDescriptor tdd : tdds.values()) {_				assertEquals(errMsg, expectedAppId, tdd.getApplicationID())__			}__			_			_			for (StateForTask stateForTask : expectedCheckpoint.getStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(_						stateForTask.getOperatorId())___				errMsg = "Missing task for savepoint state for operator "_						+ stateForTask.getOperatorId() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				boolean success = false__				for (TaskDeploymentDescriptor tdd : taskTdds) {_					if (tdd.getIndexInSubtaskGroup() == stateForTask.getSubtask()) {_						success = true___						errMsg = "Initial operator state mismatch."__						assertEquals(errMsg, stateForTask.getState(), tdd.getOperatorState())__					}_				}__				errMsg = "No matching task deployment descriptor found."__				assertTrue(errMsg, success)__			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (StateForTask stateForTask : expectedCheckpoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileState fsState = (AbstractFileState) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,final,application,id,expected,app,id,savepoint,get,application,id,final,completed,checkpoint,expected,checkpoint,savepoint,get,completed,checkpoint,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,err,msg,application,id,mismatch,after,redeployment,for,task,deployment,descriptor,tdd,tdds,values,assert,equals,err,msg,expected,app,id,tdd,get,application,id,for,state,for,task,state,for,task,expected,checkpoint,get,states,collection,task,deployment,descriptor,task,tdds,tdds,get,state,for,task,get,operator,id,err,msg,missing,task,for,savepoint,state,for,operator,state,for,task,get,operator,id,assert,true,err,msg,task,tdds,size,0,boolean,success,false,for,task,deployment,descriptor,tdd,task,tdds,if,tdd,get,index,in,subtask,group,state,for,task,get,subtask,success,true,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,state,for,task,get,state,tdd,get,operator,state,err,msg,no,matching,task,deployment,descriptor,found,assert,true,err,msg,success,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,state,for,task,state,for,task,expected,checkpoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,fs,state,abstract,file,state,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1450188912;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			final ApplicationID expectedAppId = savepoint.getApplicationId()__			final CompletedCheckpoint expectedCheckpoint = savepoint.getCompletedCheckpoint()___			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			errMsg = "Application ID mismatch after redeployment."__			for (TaskDeploymentDescriptor tdd : tdds.values()) {_				assertEquals(errMsg, expectedAppId, tdd.getApplicationID())__			}__			_			_			for (StateForTask stateForTask : expectedCheckpoint.getStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(_						stateForTask.getOperatorId())___				errMsg = "Missing task for savepoint state for operator "_						+ stateForTask.getOperatorId() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				boolean success = false__				for (TaskDeploymentDescriptor tdd : taskTdds) {_					if (tdd.getIndexInSubtaskGroup() == stateForTask.getSubtask()) {_						success = true___						errMsg = "Initial operator state mismatch."__						assertEquals(errMsg, stateForTask.getState(), tdd.getOperatorState())__					}_				}__				errMsg = "No matching task deployment descriptor found."__				assertTrue(errMsg, success)__			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (StateForTask stateForTask : expectedCheckpoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileState fsState = (AbstractFileState) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,final,application,id,expected,app,id,savepoint,get,application,id,final,completed,checkpoint,expected,checkpoint,savepoint,get,completed,checkpoint,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,err,msg,application,id,mismatch,after,redeployment,for,task,deployment,descriptor,tdd,tdds,values,assert,equals,err,msg,expected,app,id,tdd,get,application,id,for,state,for,task,state,for,task,expected,checkpoint,get,states,collection,task,deployment,descriptor,task,tdds,tdds,get,state,for,task,get,operator,id,err,msg,missing,task,for,savepoint,state,for,operator,state,for,task,get,operator,id,assert,true,err,msg,task,tdds,size,0,boolean,success,false,for,task,deployment,descriptor,tdd,task,tdds,if,tdd,get,index,in,subtask,group,state,for,task,get,subtask,success,true,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,state,for,task,get,state,tdd,get,operator,state,err,msg,no,matching,task,deployment,descriptor,found,assert,true,err,msg,success,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,state,for,task,state,for,task,expected,checkpoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,fs,state,abstract,file,state,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1450356550;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			final ApplicationID expectedAppId = savepoint.getApplicationId()__			final CompletedCheckpoint expectedCheckpoint = savepoint.getCompletedCheckpoint()___			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			errMsg = "Application ID mismatch after redeployment."__			for (TaskDeploymentDescriptor tdd : tdds.values()) {_				assertEquals(errMsg, expectedAppId, tdd.getApplicationID())__			}__			_			_			for (StateForTask stateForTask : expectedCheckpoint.getStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(_						stateForTask.getOperatorId())___				errMsg = "Missing task for savepoint state for operator "_						+ stateForTask.getOperatorId() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				boolean success = false__				for (TaskDeploymentDescriptor tdd : taskTdds) {_					if (tdd.getIndexInSubtaskGroup() == stateForTask.getSubtask()) {_						success = true___						errMsg = "Initial operator state mismatch."__						assertEquals(errMsg, stateForTask.getState(), tdd.getOperatorState())__					}_				}__				errMsg = "No matching task deployment descriptor found."__				assertTrue(errMsg, success)__			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (StateForTask stateForTask : expectedCheckpoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,final,application,id,expected,app,id,savepoint,get,application,id,final,completed,checkpoint,expected,checkpoint,savepoint,get,completed,checkpoint,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,err,msg,application,id,mismatch,after,redeployment,for,task,deployment,descriptor,tdd,tdds,values,assert,equals,err,msg,expected,app,id,tdd,get,application,id,for,state,for,task,state,for,task,expected,checkpoint,get,states,collection,task,deployment,descriptor,task,tdds,tdds,get,state,for,task,get,operator,id,err,msg,missing,task,for,savepoint,state,for,operator,state,for,task,get,operator,id,assert,true,err,msg,task,tdds,size,0,boolean,success,false,for,task,deployment,descriptor,tdd,task,tdds,if,tdd,get,index,in,subtask,group,state,for,task,get,subtask,success,true,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,state,for,task,get,state,tdd,get,operator,state,err,msg,no,matching,task,deployment,descriptor,found,assert,true,err,msg,success,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,state,for,task,state,for,task,expected,checkpoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1453721631;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			final ApplicationID expectedAppId = savepoint.getApplicationId()__			final CompletedCheckpoint expectedCheckpoint = savepoint.getCompletedCheckpoint()___			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			errMsg = "Application ID mismatch after redeployment."__			for (TaskDeploymentDescriptor tdd : tdds.values()) {_				assertEquals(errMsg, expectedAppId, tdd.getApplicationID())__			}__			_			_			for (StateForTask stateForTask : expectedCheckpoint.getStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(_						stateForTask.getOperatorId())___				errMsg = "Missing task for savepoint state for operator "_						+ stateForTask.getOperatorId() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				boolean success = false__				for (TaskDeploymentDescriptor tdd : taskTdds) {_					if (tdd.getIndexInSubtaskGroup() == stateForTask.getSubtask()) {_						success = true___						errMsg = "Initial operator state mismatch."__						assertEquals(errMsg, stateForTask.getState(), tdd.getOperatorState())__					}_				}__				errMsg = "No matching task deployment descriptor found."__				assertTrue(errMsg, success)__			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (StateForTask stateForTask : expectedCheckpoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,final,application,id,expected,app,id,savepoint,get,application,id,final,completed,checkpoint,expected,checkpoint,savepoint,get,completed,checkpoint,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,err,msg,application,id,mismatch,after,redeployment,for,task,deployment,descriptor,tdd,tdds,values,assert,equals,err,msg,expected,app,id,tdd,get,application,id,for,state,for,task,state,for,task,expected,checkpoint,get,states,collection,task,deployment,descriptor,task,tdds,tdds,get,state,for,task,get,operator,id,err,msg,missing,task,for,savepoint,state,for,operator,state,for,task,get,operator,id,assert,true,err,msg,task,tdds,size,0,boolean,success,false,for,task,deployment,descriptor,tdd,task,tdds,if,tdd,get,index,in,subtask,group,state,for,task,get,subtask,success,true,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,state,for,task,get,state,tdd,get,operator,state,err,msg,no,matching,task,deployment,descriptor,found,assert,true,err,msg,success,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,state,for,task,state,for,task,expected,checkpoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1455203048;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (StateForTask stateForTask : savepoint.getStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(_						stateForTask.getOperatorId())___				errMsg = "Missing task for savepoint state for operator "_						+ stateForTask.getOperatorId() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				boolean success = false__				for (TaskDeploymentDescriptor tdd : taskTdds) {_					if (tdd.getIndexInSubtaskGroup() == stateForTask.getSubtask()) {_						success = true___						errMsg = "Initial operator state mismatch."__						assertEquals(errMsg, stateForTask.getState(), tdd.getOperatorState())__					}_				}__				errMsg = "No matching task deployment descriptor found."__				assertTrue(errMsg, success)__			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (StateForTask stateForTask : savepoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,state,for,task,state,for,task,savepoint,get,states,collection,task,deployment,descriptor,task,tdds,tdds,get,state,for,task,get,operator,id,err,msg,missing,task,for,savepoint,state,for,operator,state,for,task,get,operator,id,assert,true,err,msg,task,tdds,size,0,boolean,success,false,for,task,deployment,descriptor,tdd,task,tdds,if,tdd,get,index,in,subtask,group,state,for,task,get,subtask,success,true,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,state,for,task,get,state,tdd,get,operator,state,err,msg,no,matching,task,deployment,descriptor,found,assert,true,err,msg,success,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,state,for,task,state,for,task,savepoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1455203606;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			final ApplicationID expectedAppId = savepoint.getApplicationId()__			final CompletedCheckpoint expectedCheckpoint = savepoint.getCompletedCheckpoint()___			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			errMsg = "Application ID mismatch after redeployment."__			for (TaskDeploymentDescriptor tdd : tdds.values()) {_				assertEquals(errMsg, expectedAppId, tdd.getApplicationID())__			}__			_			_			for (StateForTask stateForTask : expectedCheckpoint.getStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(_						stateForTask.getOperatorId())___				errMsg = "Missing task for savepoint state for operator "_						+ stateForTask.getOperatorId() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				boolean success = false__				for (TaskDeploymentDescriptor tdd : taskTdds) {_					if (tdd.getIndexInSubtaskGroup() == stateForTask.getSubtask()) {_						success = true___						errMsg = "Initial operator state mismatch."__						assertEquals(errMsg, stateForTask.getState(), tdd.getOperatorState())__					}_				}__				errMsg = "No matching task deployment descriptor found."__				assertTrue(errMsg, success)__			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (StateForTask stateForTask : expectedCheckpoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,final,application,id,expected,app,id,savepoint,get,application,id,final,completed,checkpoint,expected,checkpoint,savepoint,get,completed,checkpoint,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,err,msg,application,id,mismatch,after,redeployment,for,task,deployment,descriptor,tdd,tdds,values,assert,equals,err,msg,expected,app,id,tdd,get,application,id,for,state,for,task,state,for,task,expected,checkpoint,get,states,collection,task,deployment,descriptor,task,tdds,tdds,get,state,for,task,get,operator,id,err,msg,missing,task,for,savepoint,state,for,operator,state,for,task,get,operator,id,assert,true,err,msg,task,tdds,size,0,boolean,success,false,for,task,deployment,descriptor,tdd,task,tdds,if,tdd,get,index,in,subtask,group,state,for,task,get,subtask,success,true,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,state,for,task,get,state,tdd,get,operator,state,err,msg,no,matching,task,deployment,descriptor,found,assert,true,err,msg,success,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,state,for,task,state,for,task,expected,checkpoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1455311369;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (StateForTask stateForTask : savepoint.getStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(_						stateForTask.getOperatorId())___				errMsg = "Missing task for savepoint state for operator "_						+ stateForTask.getOperatorId() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				boolean success = false__				for (TaskDeploymentDescriptor tdd : taskTdds) {_					if (tdd.getIndexInSubtaskGroup() == stateForTask.getSubtask()) {_						success = true___						errMsg = "Initial operator state mismatch."__						assertEquals(errMsg, stateForTask.getState(), tdd.getOperatorState())__					}_				}__				errMsg = "No matching task deployment descriptor found."__				assertTrue(errMsg, success)__			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (StateForTask stateForTask : savepoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,state,for,task,state,for,task,savepoint,get,states,collection,task,deployment,descriptor,task,tdds,tdds,get,state,for,task,get,operator,id,err,msg,missing,task,for,savepoint,state,for,operator,state,for,task,get,operator,id,assert,true,err,msg,task,tdds,size,0,boolean,success,false,for,task,deployment,descriptor,tdd,task,tdds,if,tdd,get,index,in,subtask,group,state,for,task,get,subtask,success,true,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,state,for,task,get,state,tdd,get,operator,state,err,msg,no,matching,task,deployment,descriptor,found,assert,true,err,msg,success,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,state,for,task,state,for,task,savepoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1456487167;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (StateForTask stateForTask : savepoint.getStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(_						stateForTask.getOperatorId())___				errMsg = "Missing task for savepoint state for operator "_						+ stateForTask.getOperatorId() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				boolean success = false__				for (TaskDeploymentDescriptor tdd : taskTdds) {_					if (tdd.getIndexInSubtaskGroup() == stateForTask.getSubtask()) {_						success = true___						errMsg = "Initial operator state mismatch."__						assertEquals(errMsg, stateForTask.getState(), tdd.getOperatorState())__					}_				}__				errMsg = "No matching task deployment descriptor found."__				assertTrue(errMsg, success)__			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (StateForTask stateForTask : savepoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,state,for,task,state,for,task,savepoint,get,states,collection,task,deployment,descriptor,task,tdds,tdds,get,state,for,task,get,operator,id,err,msg,missing,task,for,savepoint,state,for,operator,state,for,task,get,operator,id,assert,true,err,msg,task,tdds,size,0,boolean,success,false,for,task,deployment,descriptor,tdd,task,tdds,if,tdd,get,index,in,subtask,group,state,for,task,get,subtask,success,true,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,state,for,task,get,state,tdd,get,operator,state,err,msg,no,matching,task,deployment,descriptor,found,assert,true,err,msg,success,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,state,for,task,state,for,task,savepoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1457706031;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (StateForTask stateForTask : savepoint.getStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(_						stateForTask.getOperatorId())___				errMsg = "Missing task for savepoint state for operator "_						+ stateForTask.getOperatorId() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				boolean success = false__				for (TaskDeploymentDescriptor tdd : taskTdds) {_					if (tdd.getIndexInSubtaskGroup() == stateForTask.getSubtask()) {_						success = true___						errMsg = "Initial operator state mismatch."__						assertEquals(errMsg, stateForTask.getState(), tdd.getOperatorState())__					}_				}__				errMsg = "No matching task deployment descriptor found."__				assertTrue(errMsg, success)__			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (StateForTask stateForTask : savepoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,state,for,task,state,for,task,savepoint,get,states,collection,task,deployment,descriptor,task,tdds,tdds,get,state,for,task,get,operator,id,err,msg,missing,task,for,savepoint,state,for,operator,state,for,task,get,operator,id,assert,true,err,msg,task,tdds,size,0,boolean,success,false,for,task,deployment,descriptor,tdd,task,tdds,if,tdd,get,index,in,subtask,group,state,for,task,get,subtask,success,true,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,state,for,task,get,state,tdd,get,operator,state,err,msg,no,matching,task,deployment,descriptor,found,assert,true,err,msg,success,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,state,for,task,state,for,task,savepoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1459778142;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (StateForTask stateForTask : savepoint.getStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(_						stateForTask.getOperatorId())___				errMsg = "Missing task for savepoint state for operator "_						+ stateForTask.getOperatorId() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				boolean success = false__				for (TaskDeploymentDescriptor tdd : taskTdds) {_					if (tdd.getIndexInSubtaskGroup() == stateForTask.getSubtask()) {_						success = true___						errMsg = "Initial operator state mismatch."__						assertEquals(errMsg, stateForTask.getState(), tdd.getOperatorState())__					}_				}__				errMsg = "No matching task deployment descriptor found."__				assertTrue(errMsg, success)__			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (StateForTask stateForTask : savepoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,state,for,task,state,for,task,savepoint,get,states,collection,task,deployment,descriptor,task,tdds,tdds,get,state,for,task,get,operator,id,err,msg,missing,task,for,savepoint,state,for,operator,state,for,task,get,operator,id,assert,true,err,msg,task,tdds,size,0,boolean,success,false,for,task,deployment,descriptor,tdd,task,tdds,if,tdd,get,index,in,subtask,group,state,for,task,get,subtask,success,true,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,state,for,task,get,state,tdd,get,operator,state,err,msg,no,matching,task,deployment,descriptor,found,assert,true,err,msg,success,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,state,for,task,state,for,task,savepoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1460121606;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (Map.Entry<JobVertexID, TaskState> entry: savepoint.getTaskStates().entrySet()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(entry.getKey())__				TaskState taskState = entry.getValue()___				errMsg = "Missing task for savepoint state for operator "_					+ entry.getKey() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getState(), tdd.getOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates().values()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamTaskStateList taskStateList = (StreamTaskStateList) subtaskState.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___					for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__						AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__						checkpointFiles.add(new File(fsState.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,map,entry,job,vertex,id,task,state,entry,savepoint,get,task,states,entry,set,collection,task,deployment,descriptor,task,tdds,tdds,get,entry,get,key,task,state,task,state,entry,get,value,err,msg,missing,task,for,savepoint,state,for,operator,entry,get,key,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,state,tdd,get,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,values,for,subtask,state,subtask,state,state,for,task,group,get,states,stream,task,state,list,task,state,list,stream,task,state,list,subtask,state,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1465376364;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (Map.Entry<JobVertexID, TaskState> entry: savepoint.getTaskStates().entrySet()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(entry.getKey())__				TaskState taskState = entry.getValue()___				errMsg = "Missing task for savepoint state for operator "_					+ entry.getKey() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getState(), tdd.getOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath, Option.<List<BlobKey>>empty()),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates().values()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamTaskStateList taskStateList = (StreamTaskStateList) subtaskState.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___					for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__						AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__						checkpointFiles.add(new File(fsState.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,map,entry,job,vertex,id,task,state,entry,savepoint,get,task,states,entry,set,collection,task,deployment,descriptor,task,tdds,tdds,get,entry,get,key,task,state,task,state,entry,get,value,err,msg,missing,task,for,savepoint,state,for,operator,entry,get,key,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,state,tdd,get,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,option,list,blob,key,empty,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,values,for,subtask,state,subtask,state,state,for,task,group,get,states,stream,task,state,list,task,state,list,stream,task,state,list,subtask,state,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1466083944;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (Map.Entry<JobVertexID, TaskState> entry: savepoint.getTaskStates().entrySet()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(entry.getKey())__				TaskState taskState = entry.getValue()___				errMsg = "Missing task for savepoint state for operator "_					+ entry.getKey() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getState(), tdd.getOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates().values()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamTaskStateList taskStateList = (StreamTaskStateList) subtaskState.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___					for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__						AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__						checkpointFiles.add(new File(fsState.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertNull(errMsg, savepointDir.listFiles())___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,map,entry,job,vertex,id,task,state,entry,savepoint,get,task,states,entry,set,collection,task,deployment,descriptor,task,tdds,tdds,get,entry,get,key,task,state,task,state,entry,get,value,err,msg,missing,task,for,savepoint,state,for,operator,entry,get,key,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,state,tdd,get,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,values,for,subtask,state,subtask,state,state,for,task,group,get,states,stream,task,state,list,task,state,list,stream,task,state,list,subtask,state,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,null,err,msg,savepoint,dir,list,files,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1467296201;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV0 savepoint = (SavepointV0) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getState(), tdd.getOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath, Option.<List<BlobKey>>empty()),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamTaskStateList taskStateList = (StreamTaskStateList) subtaskState.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___					for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__						AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__						checkpointFiles.add(new File(fsState.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v0,savepoint,savepoint,v0,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,state,tdd,get,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,option,list,blob,key,empty,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,stream,task,state,list,task,state,list,stream,task,state,list,subtask,state,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1470909547;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getChainedStateHandle(), tdd.getOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getChainedStateHandle()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,chained,state,handle,tdd,get,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,chained,state,handle,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1470937207;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV0 savepoint = (SavepointV0) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final ForkableFlinkMiniCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getState(), tdd.getOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath, Option.<List<BlobKey>>empty()),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamTaskStateList taskStateList = (StreamTaskStateList) subtaskState.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___					for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__						AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__						checkpointFiles.add(new File(fsState.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v0,savepoint,savepoint,v0,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,forkable,flink,mini,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,state,tdd,get,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,option,list,blob,key,empty,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,stream,task,state,list,task,state,list,stream,task,state,list,subtask,state,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1472659089;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			File[] files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getChainedStateHandle(), tdd.getOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getChainedStateHandle()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,filesystem,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,file,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,chained,state,handle,tdd,get,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,chained,state,handle,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1473856047;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getChainedStateHandle(), tdd.getOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getChainedStateHandle()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,chained,state,handle,tdd,get,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,chained,state,handle,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1474899711;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_							tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1475571578;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_							tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1475765022;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getChainedStateHandle(), tdd.getOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getChainedStateHandle()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,chained,state,handle,tdd,get,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,chained,state,handle,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1475833727;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointPath(savepointPath)___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getChainedStateHandle(), tdd.getOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getChainedStateHandle()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,chained,state,handle,tdd,get,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,chained,state,handle,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1477497926;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)__					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_							tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,string,err,msg,checkpoints,directory,not,cleaned,up,properly,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1478686523;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								tdds.put(tdd.getVertexID(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getIndexInSubtaskGroup())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_							tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,string,err,msg,checkpoints,directory,not,cleaned,up,properly,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,tdds,put,tdd,get,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,index,in,subtask,group,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1478715096;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint, and_verify that the initial state has been reset</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			String errMsg = "Checkpoints directory not cleaned up properly."__			files = checkpointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			_			errMsg = "Savepoints directory cleaned up."__			files = savepointDir.listFiles()__			if (files != null) {_				assertEquals(errMsg, 1, files.length)__			}_			else {_				fail(errMsg)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_										.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_									"savepoint path " + savepointPath + " in detached mode.")___							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_									"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_										expectMsgAnyClassOf(getRemainingTime(),_												ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						}_						catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_						+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_							tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(_					new DisposeSavepoint(savepointPath),_					deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() ==_					getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_					Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,and,verify,that,the,initial,state,has,been,reset,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,string,err,msg,checkpoints,directory,not,cleaned,up,properly,files,checkpoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,err,msg,savepoints,directory,cleaned,up,files,savepoint,dir,list,files,if,files,null,assert,equals,err,msg,1,files,length,else,fail,err,msg,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1479839013;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 2__		final int checkpointingInterval = 100___		_		final File tmpDir = folder.newFolder()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_				checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_				savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			flink.start()___			_			ActorGateway jobManager = Await.result(_				flink.leaderGateway().future(),_				deadline.timeLeft())___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, checkpointingInterval)__			final JobID jobId = jobGraph.getJobID()___			_			_			StatefulCounter.resetForTest()___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints + " checkpoint complete notifications.")___			_			StatefulCounter.awaitCompletedCheckpoints(parallelism, numberOfCompletedCheckpoints, deadline.timeLeft().toMillis())___			LOG.info("Received all " + numberOfCompletedCheckpoints +_				" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_				new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_				.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_				savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			_			files = checkpointDir.listFiles()__			assertNotNull("Checkpoint directory empty", files)__			assertEquals("Checkpoints directory cleaned up, but needed for savepoint.", 1, files.length)__			assertEquals("No job-specific base directory", jobGraph.getJobID().toString(), files[0].getName())___			_			files = savepointDir.listFiles()__			assertNotNull("Savepoint directory empty", files)__			assertEquals("No savepoint found in savepoint directory", 1, files.length)___			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest()___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_					+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			_			StatefulCounter.awaitStateRestoredFromCheckpoint(deadline.timeLeft().toMillis())___			_			StatefulCounter.awaitCompletedCheckpoints(parallelism, numberOfCompletedCheckpoints, deadline.timeLeft().toMillis())___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,2,final,int,checkpointing,interval,100,final,file,tmp,dir,folder,new,folder,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,flink,start,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,checkpointing,interval,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,stateful,counter,await,completed,checkpoints,parallelism,number,of,completed,checkpoints,deadline,time,left,to,millis,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,files,checkpoint,dir,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,cleaned,up,but,needed,for,savepoint,1,files,length,assert,equals,no,job,specific,base,directory,job,graph,get,job,id,to,string,files,0,get,name,files,savepoint,dir,list,files,assert,not,null,savepoint,directory,empty,files,assert,equals,no,savepoint,found,in,savepoint,directory,1,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,string,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,stateful,counter,await,state,restored,from,checkpoint,deadline,time,left,to,millis,stateful,counter,await,completed,checkpoints,parallelism,number,of,completed,checkpoints,deadline,time,left,to,millis,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1480933339;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 2__		final int checkpointingInterval = 100___		_		final File tmpDir = folder.newFolder()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_				checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_				savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			flink.start()___			_			ActorGateway jobManager = Await.result(_				flink.leaderGateway().future(),_				deadline.timeLeft())___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, checkpointingInterval)__			final JobID jobId = jobGraph.getJobID()___			_			_			StatefulCounter.resetForTest()___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints + " checkpoint complete notifications.")___			_			StatefulCounter.awaitCompletedCheckpoints(parallelism, numberOfCompletedCheckpoints, deadline.timeLeft().toMillis())___			LOG.info("Received all " + numberOfCompletedCheckpoints +_				" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_				new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_				.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_				savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			_			files = checkpointDir.listFiles()__			assertNotNull("Checkpoint directory empty", files)__			assertEquals("Checkpoints directory cleaned up, but needed for savepoint.", 1, files.length)__			assertEquals("No job-specific base directory", jobGraph.getJobID().toString(), files[0].getName())___			_			files = savepointDir.listFiles()__			assertNotNull("Savepoint directory empty", files)__			assertEquals("No savepoint found in savepoint directory", 1, files.length)___			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest()___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_					+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			_			StatefulCounter.awaitStateRestoredFromCheckpoint(deadline.timeLeft().toMillis())___			_			StatefulCounter.awaitCompletedCheckpoints(parallelism, numberOfCompletedCheckpoints, deadline.timeLeft().toMillis())___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,2,final,int,checkpointing,interval,100,final,file,tmp,dir,folder,new,folder,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,flink,start,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,checkpointing,interval,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,stateful,counter,await,completed,checkpoints,parallelism,number,of,completed,checkpoints,deadline,time,left,to,millis,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,files,checkpoint,dir,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,cleaned,up,but,needed,for,savepoint,1,files,length,assert,equals,no,job,specific,base,directory,job,graph,get,job,id,to,string,files,0,get,name,files,savepoint,dir,list,files,assert,not,null,savepoint,directory,empty,files,assert,equals,no,savepoint,found,in,savepoint,directory,1,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,string,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,stateful,counter,await,state,restored,from,checkpoint,deadline,time,left,to,millis,stateful,counter,await,completed,checkpoints,parallelism,number,of,completed,checkpoints,deadline,time,left,to,millis,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1484060886;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 2__		final int checkpointingInterval = 100___		_		final File tmpDir = folder.newFolder()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_				checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_				savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			flink.start()___			_			ActorGateway jobManager = Await.result(_				flink.leaderGateway().future(),_				deadline.timeLeft())___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, checkpointingInterval)__			final JobID jobId = jobGraph.getJobID()___			_			_			StatefulCounter.resetForTest()___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints + " checkpoint complete notifications.")___			_			StatefulCounter.awaitCompletedCheckpoints(parallelism, numberOfCompletedCheckpoints, deadline.timeLeft().toMillis())___			LOG.info("Received all " + numberOfCompletedCheckpoints +_				" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_				new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_				.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_				savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			_			files = checkpointDir.listFiles()__			assertNotNull("Checkpoint directory empty", files)__			assertEquals("Checkpoints directory cleaned up, but needed for savepoint.", 1, files.length)__			assertEquals("No job-specific base directory", jobGraph.getJobID().toString(), files[0].getName())___			_			files = savepointDir.listFiles()__			assertNotNull("Savepoint directory empty", files)__			assertEquals("No savepoint found in savepoint directory", 1, files.length)___			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest()___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_					+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			_			StatefulCounter.awaitStateRestoredFromCheckpoint(deadline.timeLeft().toMillis())___			_			StatefulCounter.awaitCompletedCheckpoints(parallelism, numberOfCompletedCheckpoints, deadline.timeLeft().toMillis())___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,2,final,int,checkpointing,interval,100,final,file,tmp,dir,folder,new,folder,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,flink,start,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,checkpointing,interval,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,stateful,counter,await,completed,checkpoints,parallelism,number,of,completed,checkpoints,deadline,time,left,to,millis,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,files,checkpoint,dir,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,cleaned,up,but,needed,for,savepoint,1,files,length,assert,equals,no,job,specific,base,directory,job,graph,get,job,id,to,string,files,0,get,name,files,savepoint,dir,list,files,assert,not,null,savepoint,directory,empty,files,assert,equals,no,savepoint,found,in,savepoint,directory,1,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,string,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,stateful,counter,await,state,restored,from,checkpoint,deadline,time,left,to,millis,stateful,counter,await,completed,checkpoints,parallelism,number,of,completed,checkpoints,deadline,time,left,to,millis,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1487264183;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 2__		final int checkpointingInterval = 100___		_		final File tmpDir = folder.newFolder()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointRootDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointRootDir + ".")___			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_				checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_				savepointRootDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			flink.start()___			_			ActorGateway jobManager = Await.result(_				flink.leaderGateway().future(),_				deadline.timeLeft())___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, checkpointingInterval)__			final JobID jobId = jobGraph.getJobID()___			_			_			StatefulCounter.resetForTest()___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints + " checkpoint complete notifications.")___			_			StatefulCounter.awaitCompletedCheckpoints(parallelism, numberOfCompletedCheckpoints, deadline.timeLeft().toMillis())___			LOG.info("Received all " + numberOfCompletedCheckpoints +_				" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_				new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_				.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_				savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)__				assertTrue("Did not write savepoint files to directory",savepointFiles.length > 1)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not cleaned up: " + Arrays.toString(files), 0, files.length)__			}__			_			files = savepointRootDir.listFiles()__			assertNotNull("Savepoint directory empty", files)__			assertEquals("No savepoint found in savepoint directory", 1, files.length)___			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest()___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_					+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			_			StatefulCounter.awaitStateRestoredFromCheckpoint(deadline.timeLeft().toMillis())___			_			StatefulCounter.awaitCompletedCheckpoints(parallelism, numberOfCompletedCheckpoints, deadline.timeLeft().toMillis())___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,2,final,int,checkpointing,interval,100,final,file,tmp,dir,folder,new,folder,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,root,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,root,dir,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,root,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,flink,start,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,checkpointing,interval,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,stateful,counter,await,completed,checkpoints,parallelism,number,of,completed,checkpoints,deadline,time,left,to,millis,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,assert,true,did,not,write,savepoint,files,to,directory,savepoint,files,length,1,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,cleaned,up,arrays,to,string,files,0,files,length,files,savepoint,root,dir,list,files,assert,not,null,savepoint,directory,empty,files,assert,equals,no,savepoint,found,in,savepoint,directory,1,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,string,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,stateful,counter,await,state,restored,from,checkpoint,deadline,time,left,to,millis,stateful,counter,await,completed,checkpoints,parallelism,number,of,completed,checkpoints,deadline,time,left,to,millis,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testTriggerSavepointAndResume() throws Exception;1487339840;Tests that it is possible to submit a job, trigger a savepoint, and_later restart the job on a new cluster. The savepoint is written to_a file.__<ol>_<li>Submit job, wait for some checkpoints to complete</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResume() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 2__		final int checkpointingInterval = 100___		_		final File tmpDir = folder.newFolder()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_				checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_				savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			flink.start()___			_			ActorGateway jobManager = Await.result(_				flink.leaderGateway().future(),_				deadline.timeLeft())___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, checkpointingInterval)__			final JobID jobId = jobGraph.getJobID()___			_			_			StatefulCounter.resetForTest()___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints + " checkpoint complete notifications.")___			_			StatefulCounter.awaitCompletedCheckpoints(parallelism, numberOfCompletedCheckpoints, deadline.timeLeft().toMillis())___			LOG.info("Received all " + numberOfCompletedCheckpoints +_				" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_				new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_				.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			File[] files = savepointDir.listFiles()__			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_				savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			_			files = checkpointDir.listFiles()__			assertNotNull("Checkpoint directory empty", files)__			assertEquals("Checkpoints directory cleaned up, but needed for savepoint.", 1, files.length)__			assertEquals("No job-specific base directory", jobGraph.getJobID().toString(), files[0].getName())___			_			files = savepointDir.listFiles()__			assertNotNull("Savepoint directory empty", files)__			assertEquals("No savepoint found in savepoint directory", 1, files.length)___			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest()___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()__			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_					+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			_			StatefulCounter.awaitStateRestoredFromCheckpoint(deadline.timeLeft().toMillis())___			_			StatefulCounter.awaitCompletedCheckpoints(parallelism, numberOfCompletedCheckpoints, deadline.timeLeft().toMillis())___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,it,is,possible,to,submit,a,job,trigger,a,savepoint,and,later,restart,the,job,on,a,new,cluster,the,savepoint,is,written,to,a,file,ol,li,submit,job,wait,for,some,checkpoints,to,complete,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,2,final,int,checkpointing,interval,100,final,file,tmp,dir,folder,new,folder,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,flink,start,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,checkpointing,interval,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,stateful,counter,await,completed,checkpoints,parallelism,number,of,completed,checkpoints,deadline,time,left,to,millis,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,file,files,savepoint,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,files,checkpoint,dir,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,cleaned,up,but,needed,for,savepoint,1,files,length,assert,equals,no,job,specific,base,directory,job,graph,get,job,id,to,string,files,0,get,name,files,savepoint,dir,list,files,assert,not,null,savepoint,directory,empty,files,assert,equals,no,savepoint,found,in,savepoint,directory,1,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,string,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,stateful,counter,await,state,restored,from,checkpoint,deadline,time,left,to,millis,stateful,counter,await,completed,checkpoints,parallelism,number,of,completed,checkpoints,deadline,time,left,to,millis,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,dir,list,files,assert,equals,err,msg,0,savepoint,dir,list,files,length,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	@RetryOnFailure(times = 2) 	public void testCheckpointHasBeenRemoved() throws Exception;1465376364;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	@RetryOnFailure(times = 2)_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			try {_				FileUtils.deleteDirectory(checkpointDir)__			} catch (FileNotFoundException ignored) {_			}__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,retry,on,failure,times,2,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,try,file,utils,delete,directory,checkpoint,dir,catch,file,not,found,exception,ignored,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	@RetryOnFailure(times = 2) 	public void testCheckpointHasBeenRemoved() throws Exception;1466083944;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	@RetryOnFailure(times = 2)_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			try {_				FileUtils.deleteDirectory(checkpointDir)__			} catch (FileNotFoundException ignored) {_			}__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,retry,on,failure,times,2,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,try,file,utils,delete,directory,checkpoint,dir,catch,file,not,found,exception,ignored,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	@RetryOnFailure(times = 2) 	public void testCheckpointHasBeenRemoved() throws Exception;1467296201;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	@RetryOnFailure(times = 2)_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Await.ready(savepointFuture, deadline.timeLeft())__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			try {_				FileUtils.deleteDirectory(checkpointDir)__			} catch (FileNotFoundException ignored) {_			}__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,retry,on,failure,times,2,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,await,ready,savepoint,future,deadline,time,left,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,try,file,utils,delete,directory,checkpoint,dir,catch,file,not,found,exception,ignored,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1448992027;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (StateForTask stateForTask : savepoint.getCompletedCheckpoint().getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileState fsState = (AbstractFileState) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,state,for,task,state,for,task,savepoint,get,completed,checkpoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,fs,state,abstract,file,state,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1450188912;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (StateForTask stateForTask : savepoint.getCompletedCheckpoint().getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileState fsState = (AbstractFileState) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,state,for,task,state,for,task,savepoint,get,completed,checkpoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,fs,state,abstract,file,state,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1450356550;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (StateForTask stateForTask : savepoint.getCompletedCheckpoint().getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,state,for,task,state,for,task,savepoint,get,completed,checkpoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1453721631;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (StateForTask stateForTask : savepoint.getCompletedCheckpoint().getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,state,for,task,state,for,task,savepoint,get,completed,checkpoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1455203048;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (StateForTask stateForTask : savepoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,state,for,task,state,for,task,savepoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1455203606;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (StateForTask stateForTask : savepoint.getCompletedCheckpoint().getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,state,for,task,state,for,task,savepoint,get,completed,checkpoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1455311369;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (StateForTask stateForTask : savepoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,state,for,task,state,for,task,savepoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1456487167;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (StateForTask stateForTask : savepoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,state,for,task,state,for,task,savepoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1457706031;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (StateForTask stateForTask : savepoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,state,for,task,state,for,task,savepoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1459778142;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (StateForTask stateForTask : savepoint.getStates()) {_				StreamTaskStateList taskStateList = (StreamTaskStateList) stateForTask.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___				for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__					AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__					checkpointFiles.add(new File(fsState.getFilePath().toUri()))__				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,state,for,task,state,for,task,savepoint,get,states,stream,task,state,list,task,state,list,stream,task,state,list,state,for,task,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1460121606;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (TaskState stateForTaskGroup : savepoint.getTaskStates().values()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamTaskStateList taskStateList = (StreamTaskStateList) subtaskState.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___					for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__						AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__						checkpointFiles.add(new File(fsState.getFilePath().toUri()))__					}_				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,task,state,state,for,task,group,savepoint,get,task,states,values,for,subtask,state,subtask,state,state,for,task,group,get,states,stream,task,state,list,task,state,list,stream,task,state,list,subtask,state,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1465376364;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (TaskState stateForTaskGroup : savepoint.getTaskStates().values()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamTaskStateList taskStateList = (StreamTaskStateList) subtaskState.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___					for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__						AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__						checkpointFiles.add(new File(fsState.getFilePath().toUri()))__					}_				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,task,state,state,for,task,group,savepoint,get,task,states,values,for,subtask,state,subtask,state,state,for,task,group,get,states,stream,task,state,list,task,state,list,stream,task,state,list,subtask,state,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1466083944;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (TaskState stateForTaskGroup : savepoint.getTaskStates().values()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamTaskStateList taskStateList = (StreamTaskStateList) subtaskState.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___					for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__						AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__						checkpointFiles.add(new File(fsState.getFilePath().toUri()))__					}_				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,task,state,state,for,task,group,savepoint,get,task,states,values,for,subtask,state,subtask,state,state,for,task,group,get,states,stream,task,state,list,task,state,list,stream,task,state,list,subtask,state,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1467296201;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV0 savepoint = (SavepointV0) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))___			_			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamTaskStateList taskStateList = (StreamTaskStateList) subtaskState.getState()_						.deserializeValue(ClassLoader.getSystemClassLoader())___					for (StreamTaskState taskState : taskStateList.getState(_						ClassLoader.getSystemClassLoader())) {__						AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__						checkpointFiles.add(new File(fsState.getFilePath().toUri()))__					}_				}_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			_			assertTrue(checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v0,savepoint,savepoint,v0,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,stream,task,state,list,task,state,list,stream,task,state,list,subtask,state,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,finally,if,flink,null,flink,shutdown,assert,true,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1470909547;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getChainedStateHandle()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))__		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			Thread.sleep(1000)___			_			assertTrue(checkpointFiles.toString(), checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,chained,state,handle,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,finally,if,flink,null,flink,shutdown,thread,sleep,1000,assert,true,checkpoint,files,to,string,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1470937207;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV0 savepoint = (SavepointV0) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamTaskStateList taskStateList = (StreamTaskStateList) subtaskState.getState()_							.deserializeValue(ClassLoader.getSystemClassLoader())___					for (StreamTaskState taskState : taskStateList.getState(_							ClassLoader.getSystemClassLoader())) {__						AbstractFileStateHandle fsState = (AbstractFileStateHandle) taskState.getFunctionState()__						checkpointFiles.add(new File(fsState.getFilePath().toUri()))__					}_				}_			}__			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))__		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			Thread.sleep(1000)___			_			assertTrue(checkpointFiles.toString(), checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v0,savepoint,savepoint,v0,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,stream,task,state,list,task,state,list,stream,task,state,list,subtask,state,get,state,deserialize,value,class,loader,get,system,class,loader,for,stream,task,state,task,state,task,state,list,get,state,class,loader,get,system,class,loader,abstract,file,state,handle,fs,state,abstract,file,state,handle,task,state,get,function,state,checkpoint,files,add,new,file,fs,state,get,file,path,to,uri,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,finally,if,flink,null,flink,shutdown,thread,sleep,1000,assert,true,checkpoint,files,to,string,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception;1472659089;Tests that a job manager backed savepoint is removed when the checkpoint_coordinator is shut down, because the associated checkpoints files will_linger around otherwise.;@Test_	public void testCheckpointsRemovedWithJobManagerBackendOnShutdown() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		TestingCluster flink = null__		List<File> checkpointFiles = new ArrayList<>()___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")___			if (!checkpointDir.mkdir()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")___			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "jobmanager")__			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getChainedStateHandle()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			LOG.info("Cancelling job " + jobId + ".")__			Future<Object> cancelRespFuture = jobManager.ask(_					new CancelJob(jobId), deadline.timeLeft())__			assertTrue(Await.result(cancelRespFuture, deadline.timeLeft())_					instanceof CancellationSuccess)___			LOG.info("Waiting for job " + jobId + " to be removed.")__			Future<Object> removedRespFuture = jobManager.ask(_					new NotifyWhenJobRemoved(jobId), deadline.timeLeft())__			assertTrue((Boolean) Await.result(removedRespFuture, deadline.timeLeft()))__		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			Thread.sleep(1000)___			_			assertTrue(checkpointFiles.toString(), checkpointFiles.size() > 0)___			_			_			for (File f : checkpointFiles) {_				String errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,a,job,manager,backed,savepoint,is,removed,when,the,checkpoint,coordinator,is,shut,down,because,the,associated,checkpoints,files,will,linger,around,otherwise;test,public,void,test,checkpoints,removed,with,job,manager,backend,on,shutdown,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,testing,cluster,flink,null,list,file,checkpoint,files,new,array,list,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,if,checkpoint,dir,mkdir,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,config,set,string,savepoint,store,factory,jobmanager,config,set,string,config,constants,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,chained,state,handle,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,log,info,cancelling,job,job,id,future,object,cancel,resp,future,job,manager,ask,new,cancel,job,job,id,deadline,time,left,assert,true,await,result,cancel,resp,future,deadline,time,left,instanceof,cancellation,success,log,info,waiting,for,job,job,id,to,be,removed,future,object,removed,resp,future,job,manager,ask,new,notify,when,job,removed,job,id,deadline,time,left,assert,true,boolean,await,result,removed,resp,future,deadline,time,left,finally,if,flink,null,flink,shutdown,thread,sleep,1000,assert,true,checkpoint,files,to,string,checkpoint,files,size,0,for,file,f,checkpoint,files,string,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay, 		int checkpointingInterval);1479839013;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay,_		int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay, 		int checkpointingInterval);1480933339;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay,_		int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay, 		int checkpointingInterval);1484060886;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay,_		int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay, 		int checkpointingInterval);1487264183;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay,_		int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 		int parallelism, 		int numberOfRetries, 		long restartDelay, 		int checkpointingInterval);1487339840;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_		int parallelism,_		int numberOfRetries,_		long restartDelay,_		int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_			.addSource(new InfiniteTestSource())_			.shuffle()_			.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1448992027;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "fileystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,fileystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1450188912;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "fileystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,fileystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1450356550;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1453721631;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "fileystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,fileystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1455203048;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1455203606;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			Savepoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1455311369;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1456487167;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1457706031;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1459778142;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCheckpointHasBeenRemoved() throws Exception;1460121606;Tests that removed checkpoint files which are part of a savepoint throw_a proper Exception on submission.;@Test_	public void testCheckpointHasBeenRemoved() throws Exception {_		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = numTaskManagers * numSlotsPerTaskManager___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		_		final int numberOfCompletedCheckpoints = 10___		_		final File tmpDir = CommonTestUtils.createTempDirectory()___		LOG.info("Created temporary directory: " + tmpDir + ".")___		ForkableFlinkMiniCluster flink = null___		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(tmpDir, "checkpoints")__			final File savepointDir = new File(tmpDir, "savepoints")___			if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".")__			LOG.info("Created temporary savepoint directory: " + savepointDir + ".")___			config.setString(ConfigConstants.STATE_BACKEND, "filesystem")__			config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY, "filesystem")___			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,_					checkpointDir.toURI().toString())__			config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			_			InfiniteTestSource.CheckpointCompleteLatch = new CountDownLatch(_					numberOfCompletedCheckpoints)___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			InfiniteTestSource.CheckpointCompleteLatch.await()___			LOG.info("Received all " + numberOfCompletedCheckpoints +_					" checkpoint complete notifications.")___			_			LOG.info("Triggering a savepoint.")___			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobId), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(_					new RequestSavepoint(savepointPath),_					deadline.timeLeft())___			CompletedCheckpoint savepoint = ((ResponseSavepoint) Await.result(_					savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepoint + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()___			_			FileUtils.deleteDirectory(checkpointDir)___			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			jobGraph.setSavepointPath(savepointPath)___			LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				fail("Did not throw expected Exception because of missing checkpoint files")__			}_			catch (Exception ignored) {_			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}__			if (tmpDir != null) {_				FileUtils.deleteDirectory(tmpDir)__			}_		}_	};tests,that,removed,checkpoint,files,which,are,part,of,a,savepoint,throw,a,proper,exception,on,submission;test,public,void,test,checkpoint,has,been,removed,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,int,number,of,completed,checkpoints,10,final,file,tmp,dir,common,test,utils,create,temp,directory,log,info,created,temporary,directory,tmp,dir,forkable,flink,mini,cluster,flink,null,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,tmp,dir,checkpoints,final,file,savepoint,dir,new,file,tmp,dir,savepoints,if,checkpoint,dir,mkdir,savepoint,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,log,info,created,temporary,checkpoint,directory,checkpoint,dir,log,info,created,temporary,savepoint,directory,savepoint,dir,config,set,string,config,constants,filesystem,config,set,string,savepoint,store,factory,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,savepoint,store,factory,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,1000,final,job,id,job,id,job,graph,get,job,id,infinite,test,source,checkpoint,complete,latch,new,count,down,latch,number,of,completed,checkpoints,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,number,of,completed,checkpoints,checkpoint,complete,notifications,infinite,test,source,checkpoint,complete,latch,await,log,info,received,all,number,of,completed,checkpoints,checkpoint,complete,notifications,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,completed,checkpoint,savepoint,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,log,info,shutting,down,flink,cluster,flink,shutdown,file,utils,delete,directory,checkpoint,dir,log,info,restarting,flink,cluster,flink,start,job,graph,set,savepoint,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,because,of,missing,checkpoint,files,catch,exception,ignored,finally,if,flink,null,flink,shutdown,if,tmp,dir,null,file,utils,delete,directory,tmp,dir
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1489164945;FLINK-5985__This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = CommonTestUtils.createTempDirectory()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,common,test,utils,create,temp,directory,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,finally,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1490628047;FLINK-5985__This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = CommonTestUtils.createTempDirectory()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,common,test,utils,create,temp,directory,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,finally,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1491385557;FLINK-5985__This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = CommonTestUtils.createTempDirectory()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,common,test,utils,create,temp,directory,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,finally,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1493401220;FLINK-5985__This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = CommonTestUtils.createTempDirectory()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,common,test,utils,create,temp,directory,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,finally,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1495464939;FLINK-5985__This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,config,constants,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,finally,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1496173247;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,finally,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1498211968;FLINK-5985__This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,finally,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1498493279;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,finally,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1501592283;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,finally,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1503588494;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,finally,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1506689437;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__		config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_				savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		TestingCluster flink = new TestingCluster(config)__		try {_			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__		}__		_		_		flink = new TestingCluster(config)__		try {_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)___			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.stop()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,testing,cluster,flink,new,testing,cluster,config,try,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,flink,stop,flink,new,testing,cluster,config,try,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,stop
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1507293223;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		TestingCluster flink = null__		String savepointPath__		try {_			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_					savepointDir.toURI().toString())___			LOG.info("Flink configuration: " + config + ".")___			_			flink = new TestingCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()__		}__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.shutdown()__			flink.awaitTermination()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,testing,cluster,flink,null,string,savepoint,path,try,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,log,info,flink,configuration,config,flink,new,testing,cluster,config,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,shutdown,flink,await,termination
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1508093641;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__		config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_				savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		TestingCluster flink = new TestingCluster(config)__		try {_			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__		}__		_		_		flink = new TestingCluster(config)__		try {_			LOG.info("Restarting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.stop()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,testing,cluster,flink,new,testing,cluster,config,try,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,flink,stop,flink,new,testing,cluster,config,try,log,info,restarting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,stop
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1508494390;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__		config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_				savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		TestingCluster flink = new TestingCluster(config)__		try {_			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__		}__		_		_		flink = new TestingCluster(config)__		try {_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)___			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.stop()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,testing,cluster,flink,new,testing,cluster,config,try,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,flink,stop,flink,new,testing,cluster,config,try,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,stop
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1508945414;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		TestingCluster flink = new TestingCluster(config)__		try {_			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__		}__		_		_		flink = new TestingCluster(config)__		try {_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)___			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.stop()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,testing,cluster,flink,new,testing,cluster,config,try,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,flink,stop,flink,new,testing,cluster,config,try,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,stop
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1509045960;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		TestingCluster flink = new TestingCluster(config)__		try {_			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__		}__		_		_		flink = new TestingCluster(config)__		try {_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)___			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.stop()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,testing,cluster,flink,new,testing,cluster,config,try,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,flink,stop,flink,new,testing,cluster,config,try,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,stop
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1509287653;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__		config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_				savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		TestingCluster flink = new TestingCluster(config)__		try {_			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__		}__		_		_		flink = new TestingCluster(config)__		try {_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)___			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.stop()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,testing,cluster,flink,new,testing,cluster,config,try,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,flink,stop,flink,new,testing,cluster,config,try,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,stop
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1511291153;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()___		final File tmpDir = folder.getRoot()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__		config.setString(CoreOptions.SAVEPOINT_DIRECTORY,_				savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		TestingCluster flink = new TestingCluster(config)__		try {_			LOG.info("Starting Flink cluster.")__			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(_					flink.leaderGateway().future(),_					deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			JobSubmissionResult submissionResult = flink.submitJobDetached(originalJobGraph)__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__		}__		_		_		flink = new TestingCluster(config)__		try {_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)___			flink.start(true)___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			flink.submitJobDetached(modifiedJobGraph)__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			flink.stop()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,tmp,dir,folder,get,root,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,config,set,string,core,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,testing,cluster,flink,new,testing,cluster,config,try,log,info,starting,flink,cluster,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,job,submission,result,submission,result,flink,submit,job,detached,original,job,graph,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,flink,stop,flink,new,testing,cluster,config,try,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,true,log,info,retrieving,job,manager,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,flink,submit,job,detached,modified,job,graph,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,flink,stop
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1518245533;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		final File tmpDir = folder.newFolder()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterResource cluster = new MiniClusterResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(value -> 4 * value)_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(value -> 2 * value)_					.addSink(new DiscardingSink<>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(value -> value)_					.addSink(new DiscardingSink<>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,file,tmp,dir,folder,new,folder,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,resource,cluster,new,mini,cluster,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,value,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,value,2,value,add,sink,new,discarding,sink,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,value,value,add,sink,new,discarding,sink,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1522154703;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		final File tmpDir = folder.newFolder()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterResource cluster = new MiniClusterResource(_			new MiniClusterResource.MiniClusterResourceConfiguration(_				config,_				numTaskManagers,_				numSlotsPerTaskManager_			),_			true)___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 4 * value__						}_					})_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return 2 * value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterResource(_			new MiniClusterResource.MiniClusterResourceConfiguration(_				config,_				numTaskManagers,_				numSlotsPerTaskManager_			),_			true)__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(new MapFunction<Integer, Integer>() {__						@Override_						public Integer map(Integer value) throws Exception {_							return value__						}_					})_					.addSink(new DiscardingSink<Integer>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,file,tmp,dir,folder,new,folder,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,resource,cluster,new,mini,cluster,resource,new,mini,cluster,resource,mini,cluster,resource,configuration,config,num,task,managers,num,slots,per,task,manager,true,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,2,value,add,sink,new,discarding,sink,integer,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,resource,new,mini,cluster,resource,mini,cluster,resource,configuration,config,num,task,managers,num,slots,per,task,manager,true,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,new,map,function,integer,integer,override,public,integer,map,integer,value,throws,exception,return,value,add,sink,new,discarding,sink,integer,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1527089094;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		final File tmpDir = folder.newFolder()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterResource cluster = new MiniClusterResource(_			new MiniClusterResource.MiniClusterResourceConfiguration(_				config,_				numTaskManagers,_				numSlotsPerTaskManager_			),_			true)___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(value -> 4 * value)_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(value -> 2 * value)_					.addSink(new DiscardingSink<>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterResource(_			new MiniClusterResource.MiniClusterResourceConfiguration(_				config,_				numTaskManagers,_				numSlotsPerTaskManager_			),_			true)__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(value -> value)_					.addSink(new DiscardingSink<>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,file,tmp,dir,folder,new,folder,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,resource,cluster,new,mini,cluster,resource,new,mini,cluster,resource,mini,cluster,resource,configuration,config,num,task,managers,num,slots,per,task,manager,true,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,value,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,value,2,value,add,sink,new,discarding,sink,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,resource,new,mini,cluster,resource,mini,cluster,resource,configuration,config,num,task,managers,num,slots,per,task,manager,true,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,value,value,add,sink,new,discarding,sink,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1529585865;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		final File tmpDir = folder.newFolder()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterResource cluster = new MiniClusterResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build(),_			true)___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(value -> 4 * value)_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(value -> 2 * value)_					.addSink(new DiscardingSink<>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build(),_			true)__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(value -> value)_					.addSink(new DiscardingSink<>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,file,tmp,dir,folder,new,folder,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,resource,cluster,new,mini,cluster,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,true,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,value,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,value,2,value,add,sink,new,discarding,sink,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,true,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,value,value,add,sink,new,discarding,sink,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1529586951;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		final File tmpDir = folder.newFolder()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterResource cluster = new MiniClusterResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(value -> 4 * value)_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(value -> 2 * value)_					.addSink(new DiscardingSink<>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(value -> value)_					.addSink(new DiscardingSink<>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,file,tmp,dir,folder,new,folder,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,resource,cluster,new,mini,cluster,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,value,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,value,2,value,add,sink,new,discarding,sink,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,value,value,add,sink,new,discarding,sink,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1531820069;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		final File tmpDir = folder.newFolder()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterResource cluster = new MiniClusterResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(value -> 4 * value)_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(value -> 2 * value)_					.addSink(new DiscardingSink<>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(value -> value)_					.addSink(new DiscardingSink<>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,file,tmp,dir,folder,new,folder,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,resource,cluster,new,mini,cluster,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,value,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,value,2,value,add,sink,new,discarding,sink,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,value,value,add,sink,new,discarding,sink,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1539371200;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		final File tmpDir = folder.newFolder()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterResource cluster = new MiniClusterResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(value -> 4 * value)_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(value -> 2 * value)_					.addSink(new DiscardingSink<>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(value -> value)_					.addSink(new DiscardingSink<>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,file,tmp,dir,folder,new,folder,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,resource,cluster,new,mini,cluster,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,value,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,value,2,value,add,sink,new,discarding,sink,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,value,value,add,sink,new,discarding,sink,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1540216840;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		final File tmpDir = folder.newFolder()__		final File savepointDir = new File(tmpDir, "savepoints")___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterWithClientResource cluster = new MiniClusterWithClientResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(value -> 4 * value)_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(value -> 2 * value)_					.addSink(new DiscardingSink<>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterWithClientResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(value -> value)_					.addSink(new DiscardingSink<>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,file,tmp,dir,folder,new,folder,final,file,savepoint,dir,new,file,tmp,dir,savepoints,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,with,client,resource,cluster,new,mini,cluster,with,client,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,value,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,value,2,value,add,sink,new,discarding,sink,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,with,client,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,value,value,add,sink,new,discarding,sink,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1542192035;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterWithClientResource cluster = new MiniClusterWithClientResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(value -> 4 * value)_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(value -> 2 * value)_					.addSink(new DiscardingSink<>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterWithClientResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(value -> value)_					.addSink(new DiscardingSink<>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,with,client,resource,cluster,new,mini,cluster,with,client,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,value,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,value,2,value,add,sink,new,discarding,sink,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,with,client,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,value,value,add,sink,new,discarding,sink,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1542279564;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterWithClientResource cluster = new MiniClusterWithClientResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(value -> 4 * value)_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(value -> 2 * value)_					.addSink(new DiscardingSink<>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterWithClientResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(value -> value)_					.addSink(new DiscardingSink<>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,with,client,resource,cluster,new,mini,cluster,with,client,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,value,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,value,2,value,add,sink,new,discarding,sink,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,with,client,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,value,value,add,sink,new,discarding,sink,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testCanRestoreWithModifiedStatelessOperators() throws Exception;1550075375;FLINK-5985__<p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern_stateless operators.;@Test_	public void testCanRestoreWithModifiedStatelessOperators() throws Exception {__		_		int numTaskManagers = 2__		int numSlotsPerTaskManager = 2__		int parallelism = 2___		_		final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5))___		_		final Configuration config = new Configuration()__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString())___		String savepointPath___		LOG.info("Flink configuration: " + config + ".")___		_		MiniClusterWithClientResource cluster = new MiniClusterWithClientResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())___		LOG.info("Shutting down Flink cluster.")__		cluster.before()__		ClusterClient<?> client = cluster.getClusterClient()__		try {_			final StatefulCounter statefulCounter = new StatefulCounter()__			StatefulCounter.resetForTest(parallelism)___			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)__			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(value -> 4 * value)_					.shuffle()_					.map(statefulCounter).uid("statefulCounter")_					.shuffle()_					.map(value -> 2 * value)_					.addSink(new DiscardingSink<>())___			JobGraph originalJobGraph = env.getStreamGraph().getJobGraph()___			client.setDetached(true)__			JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader())__			JobID jobID = submissionResult.getJobID()___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			savepointPath = client.triggerSavepoint(jobID, null).get()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")__		} finally {_			_			LOG.info("Shutting down Flink cluster.")__			cluster.after()__		}__		_		_		cluster = new MiniClusterWithClientResource(_			new MiniClusterResourceConfiguration.Builder()_				.setConfiguration(config)_				.setNumberTaskManagers(numTaskManagers)_				.setNumberSlotsPerTaskManager(numSlotsPerTaskManager)_				.build())__		LOG.info("Restarting Flink cluster.")__		cluster.before()__		client = cluster.getClusterClient()__		try {_			_			StatefulCounter.resetForTest(parallelism)___			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(parallelism)___			_			env.addSource(new InfiniteTestSource())_					.shuffle()_					.map(new StatefulCounter()).uid("statefulCounter")_					.shuffle()_					.map(value -> value)_					.addSink(new DiscardingSink<>())___			JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph()___			_			modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " +_					"savepoint path " + savepointPath + " in detached mode.")___			_			client.setDetached(true)__			client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader())__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__		} finally {_			cluster.after()__		}_	};flink,5985,p,this,test,ensures,we,can,restore,from,a,savepoint,under,modifications,to,the,job,graph,that,only,concern,stateless,operators;test,public,void,test,can,restore,with,modified,stateless,operators,throws,exception,int,num,task,managers,2,int,num,slots,per,task,manager,2,int,parallelism,2,final,deadline,deadline,deadline,now,plus,duration,of,minutes,5,final,configuration,config,new,configuration,config,set,string,checkpointing,options,savepoint,dir,to,uri,to,string,string,savepoint,path,log,info,flink,configuration,config,mini,cluster,with,client,resource,cluster,new,mini,cluster,with,client,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,shutting,down,flink,cluster,cluster,before,cluster,client,client,cluster,get,cluster,client,try,final,stateful,counter,stateful,counter,new,stateful,counter,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,value,4,value,shuffle,map,stateful,counter,uid,stateful,counter,shuffle,map,value,2,value,add,sink,new,discarding,sink,job,graph,original,job,graph,env,get,stream,graph,get,job,graph,client,set,detached,true,job,submission,result,submission,result,client,submit,job,original,job,graph,savepoint,itcase,class,get,class,loader,job,id,job,id,submission,result,get,job,id,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,savepoint,path,client,trigger,savepoint,job,id,null,get,log,info,retrieved,savepoint,savepoint,path,finally,log,info,shutting,down,flink,cluster,cluster,after,cluster,new,mini,cluster,with,client,resource,new,mini,cluster,resource,configuration,builder,set,configuration,config,set,number,task,managers,num,task,managers,set,number,slots,per,task,manager,num,slots,per,task,manager,build,log,info,restarting,flink,cluster,cluster,before,client,cluster,get,cluster,client,try,stateful,counter,reset,for,test,parallelism,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,uid,stateful,counter,shuffle,map,value,value,add,sink,new,discarding,sink,job,graph,modified,job,graph,env,get,stream,graph,get,job,graph,modified,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,modified,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,client,set,detached,true,client,submit,job,modified,job,graph,savepoint,itcase,class,get,class,loader,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,finally,cluster,after
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1488276808;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.newFolder()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_					+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,new,folder,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,string,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1488305808;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.newFolder()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_					+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,new,folder,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,string,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1489164945;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.newFolder()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_					+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,new,folder,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,string,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1490628047;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.newFolder()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_					+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,new,folder,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,string,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1491385557;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.newFolder()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV1 savepoint = (SavepointV1) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			assertNull(errMsg, error[0])___			_			_			for (TaskState taskState : savepoint.getTaskStates()) {_				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(taskState.getJobVertexID())___				errMsg = "Missing task for savepoint state for operator "_					+ taskState.getJobVertexID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(taskState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					SubtaskState subtaskState = taskState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState())__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (TaskState stateForTaskGroup : savepoint.getTaskStates()) {_				for (SubtaskState subtaskState : stateForTaskGroup.getStates()) {_					ChainedStateHandle<StreamStateHandle> streamTaskState = subtaskState.getLegacyOperatorState()___					for (int i = 0_ i < streamTaskState.getLength()_ i++) {_						if (streamTaskState.get(i) != null) {_							FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState.get(i)__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,new,folder,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v1,savepoint,savepoint,v1,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,string,err,msg,error,during,gathering,of,task,deployment,descriptors,assert,null,err,msg,error,0,for,task,state,task,state,savepoint,get,task,states,collection,task,deployment,descriptor,task,tdds,tdds,get,task,state,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,task,state,get,job,vertex,id,assert,true,err,msg,task,tdds,size,0,assert,equals,task,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,subtask,state,subtask,state,task,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,task,state,state,for,task,group,savepoint,get,task,states,for,subtask,state,subtask,state,state,for,task,group,get,states,chained,state,handle,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,for,int,i,0,i,stream,task,state,get,length,i,if,stream,task,state,get,i,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,get,i,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1493401220;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.newFolder()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState().get(chainIndexAndJobVertex.f0))__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamStateHandle streamTaskState = subtaskState.getLegacyOperatorState()___					if (streamTaskState != null) {_						FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState__						checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,new,folder,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,get,chain,index,and,job,vertex,f0,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,if,stream,task,state,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1495464939;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(ConfigConstants.SAVEPOINT_DIRECTORY_KEY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState().get(chainIndexAndJobVertex.f0))__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamStateHandle streamTaskState = subtaskState.getLegacyOperatorState()___					if (streamTaskState != null) {_						FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState__						checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,config,constants,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,get,chain,index,and,job,vertex,f0,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,if,stream,task,state,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1496173247;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState().get(chainIndexAndJobVertex.f0))__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamStateHandle streamTaskState = subtaskState.getLegacyOperatorState()___					if (streamTaskState != null) {_						FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState__						checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,get,chain,index,and,job,vertex,f0,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,if,stream,task,state,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1498211968;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState().get(chainIndexAndJobVertex.f0))__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamStateHandle streamTaskState = subtaskState.getLegacyOperatorState()___					if (streamTaskState != null) {_						FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState__						checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,get,chain,index,and,job,vertex,f0,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,if,stream,task,state,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1498493279;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getSubtaskStateByOperatorID(operatorState.getOperatorID()).getLegacyOperatorState())__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamStateHandle streamTaskState = subtaskState.getLegacyOperatorState()___					if (streamTaskState != null) {_						FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState__						checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,subtask,state,by,operator,id,operator,state,get,operator,id,get,legacy,operator,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,if,stream,task,state,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1501592283;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)___					errMsg = "Initial operator state mismatch."__					assertEquals(errMsg, subtaskState.getLegacyOperatorState(),_						tdd.getTaskStateHandles().getLegacyOperatorState().get(chainIndexAndJobVertex.f0))__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			__			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					StreamStateHandle streamTaskState = subtaskState.getLegacyOperatorState()___					if (streamTaskState != null) {_						FileStateHandle fileStateHandle = (FileStateHandle) streamTaskState__						checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,err,msg,initial,operator,state,mismatch,assert,equals,err,msg,subtask,state,get,legacy,operator,state,tdd,get,task,state,handles,get,legacy,operator,state,get,chain,index,and,job,vertex,f0,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,stream,state,handle,stream,task,state,subtask,state,get,legacy,operator,state,if,stream,task,state,null,file,state,handle,file,state,handle,file,state,handle,stream,task,state,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1503588494;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			_			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					Collection<OperatorStateHandle> streamTaskState = subtaskState.getManagedOperatorState()___					if (streamTaskState != null && !streamTaskState.isEmpty()) {_						for (OperatorStateHandle osh : streamTaskState) {_							FileStateHandle fileStateHandle = (FileStateHandle) osh.getDelegateStateHandle()__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,collection,operator,state,handle,stream,task,state,subtask,state,get,managed,operator,state,if,stream,task,state,null,stream,task,state,is,empty,for,operator,state,handle,osh,stream,task,state,file,state,handle,file,state,handle,file,state,handle,osh,get,delegate,state,handle,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1506689437;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__			flink = null___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			_			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					Collection<OperatorStateHandle> streamTaskState = subtaskState.getManagedOperatorState()___					if (streamTaskState != null && !streamTaskState.isEmpty()) {_						for (OperatorStateHandle osh : streamTaskState) {_							FileStateHandle fileStateHandle = (FileStateHandle) osh.getDelegateStateHandle()__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.stop()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,stop,flink,null,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,collection,operator,state,handle,stream,task,state,subtask,state,get,managed,operator,state,if,stream,task,state,null,stream,task,state,is,empty,for,operator,state,handle,osh,stream,task,state,file,state,handle,file,state,handle,file,state,handle,osh,get,delegate,state,handle,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,stop
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1507293223;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			_			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					Collection<OperatorStateHandle> streamTaskState = subtaskState.getManagedOperatorState()___					if (streamTaskState != null && !streamTaskState.isEmpty()) {_						for (OperatorStateHandle osh : streamTaskState) {_							FileStateHandle fileStateHandle = (FileStateHandle) osh.getDelegateStateHandle()__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,collection,operator,state,handle,stream,task,state,subtask,state,get,managed,operator,state,if,stream,task,state,null,stream,task,state,is,empty,for,operator,state,handle,osh,stream,task,state,file,state,handle,file,state,handle,file,state,handle,osh,get,delegate,state,handle,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1508093641;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.shutdown()__			flink.awaitTermination()___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			_			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					Collection<OperatorStateHandle> streamTaskState = subtaskState.getManagedOperatorState()___					if (streamTaskState != null && !streamTaskState.isEmpty()) {_						for (OperatorStateHandle osh : streamTaskState) {_							FileStateHandle fileStateHandle = (FileStateHandle) osh.getDelegateStateHandle()__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,shutdown,flink,await,termination,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,collection,operator,state,handle,stream,task,state,subtask,state,get,managed,operator,state,if,stream,task,state,null,stream,task,state,is,empty,for,operator,state,handle,osh,stream,task,state,file,state,handle,file,state,handle,file,state,handle,osh,get,delegate,state,handle,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1508494390;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__			flink = null___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			_			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					Collection<OperatorStateHandle> streamTaskState = subtaskState.getManagedOperatorState()___					if (streamTaskState != null && !streamTaskState.isEmpty()) {_						for (OperatorStateHandle osh : streamTaskState) {_							FileStateHandle fileStateHandle = (FileStateHandle) osh.getDelegateStateHandle()__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.stop()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,stop,flink,null,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,collection,operator,state,handle,stream,task,state,subtask,state,get,managed,operator,state,if,stream,task,state,null,stream,task,state,is,empty,for,operator,state,handle,osh,stream,task,state,file,state,handle,file,state,handle,file,state,handle,osh,get,delegate,state,handle,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,stop
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1508945414;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem")__			config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString())__			config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0)__			config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__			flink = null___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			_			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					Collection<OperatorStateHandle> streamTaskState = subtaskState.getManagedOperatorState()___					if (streamTaskState != null && !streamTaskState.isEmpty()) {_						for (OperatorStateHandle osh : streamTaskState) {_							FileStateHandle fileStateHandle = (FileStateHandle) osh.getDelegateStateHandle()__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.stop()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,checkpointing,options,filesystem,config,set,string,checkpointing,options,checkpoint,dir,to,uri,to,string,config,set,integer,checkpointing,options,0,config,set,string,checkpointing,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,stop,flink,null,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,collection,operator,state,handle,stream,task,state,subtask,state,get,managed,operator,state,if,stream,task,state,null,stream,task,state,is,empty,for,operator,state,handle,osh,stream,task,state,file,state,handle,file,state,handle,file,state,handle,osh,get,delegate,state,handle,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,stop
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1509045960;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem")__			config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString())__			config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0)__			config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__			flink = null___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			_			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					Collection<OperatorStateHandle> streamTaskState = subtaskState.getManagedOperatorState()___					if (streamTaskState != null && !streamTaskState.isEmpty()) {_						for (OperatorStateHandle osh : streamTaskState) {_							FileStateHandle fileStateHandle = (FileStateHandle) osh.getDelegateStateHandle()__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.stop()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,checkpointing,options,filesystem,config,set,string,checkpointing,options,checkpoint,dir,to,uri,to,string,config,set,integer,checkpointing,options,0,config,set,string,checkpointing,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,stop,flink,null,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,collection,operator,state,handle,stream,task,state,subtask,state,get,managed,operator,state,if,stream,task,state,null,stream,task,state,is,empty,for,operator,state,handle,osh,stream,task,state,file,state,handle,file,state,handle,file,state,handle,osh,get,delegate,state,handle,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,stop
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1509287653;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__			flink = null___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			_			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					Collection<OperatorStateHandle> streamTaskState = subtaskState.getManagedOperatorState()___					if (streamTaskState != null && !streamTaskState.isEmpty()) {_						for (OperatorStateHandle osh : streamTaskState) {_							FileStateHandle fileStateHandle = (FileStateHandle) osh.getDelegateStateHandle()__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.stop()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,stop,flink,null,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,collection,operator,state,handle,stream,task,state,subtask,state,get,managed,operator,state,if,stream,task,state,null,stream,task,state,is,empty,for,operator,state,handle,osh,stream,task,state,file,state,handle,file,state,handle,file,state,handle,osh,get,delegate,state,handle,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,stop
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1511291153;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final Deadline deadline = new FiniteDuration(5, TimeUnit.MINUTES).fromNow()__		final File testRoot = folder.getRoot()___		TestingCluster flink = null___		try {_			_			ActorSystem testActorSystem = AkkaUtils.createDefaultActorSystem()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)___			final File checkpointDir = new File(testRoot, "checkpoints")__			final File savepointRootDir = new File(testRoot, "savepoints")___			if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_				fail("Test setup failed: failed to create temporary directories.")__			}__			_			config.setString(CoreOptions.STATE_BACKEND, "filesystem")__			config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY, checkpointDir.toURI().toString())__			config.setString(FsStateBackendFactory.MEMORY_THRESHOLD_CONF_KEY, "0")__			config.setString(CoreOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___			_			flink = new TestingCluster(config)__			flink.start(true)___			_			final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000)__			final JobID jobId = jobGraph.getJobID()___			_			StatefulCounter.resetForTest(parallelism)___			_			ActorGateway jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())___			LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.")___			flink.submitJobDetached(jobGraph)___			LOG.info("Waiting for some progress.")___			_			Future<Object> allRunning = jobManager.ask(new WaitForAllVerticesToBeRunning(jobId), deadline.timeLeft())__			Await.ready(allRunning, deadline.timeLeft())___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			LOG.info("Triggering a savepoint.")__			Future<Object> savepointPathFuture = jobManager.ask(new TriggerSavepoint(jobId, Option.<String>empty()), deadline.timeLeft())__			final String savepointPath = ((TriggerSavepointSuccess) Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			LOG.info("Requesting the savepoint.")__			Future<Object> savepointFuture = jobManager.ask(new RequestSavepoint(savepointPath), deadline.timeLeft())___			SavepointV2 savepoint = (SavepointV2) ((ResponseSavepoint) Await.result(savepointFuture, deadline.timeLeft())).savepoint()__			LOG.info("Retrieved savepoint: " + savepointPath + ".")___			_			LOG.info("Shutting down Flink cluster.")__			flink.stop()__			flink = null___			__			_			File[] files = savepointRootDir.listFiles()___			if (files != null) {_				assertEquals("Savepoint not created in expected directory", 1, files.length)__				assertTrue("Savepoint did not create self-contained directory", files[0].isDirectory())___				File savepointDir = files[0]__				File[] savepointFiles = savepointDir.listFiles()__				assertNotNull(savepointFiles)___				_				_				String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: "_					+ Arrays.toString(savepointFiles)__				assertEquals(errMsg, 1 + parallelism, savepointFiles.length)__			} else {_				fail("Savepoint not created in expected directory")__			}__			_			File jobCheckpoints = new File(checkpointDir, jobId.toString())___			if (jobCheckpoints.exists()) {_				files = jobCheckpoints.listFiles()__				assertNotNull("Checkpoint directory empty", files)__				assertEquals("Checkpoints directory not clean: " + Arrays.toString(files), 0, files.length)__			}__			__			_			LOG.info("Restarting Flink cluster.")__			flink = new TestingCluster(config)__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			jobManager = Await.result(flink.leaderGateway().future(), deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			StatefulCounter.resetForTest(parallelism)___			_			final Throwable[] error = new Throwable[1]__			final TestingCluster finalFlink = flink__			final Multimap<JobVertexID, TaskDeploymentDescriptor> tdds = HashMultimap.create()___			new JavaTestKit(testActorSystem) {{__				new Within(deadline.timeLeft()) {_					@Override_					protected void run() {_						try {_							_							for (ActorRef taskManager : finalFlink.getTaskManagersAsJava()) {_								taskManager.tell(new TestingTaskManagerMessages_									.RegisterSubmitTaskListener(jobId), getTestActor())__							}__							_							jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___							LOG.info("Resubmitting job " + jobGraph.getJobID() + " with " +_								"savepoint path " + savepointPath + " in detached mode.")___							_							finalFlink.submitJobDetached(jobGraph)___							int numTasks = 0__							for (JobVertex jobVertex : jobGraph.getVertices()) {_								numTasks += jobVertex.getParallelism()__							}__							_							LOG.info("Gathering " + numTasks + " submitted " +_								"TaskDeploymentDescriptor instances.")___							for (int i = 0_ i < numTasks_ i++) {_								ResponseSubmitTaskListener resp = (ResponseSubmitTaskListener)_									expectMsgAnyClassOf(getRemainingTime(),_										ResponseSubmitTaskListener.class)___								TaskDeploymentDescriptor tdd = resp.tdd()___								LOG.info("Received: " + tdd.toString() + ".")___								TaskInformation taskInformation = tdd_									.getSerializedTaskInformation()_									.deserializeValue(getClass().getClassLoader())___								tdds.put(taskInformation.getJobVertexId(), tdd)__							}_						} catch (Throwable t) {_							error[0] = t__						}_					}_				}__			}}___			ExecutionGraph graph = (ExecutionGraph) ((JobManagerMessages.JobFound) Await.result(jobManager.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft()), deadline.timeLeft())).executionGraph()___			__			String errMsg = "Error during gathering of TaskDeploymentDescriptors"__			if (error[0] != null) {_				throw new RuntimeException(error[0])__			}__			Map<OperatorID, Tuple2<Integer, ExecutionJobVertex>> operatorToJobVertexMapping = new HashMap<>()__			for (ExecutionJobVertex task : graph.getVerticesTopologically()) {_				List<OperatorID> operatorIDs = task.getOperatorIDs()__				for (int x = 0_ x < operatorIDs.size()_ x++) {_					operatorToJobVertexMapping.put(operatorIDs.get(x), new Tuple2<>(x, task))__				}_			}__			_			_			for (OperatorState operatorState : savepoint.getOperatorStates()) {_				Tuple2<Integer, ExecutionJobVertex> chainIndexAndJobVertex = operatorToJobVertexMapping.get(operatorState.getOperatorID())__				Collection<TaskDeploymentDescriptor> taskTdds = tdds.get(chainIndexAndJobVertex.f1.getJobVertexId())___				errMsg = "Missing task for savepoint state for operator "_					+ operatorState.getOperatorID() + "."__				assertTrue(errMsg, taskTdds.size() > 0)___				assertEquals(operatorState.getNumberCollectedStates(), taskTdds.size())___				for (TaskDeploymentDescriptor tdd : taskTdds) {_					OperatorSubtaskState subtaskState = operatorState.getState(tdd.getSubtaskIndex())___					assertNotNull(subtaskState)__				}_			}__			_			StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			_			StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			LOG.info("Cancelling job " + jobId + ".")__			jobManager.tell(new CancelJob(jobId))___			LOG.info("Disposing savepoint " + savepointPath + ".")__			Future<Object> disposeFuture = jobManager.ask(new DisposeSavepoint(savepointPath), deadline.timeLeft())___			errMsg = "Failed to dispose savepoint " + savepointPath + "."__			Object resp = Await.result(disposeFuture, deadline.timeLeft())__			assertTrue(errMsg, resp.getClass() == getDisposeSavepointSuccess().getClass())___			_			_			List<File> checkpointFiles = new ArrayList<>()___			for (OperatorState stateForTaskGroup : savepoint.getOperatorStates()) {_				for (OperatorSubtaskState subtaskState : stateForTaskGroup.getStates()) {_					Collection<OperatorStateHandle> streamTaskState = subtaskState.getManagedOperatorState()___					if (streamTaskState != null && !streamTaskState.isEmpty()) {_						for (OperatorStateHandle osh : streamTaskState) {_							FileStateHandle fileStateHandle = (FileStateHandle) osh.getDelegateStateHandle()__							checkpointFiles.add(new File(fileStateHandle.getFilePath().toUri()))__						}_					}_				}_			}__			_			for (File f : checkpointFiles) {_				errMsg = "Checkpoint file " + f + " not cleaned up properly."__				assertFalse(errMsg, f.exists())__			}__			if (checkpointFiles.size() > 0) {_				File parent = checkpointFiles.get(0).getParentFile()__				errMsg = "Checkpoint parent directory " + parent + " not cleaned up properly."__				assertFalse(errMsg, parent.exists())__			}__			_			errMsg = "Savepoints directory not cleaned up properly: " +_				Arrays.toString(savepointRootDir.listFiles()) + "."__			assertEquals(errMsg, 0, savepointRootDir.listFiles().length)___			_		} finally {_			if (flink != null) {_				flink.stop()__			}_		}_	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,deadline,deadline,new,finite,duration,5,time,unit,minutes,from,now,final,file,test,root,folder,get,root,testing,cluster,flink,null,try,actor,system,test,actor,system,akka,utils,create,default,actor,system,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,core,options,filesystem,config,set,string,fs,state,backend,factory,checkpoint,dir,to,uri,to,string,config,set,string,fs,state,backend,factory,0,config,set,string,core,options,savepoint,root,dir,to,uri,to,string,flink,new,testing,cluster,config,flink,start,true,final,job,graph,job,graph,create,job,graph,parallelism,0,1000,final,job,id,job,id,job,graph,get,job,id,stateful,counter,reset,for,test,parallelism,actor,gateway,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,submitting,job,job,graph,get,job,id,in,detached,mode,flink,submit,job,detached,job,graph,log,info,waiting,for,some,progress,future,object,all,running,job,manager,ask,new,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,running,deadline,time,left,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,triggering,a,savepoint,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,log,info,requesting,the,savepoint,future,object,savepoint,future,job,manager,ask,new,request,savepoint,savepoint,path,deadline,time,left,savepoint,v2,savepoint,savepoint,v2,response,savepoint,await,result,savepoint,future,deadline,time,left,savepoint,log,info,retrieved,savepoint,savepoint,path,log,info,shutting,down,flink,cluster,flink,stop,flink,null,file,files,savepoint,root,dir,list,files,if,files,null,assert,equals,savepoint,not,created,in,expected,directory,1,files,length,assert,true,savepoint,did,not,create,self,contained,directory,files,0,is,directory,file,savepoint,dir,files,0,file,savepoint,files,savepoint,dir,list,files,assert,not,null,savepoint,files,string,err,msg,did,not,write,expected,number,of,savepoint,checkpoint,files,to,directory,arrays,to,string,savepoint,files,assert,equals,err,msg,1,parallelism,savepoint,files,length,else,fail,savepoint,not,created,in,expected,directory,file,job,checkpoints,new,file,checkpoint,dir,job,id,to,string,if,job,checkpoints,exists,files,job,checkpoints,list,files,assert,not,null,checkpoint,directory,empty,files,assert,equals,checkpoints,directory,not,clean,arrays,to,string,files,0,files,length,log,info,restarting,flink,cluster,flink,new,testing,cluster,config,flink,start,log,info,retrieving,job,manager,job,manager,await,result,flink,leader,gateway,future,deadline,time,left,log,info,job,manager,job,manager,stateful,counter,reset,for,test,parallelism,final,throwable,error,new,throwable,1,final,testing,cluster,final,flink,flink,final,multimap,job,vertex,id,task,deployment,descriptor,tdds,hash,multimap,create,new,java,test,kit,test,actor,system,new,within,deadline,time,left,override,protected,void,run,try,for,actor,ref,task,manager,final,flink,get,task,managers,as,java,task,manager,tell,new,testing,task,manager,messages,register,submit,task,listener,job,id,get,test,actor,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,log,info,resubmitting,job,job,graph,get,job,id,with,savepoint,path,savepoint,path,in,detached,mode,final,flink,submit,job,detached,job,graph,int,num,tasks,0,for,job,vertex,job,vertex,job,graph,get,vertices,num,tasks,job,vertex,get,parallelism,log,info,gathering,num,tasks,submitted,task,deployment,descriptor,instances,for,int,i,0,i,num,tasks,i,response,submit,task,listener,resp,response,submit,task,listener,expect,msg,any,class,of,get,remaining,time,response,submit,task,listener,class,task,deployment,descriptor,tdd,resp,tdd,log,info,received,tdd,to,string,task,information,task,information,tdd,get,serialized,task,information,deserialize,value,get,class,get,class,loader,tdds,put,task,information,get,job,vertex,id,tdd,catch,throwable,t,error,0,t,execution,graph,graph,execution,graph,job,manager,messages,job,found,await,result,job,manager,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,deadline,time,left,execution,graph,string,err,msg,error,during,gathering,of,task,deployment,descriptors,if,error,0,null,throw,new,runtime,exception,error,0,map,operator,id,tuple2,integer,execution,job,vertex,operator,to,job,vertex,mapping,new,hash,map,for,execution,job,vertex,task,graph,get,vertices,topologically,list,operator,id,operator,ids,task,get,operator,ids,for,int,x,0,x,operator,ids,size,x,operator,to,job,vertex,mapping,put,operator,ids,get,x,new,tuple2,x,task,for,operator,state,operator,state,savepoint,get,operator,states,tuple2,integer,execution,job,vertex,chain,index,and,job,vertex,operator,to,job,vertex,mapping,get,operator,state,get,operator,id,collection,task,deployment,descriptor,task,tdds,tdds,get,chain,index,and,job,vertex,f1,get,job,vertex,id,err,msg,missing,task,for,savepoint,state,for,operator,operator,state,get,operator,id,assert,true,err,msg,task,tdds,size,0,assert,equals,operator,state,get,number,collected,states,task,tdds,size,for,task,deployment,descriptor,tdd,task,tdds,operator,subtask,state,subtask,state,operator,state,get,state,tdd,get,subtask,index,assert,not,null,subtask,state,stateful,counter,get,restore,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,stateful,counter,get,progress,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,log,info,cancelling,job,job,id,job,manager,tell,new,cancel,job,job,id,log,info,disposing,savepoint,savepoint,path,future,object,dispose,future,job,manager,ask,new,dispose,savepoint,savepoint,path,deadline,time,left,err,msg,failed,to,dispose,savepoint,savepoint,path,object,resp,await,result,dispose,future,deadline,time,left,assert,true,err,msg,resp,get,class,get,dispose,savepoint,success,get,class,list,file,checkpoint,files,new,array,list,for,operator,state,state,for,task,group,savepoint,get,operator,states,for,operator,subtask,state,subtask,state,state,for,task,group,get,states,collection,operator,state,handle,stream,task,state,subtask,state,get,managed,operator,state,if,stream,task,state,null,stream,task,state,is,empty,for,operator,state,handle,osh,stream,task,state,file,state,handle,file,state,handle,file,state,handle,osh,get,delegate,state,handle,checkpoint,files,add,new,file,file,state,handle,get,file,path,to,uri,for,file,f,checkpoint,files,err,msg,checkpoint,file,f,not,cleaned,up,properly,assert,false,err,msg,f,exists,if,checkpoint,files,size,0,file,parent,checkpoint,files,get,0,get,parent,file,err,msg,checkpoint,parent,directory,parent,not,cleaned,up,properly,assert,false,err,msg,parent,exists,err,msg,savepoints,directory,not,cleaned,up,properly,arrays,to,string,savepoint,root,dir,list,files,assert,equals,err,msg,0,savepoint,root,dir,list,files,length,finally,if,flink,null,flink,stop
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1518245533;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final File testRoot = folder.newFolder()___		Configuration config = new Configuration()___		final File checkpointDir = new File(testRoot, "checkpoints")__		final File savepointRootDir = new File(testRoot, "savepoints")___		if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_			fail("Test setup failed: failed to create temporary directories.")__		}__		_		config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem")__		config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString())__		config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0)__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___		MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(numTaskManagers, numSlotsPerTaskManager, config)___		String savepointPath = submitJobAndGetVerifiedSavepoint(clusterFactory, parallelism)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,file,test,root,folder,new,folder,configuration,config,new,configuration,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,checkpointing,options,filesystem,config,set,string,checkpointing,options,checkpoint,dir,to,uri,to,string,config,set,integer,checkpointing,options,0,config,set,string,checkpointing,options,savepoint,root,dir,to,uri,to,string,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,config,string,savepoint,path,submit,job,and,get,verified,savepoint,cluster,factory,parallelism,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1522154703;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final File testRoot = folder.newFolder()___		Configuration config = new Configuration()___		final File checkpointDir = new File(testRoot, "checkpoints")__		final File savepointRootDir = new File(testRoot, "savepoints")___		if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_			fail("Test setup failed: failed to create temporary directories.")__		}__		_		config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem")__		config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString())__		config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0)__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___		MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(numTaskManagers, numSlotsPerTaskManager, config)___		String savepointPath = submitJobAndGetVerifiedSavepoint(clusterFactory, parallelism)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,file,test,root,folder,new,folder,configuration,config,new,configuration,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,checkpointing,options,filesystem,config,set,string,checkpointing,options,checkpoint,dir,to,uri,to,string,config,set,integer,checkpointing,options,0,config,set,string,checkpointing,options,savepoint,root,dir,to,uri,to,string,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,config,string,savepoint,path,submit,job,and,get,verified,savepoint,cluster,factory,parallelism,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1527089094;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final File testRoot = folder.newFolder()___		Configuration config = new Configuration()___		final File checkpointDir = new File(testRoot, "checkpoints")__		final File savepointRootDir = new File(testRoot, "savepoints")___		if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_			fail("Test setup failed: failed to create temporary directories.")__		}__		_		config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem")__		config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString())__		config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0)__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___		MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(numTaskManagers, numSlotsPerTaskManager, config)___		String savepointPath = submitJobAndGetVerifiedSavepoint(clusterFactory, parallelism)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,file,test,root,folder,new,folder,configuration,config,new,configuration,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,checkpointing,options,filesystem,config,set,string,checkpointing,options,checkpoint,dir,to,uri,to,string,config,set,integer,checkpointing,options,0,config,set,string,checkpointing,options,savepoint,root,dir,to,uri,to,string,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,config,string,savepoint,path,submit,job,and,get,verified,savepoint,cluster,factory,parallelism,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1529585865;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final File testRoot = folder.newFolder()___		Configuration config = new Configuration()___		final File checkpointDir = new File(testRoot, "checkpoints")__		final File savepointRootDir = new File(testRoot, "savepoints")___		if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_			fail("Test setup failed: failed to create temporary directories.")__		}__		_		config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem")__		config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString())__		config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0)__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___		MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(numTaskManagers, numSlotsPerTaskManager, config)___		String savepointPath = submitJobAndGetVerifiedSavepoint(clusterFactory, parallelism)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,file,test,root,folder,new,folder,configuration,config,new,configuration,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,checkpointing,options,filesystem,config,set,string,checkpointing,options,checkpoint,dir,to,uri,to,string,config,set,integer,checkpointing,options,0,config,set,string,checkpointing,options,savepoint,root,dir,to,uri,to,string,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,config,string,savepoint,path,submit,job,and,get,verified,savepoint,cluster,factory,parallelism,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1529586951;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final File testRoot = folder.newFolder()___		Configuration config = new Configuration()___		final File checkpointDir = new File(testRoot, "checkpoints")__		final File savepointRootDir = new File(testRoot, "savepoints")___		if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_			fail("Test setup failed: failed to create temporary directories.")__		}__		_		config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem")__		config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString())__		config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0)__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___		MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(numTaskManagers, numSlotsPerTaskManager, config)___		String savepointPath = submitJobAndGetVerifiedSavepoint(clusterFactory, parallelism)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,file,test,root,folder,new,folder,configuration,config,new,configuration,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,checkpointing,options,filesystem,config,set,string,checkpointing,options,checkpoint,dir,to,uri,to,string,config,set,integer,checkpointing,options,0,config,set,string,checkpointing,options,savepoint,root,dir,to,uri,to,string,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,config,string,savepoint,path,submit,job,and,get,verified,savepoint,cluster,factory,parallelism,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1531820069;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final File testRoot = folder.newFolder()___		Configuration config = new Configuration()___		final File checkpointDir = new File(testRoot, "checkpoints")__		final File savepointRootDir = new File(testRoot, "savepoints")___		if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_			fail("Test setup failed: failed to create temporary directories.")__		}__		_		config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem")__		config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString())__		config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0)__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___		MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(numTaskManagers, numSlotsPerTaskManager, config)___		String savepointPath = submitJobAndGetVerifiedSavepoint(clusterFactory, parallelism)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,file,test,root,folder,new,folder,configuration,config,new,configuration,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,checkpointing,options,filesystem,config,set,string,checkpointing,options,checkpoint,dir,to,uri,to,string,config,set,integer,checkpointing,options,0,config,set,string,checkpointing,options,savepoint,root,dir,to,uri,to,string,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,config,string,savepoint,path,submit,job,and,get,verified,savepoint,cluster,factory,parallelism,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1539371200;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final File testRoot = folder.newFolder()___		Configuration config = new Configuration()___		final File checkpointDir = new File(testRoot, "checkpoints")__		final File savepointRootDir = new File(testRoot, "savepoints")___		if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_			fail("Test setup failed: failed to create temporary directories.")__		}__		_		config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem")__		config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString())__		config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0)__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___		MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(numTaskManagers, numSlotsPerTaskManager, config)___		String savepointPath = submitJobAndGetVerifiedSavepoint(clusterFactory, parallelism)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,file,test,root,folder,new,folder,configuration,config,new,configuration,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,checkpointing,options,filesystem,config,set,string,checkpointing,options,checkpoint,dir,to,uri,to,string,config,set,integer,checkpointing,options,0,config,set,string,checkpointing,options,savepoint,root,dir,to,uri,to,string,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,config,string,savepoint,path,submit,job,and,get,verified,savepoint,cluster,factory,parallelism,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1540216840;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager__		final File testRoot = folder.newFolder()___		Configuration config = new Configuration()___		final File checkpointDir = new File(testRoot, "checkpoints")__		final File savepointRootDir = new File(testRoot, "savepoints")___		if (!checkpointDir.mkdir() || !savepointRootDir.mkdirs()) {_			fail("Test setup failed: failed to create temporary directories.")__		}__		_		config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem")__		config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString())__		config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0)__		config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointRootDir.toURI().toString())___		MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(numTaskManagers, numSlotsPerTaskManager, config)___		String savepointPath = submitJobAndGetVerifiedSavepoint(clusterFactory, parallelism)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,file,test,root,folder,new,folder,configuration,config,new,configuration,final,file,checkpoint,dir,new,file,test,root,checkpoints,final,file,savepoint,root,dir,new,file,test,root,savepoints,if,checkpoint,dir,mkdir,savepoint,root,dir,mkdirs,fail,test,setup,failed,failed,to,create,temporary,directories,config,set,string,checkpointing,options,filesystem,config,set,string,checkpointing,options,checkpoint,dir,to,uri,to,string,config,set,integer,checkpointing,options,0,config,set,string,checkpointing,options,savepoint,root,dir,to,uri,to,string,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,config,string,savepoint,path,submit,job,and,get,verified,savepoint,cluster,factory,parallelism,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1542192035;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager___		final MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(_			numTaskManagers,_			numSlotsPerTaskManager,_			getFileBasedCheckpointsConfig())___		final String savepointPath = submitJobAndTakeSavepoint(clusterFactory, parallelism)__		verifySavepoint(parallelism, savepointPath)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,get,file,based,checkpoints,config,final,string,savepoint,path,submit,job,and,take,savepoint,cluster,factory,parallelism,verify,savepoint,parallelism,savepoint,path,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1542279564;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager___		final MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(_			numTaskManagers,_			numSlotsPerTaskManager,_			getFileBasedCheckpointsConfig())___		final String savepointPath = submitJobAndTakeSavepoint(clusterFactory, parallelism)__		verifySavepoint(parallelism, savepointPath)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,get,file,based,checkpoints,config,final,string,savepoint,path,submit,job,and,take,savepoint,cluster,factory,parallelism,verify,savepoint,parallelism,savepoint,path,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> @Test 	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception;1550075375;Triggers a savepoint for a job that uses the FsStateBackend. We expect_that all checkpoint files are written to a new savepoint directory.__<ol>_<li>Submit job, wait for some progress</li>_<li>Trigger savepoint and verify that savepoint has been created</li>_<li>Shut down the cluster, re-submit the job from the savepoint,_verify that the initial state has been reset, and_all tasks are running again</li>_<li>Cancel job, dispose the savepoint, and verify that everything_has been cleaned up</li>_</ol>;@Test_	public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {_		final int numTaskManagers = 2__		final int numSlotsPerTaskManager = 2__		final int parallelism = numTaskManagers * numSlotsPerTaskManager___		final MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(_			numTaskManagers,_			numSlotsPerTaskManager,_			getFileBasedCheckpointsConfig())___		final String savepointPath = submitJobAndTakeSavepoint(clusterFactory, parallelism)__		verifySavepoint(parallelism, savepointPath)___		restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism)__	};triggers,a,savepoint,for,a,job,that,uses,the,fs,state,backend,we,expect,that,all,checkpoint,files,are,written,to,a,new,savepoint,directory,ol,li,submit,job,wait,for,some,progress,li,li,trigger,savepoint,and,verify,that,savepoint,has,been,created,li,li,shut,down,the,cluster,re,submit,the,job,from,the,savepoint,verify,that,the,initial,state,has,been,reset,and,all,tasks,are,running,again,li,li,cancel,job,dispose,the,savepoint,and,verify,that,everything,has,been,cleaned,up,li,ol;test,public,void,test,trigger,savepoint,and,resume,with,file,based,checkpoints,throws,exception,final,int,num,task,managers,2,final,int,num,slots,per,task,manager,2,final,int,parallelism,num,task,managers,num,slots,per,task,manager,final,mini,cluster,resource,factory,cluster,factory,new,mini,cluster,resource,factory,num,task,managers,num,slots,per,task,manager,get,file,based,checkpoints,config,final,string,savepoint,path,submit,job,and,take,savepoint,cluster,factory,parallelism,verify,savepoint,parallelism,savepoint,path,restore,job,and,verify,state,savepoint,path,cluster,factory,parallelism
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			int checkpointingInterval);1448992027;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.setNumberOfExecutionRetries(numberOfRetries)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		_		stream.addSink(new SinkFunction<Integer>() {_			private static final long serialVersionUID = -8671189807690005893L__			@Override_			public void invoke(Integer value) throws Exception {_			}_		})___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,set,number,of,execution,retries,number,of,retries,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,sink,function,integer,private,static,final,long,serial,version,uid,8671189807690005893l,override,public,void,invoke,integer,value,throws,exception,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			int checkpointingInterval);1450188912;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.setNumberOfExecutionRetries(numberOfRetries)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		_		stream.addSink(new SinkFunction<Integer>() {_			private static final long serialVersionUID = -8671189807690005893L__			@Override_			public void invoke(Integer value) throws Exception {_			}_		})___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,set,number,of,execution,retries,number,of,retries,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,sink,function,integer,private,static,final,long,serial,version,uid,8671189807690005893l,override,public,void,invoke,integer,value,throws,exception,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			int checkpointingInterval);1453721631;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.setNumberOfExecutionRetries(numberOfRetries)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		_		stream.addSink(new SinkFunction<Integer>() {_			private static final long serialVersionUID = -8671189807690005893L__			@Override_			public void invoke(Integer value) throws Exception {_			}_		})___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,set,number,of,execution,retries,number,of,retries,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,sink,function,integer,private,static,final,long,serial,version,uid,8671189807690005893l,override,public,void,invoke,integer,value,throws,exception,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			int checkpointingInterval);1455203606;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.setNumberOfExecutionRetries(numberOfRetries)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		_		stream.addSink(new SinkFunction<Integer>() {_			private static final long serialVersionUID = -8671189807690005893L__			@Override_			public void invoke(Integer value) throws Exception {_			}_		})___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,set,number,of,execution,retries,number,of,retries,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,sink,function,integer,private,static,final,long,serial,version,uid,8671189807690005893l,override,public,void,invoke,integer,value,throws,exception,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1450356550;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		_		stream.addSink(new SinkFunction<Integer>() {_			private static final long serialVersionUID = -8671189807690005893L__			@Override_			public void invoke(Integer value) throws Exception {_			}_		})___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,sink,function,integer,private,static,final,long,serial,version,uid,8671189807690005893l,override,public,void,invoke,integer,value,throws,exception,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1455203048;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		_		stream.addSink(new SinkFunction<Integer>() {_			private static final long serialVersionUID = -8671189807690005893L__			@Override_			public void invoke(Integer value) throws Exception {_			}_		})___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,sink,function,integer,private,static,final,long,serial,version,uid,8671189807690005893l,override,public,void,invoke,integer,value,throws,exception,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1455311369;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1456487167;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1457706031;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1459778142;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1460121606;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1465376364;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1466083944;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1467296201;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1470909547;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1470937207;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1472659089;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1473856047;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1474899711;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1475571578;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1475765022;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1475833727;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1477497926;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1478686523;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> private JobGraph createJobGraph( 			int parallelism, 			int numberOfRetries, 			long restartDelay, 			int checkpointingInterval);1478715096;Creates a streaming JobGraph from the StreamEnvironment.;private JobGraph createJobGraph(_			int parallelism,_			int numberOfRetries,_			long restartDelay,_			int checkpointingInterval) {__		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(parallelism)__		env.enableCheckpointing(checkpointingInterval)__		env.disableOperatorChaining()__		env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay))__		env.getConfig().disableSysoutLogging()___		DataStream<Integer> stream = env_				.addSource(new InfiniteTestSource())_				.shuffle()_				.map(new StatefulCounter())___		stream.addSink(new DiscardingSink<Integer>())___		return env.getStreamGraph().getJobGraph()__	};creates,a,streaming,job,graph,from,the,stream,environment;private,job,graph,create,job,graph,int,parallelism,int,number,of,retries,long,restart,delay,int,checkpointing,interval,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,parallelism,env,enable,checkpointing,checkpointing,interval,env,disable,operator,chaining,env,get,config,set,restart,strategy,restart,strategies,fixed,delay,restart,number,of,retries,restart,delay,env,get,config,disable,sysout,logging,data,stream,integer,stream,env,add,source,new,infinite,test,source,shuffle,map,new,stateful,counter,stream,add,sink,new,discarding,sink,integer,return,env,get,stream,graph,get,job,graph
SavepointITCase -> @Test 	public void testRestoreFailure() throws Exception;1455311369;Tests that a restore failure is retried with the savepoint state.;@Test_	public void testRestoreFailure() throws Exception {_		_		int numTaskManagers = 1__		int numSlotsPerTaskManager = 1__		int numExecutionRetries = 2__		int retryDelay = 500__		int checkpointingInterval = 100000000___		_		final Deadline deadline = new FiniteDuration(3, TimeUnit.MINUTES).fromNow()___		ForkableFlinkMiniCluster flink = null___		try {_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(1)__			env.enableCheckpointing(checkpointingInterval)__			env.setNumberOfExecutionRetries(numExecutionRetries)__			env.getConfig().setExecutionRetryDelay(retryDelay)___			DataStream<Integer> stream = env_					.addSource(new RestoreStateCountingAndFailingSource())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = false__			RestoreStateCountingAndFailingSource.numRestoreStateCalls = 0__			RestoreStateCountingAndFailingSource.checkpointCompleteLatch = new CountDownLatch(1)__			RestoreStateCountingAndFailingSource.emitted= 0___			stream.addSink(new DiscardingSink<Integer>())___			JobGraph jobGraph = env.getStreamGraph().getJobGraph()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = flink.getLeaderGateway(deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			flink.submitJobDetached(jobGraph)___			while (deadline.hasTimeLeft() && RestoreStateCountingAndFailingSource.emitted < 100) {_				Thread.sleep(100)__			}__			assertTrue("No progress", RestoreStateCountingAndFailingSource.emitted >= 100)___			_			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobGraph.getJobID()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			RestoreStateCountingAndFailingSource.checkpointCompleteLatch.await()___			_			Future<?> cancelFuture = jobManager.ask(new CancelJob(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(cancelFuture, deadline.timeLeft())___			_			Future<?> removedFuture = jobManager.ask(new NotifyWhenJobRemoved(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(removedFuture, deadline.timeLeft())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = true__			jobGraph.setSavepointPath(savepointPath)___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				_				_				fail("Did not throw expected Exception")__			} catch (Exception ignored) {_			} finally {_				_				_				assertEquals(1 + numExecutionRetries, RestoreStateCountingAndFailingSource.numRestoreStateCalls)__			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};tests,that,a,restore,failure,is,retried,with,the,savepoint,state;test,public,void,test,restore,failure,throws,exception,int,num,task,managers,1,int,num,slots,per,task,manager,1,int,num,execution,retries,2,int,retry,delay,500,int,checkpointing,interval,100000000,final,deadline,deadline,new,finite,duration,3,time,unit,minutes,from,now,forkable,flink,mini,cluster,flink,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,1,env,enable,checkpointing,checkpointing,interval,env,set,number,of,execution,retries,num,execution,retries,env,get,config,set,execution,retry,delay,retry,delay,data,stream,integer,stream,env,add,source,new,restore,state,counting,and,failing,source,restore,state,counting,and,failing,source,fail,on,restore,state,call,false,restore,state,counting,and,failing,source,num,restore,state,calls,0,restore,state,counting,and,failing,source,checkpoint,complete,latch,new,count,down,latch,1,restore,state,counting,and,failing,source,emitted,0,stream,add,sink,new,discarding,sink,integer,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,flink,get,leader,gateway,deadline,time,left,log,info,job,manager,job,manager,flink,submit,job,detached,job,graph,while,deadline,has,time,left,restore,state,counting,and,failing,source,emitted,100,thread,sleep,100,assert,true,no,progress,restore,state,counting,and,failing,source,emitted,100,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,graph,get,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,restore,state,counting,and,failing,source,checkpoint,complete,latch,await,future,cancel,future,job,manager,ask,new,cancel,job,job,graph,get,job,id,deadline,time,left,await,ready,cancel,future,deadline,time,left,future,removed,future,job,manager,ask,new,notify,when,job,removed,job,graph,get,job,id,deadline,time,left,await,ready,removed,future,deadline,time,left,restore,state,counting,and,failing,source,fail,on,restore,state,call,true,job,graph,set,savepoint,path,savepoint,path,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,catch,exception,ignored,finally,assert,equals,1,num,execution,retries,restore,state,counting,and,failing,source,num,restore,state,calls,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testRestoreFailure() throws Exception;1456487167;Tests that a restore failure is retried with the savepoint state.;@Test_	public void testRestoreFailure() throws Exception {_		_		int numTaskManagers = 1__		int numSlotsPerTaskManager = 1__		int numExecutionRetries = 2__		int retryDelay = 500__		int checkpointingInterval = 100000000___		_		final Deadline deadline = new FiniteDuration(3, TimeUnit.MINUTES).fromNow()___		ForkableFlinkMiniCluster flink = null___		try {_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(1)__			env.enableCheckpointing(checkpointingInterval)__			env.setNumberOfExecutionRetries(numExecutionRetries)__			env.getConfig().setExecutionRetryDelay(retryDelay)___			DataStream<Integer> stream = env_					.addSource(new RestoreStateCountingAndFailingSource())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = false__			RestoreStateCountingAndFailingSource.numRestoreStateCalls = 0__			RestoreStateCountingAndFailingSource.checkpointCompleteLatch = new CountDownLatch(1)__			RestoreStateCountingAndFailingSource.emitted= 0___			stream.addSink(new DiscardingSink<Integer>())___			JobGraph jobGraph = env.getStreamGraph().getJobGraph()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = flink.getLeaderGateway(deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			flink.submitJobDetached(jobGraph)___			while (deadline.hasTimeLeft() && RestoreStateCountingAndFailingSource.emitted < 100) {_				Thread.sleep(100)__			}__			assertTrue("No progress", RestoreStateCountingAndFailingSource.emitted >= 100)___			_			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobGraph.getJobID()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			RestoreStateCountingAndFailingSource.checkpointCompleteLatch.await()___			_			Future<?> cancelFuture = jobManager.ask(new CancelJob(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(cancelFuture, deadline.timeLeft())___			_			Future<?> removedFuture = jobManager.ask(new NotifyWhenJobRemoved(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(removedFuture, deadline.timeLeft())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = true__			jobGraph.setSavepointPath(savepointPath)___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				_				_				fail("Did not throw expected Exception")__			} catch (Exception ignored) {_			} finally {_				_				_				assertEquals(1 + numExecutionRetries, RestoreStateCountingAndFailingSource.numRestoreStateCalls)__			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};tests,that,a,restore,failure,is,retried,with,the,savepoint,state;test,public,void,test,restore,failure,throws,exception,int,num,task,managers,1,int,num,slots,per,task,manager,1,int,num,execution,retries,2,int,retry,delay,500,int,checkpointing,interval,100000000,final,deadline,deadline,new,finite,duration,3,time,unit,minutes,from,now,forkable,flink,mini,cluster,flink,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,1,env,enable,checkpointing,checkpointing,interval,env,set,number,of,execution,retries,num,execution,retries,env,get,config,set,execution,retry,delay,retry,delay,data,stream,integer,stream,env,add,source,new,restore,state,counting,and,failing,source,restore,state,counting,and,failing,source,fail,on,restore,state,call,false,restore,state,counting,and,failing,source,num,restore,state,calls,0,restore,state,counting,and,failing,source,checkpoint,complete,latch,new,count,down,latch,1,restore,state,counting,and,failing,source,emitted,0,stream,add,sink,new,discarding,sink,integer,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,flink,get,leader,gateway,deadline,time,left,log,info,job,manager,job,manager,flink,submit,job,detached,job,graph,while,deadline,has,time,left,restore,state,counting,and,failing,source,emitted,100,thread,sleep,100,assert,true,no,progress,restore,state,counting,and,failing,source,emitted,100,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,graph,get,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,restore,state,counting,and,failing,source,checkpoint,complete,latch,await,future,cancel,future,job,manager,ask,new,cancel,job,job,graph,get,job,id,deadline,time,left,await,ready,cancel,future,deadline,time,left,future,removed,future,job,manager,ask,new,notify,when,job,removed,job,graph,get,job,id,deadline,time,left,await,ready,removed,future,deadline,time,left,restore,state,counting,and,failing,source,fail,on,restore,state,call,true,job,graph,set,savepoint,path,savepoint,path,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,catch,exception,ignored,finally,assert,equals,1,num,execution,retries,restore,state,counting,and,failing,source,num,restore,state,calls,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testRestoreFailure() throws Exception;1457706031;Tests that a restore failure is retried with the savepoint state.;@Test_	public void testRestoreFailure() throws Exception {_		_		int numTaskManagers = 1__		int numSlotsPerTaskManager = 1__		int numExecutionRetries = 2__		int retryDelay = 500__		int checkpointingInterval = 100000000___		_		final Deadline deadline = new FiniteDuration(3, TimeUnit.MINUTES).fromNow()___		ForkableFlinkMiniCluster flink = null___		try {_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(1)__			env.enableCheckpointing(checkpointingInterval)__			env.setNumberOfExecutionRetries(numExecutionRetries)__			env.getConfig().setExecutionRetryDelay(retryDelay)___			DataStream<Integer> stream = env_					.addSource(new RestoreStateCountingAndFailingSource())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = false__			RestoreStateCountingAndFailingSource.numRestoreStateCalls = 0__			RestoreStateCountingAndFailingSource.checkpointCompleteLatch = new CountDownLatch(1)__			RestoreStateCountingAndFailingSource.emitted= 0___			stream.addSink(new DiscardingSink<Integer>())___			JobGraph jobGraph = env.getStreamGraph().getJobGraph()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = flink.getLeaderGateway(deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			flink.submitJobDetached(jobGraph)___			while (deadline.hasTimeLeft() && RestoreStateCountingAndFailingSource.emitted < 100) {_				Thread.sleep(100)__			}__			assertTrue("No progress", RestoreStateCountingAndFailingSource.emitted >= 100)___			_			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobGraph.getJobID()), deadline.timeLeft())___			final String savepointPath = ((TriggerSavepointSuccess) Await_					.result(savepointPathFuture, deadline.timeLeft())).savepointPath()__			LOG.info("Retrieved savepoint path: " + savepointPath + ".")___			_			RestoreStateCountingAndFailingSource.checkpointCompleteLatch.await()___			_			Future<?> cancelFuture = jobManager.ask(new CancelJob(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(cancelFuture, deadline.timeLeft())___			_			Future<?> removedFuture = jobManager.ask(new NotifyWhenJobRemoved(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(removedFuture, deadline.timeLeft())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = true__			jobGraph.setSavepointPath(savepointPath)___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				_				_				fail("Did not throw expected Exception")__			} catch (Exception ignored) {_			} finally {_				_				_				assertEquals(1 + numExecutionRetries, RestoreStateCountingAndFailingSource.numRestoreStateCalls)__			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};tests,that,a,restore,failure,is,retried,with,the,savepoint,state;test,public,void,test,restore,failure,throws,exception,int,num,task,managers,1,int,num,slots,per,task,manager,1,int,num,execution,retries,2,int,retry,delay,500,int,checkpointing,interval,100000000,final,deadline,deadline,new,finite,duration,3,time,unit,minutes,from,now,forkable,flink,mini,cluster,flink,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,1,env,enable,checkpointing,checkpointing,interval,env,set,number,of,execution,retries,num,execution,retries,env,get,config,set,execution,retry,delay,retry,delay,data,stream,integer,stream,env,add,source,new,restore,state,counting,and,failing,source,restore,state,counting,and,failing,source,fail,on,restore,state,call,false,restore,state,counting,and,failing,source,num,restore,state,calls,0,restore,state,counting,and,failing,source,checkpoint,complete,latch,new,count,down,latch,1,restore,state,counting,and,failing,source,emitted,0,stream,add,sink,new,discarding,sink,integer,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,flink,get,leader,gateway,deadline,time,left,log,info,job,manager,job,manager,flink,submit,job,detached,job,graph,while,deadline,has,time,left,restore,state,counting,and,failing,source,emitted,100,thread,sleep,100,assert,true,no,progress,restore,state,counting,and,failing,source,emitted,100,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,graph,get,job,id,deadline,time,left,final,string,savepoint,path,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,restore,state,counting,and,failing,source,checkpoint,complete,latch,await,future,cancel,future,job,manager,ask,new,cancel,job,job,graph,get,job,id,deadline,time,left,await,ready,cancel,future,deadline,time,left,future,removed,future,job,manager,ask,new,notify,when,job,removed,job,graph,get,job,id,deadline,time,left,await,ready,removed,future,deadline,time,left,restore,state,counting,and,failing,source,fail,on,restore,state,call,true,job,graph,set,savepoint,path,savepoint,path,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,catch,exception,ignored,finally,assert,equals,1,num,execution,retries,restore,state,counting,and,failing,source,num,restore,state,calls,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testRestoreFailure() throws Exception;1459778142;Tests that a restore failure is retried with the savepoint state.;@Test_	public void testRestoreFailure() throws Exception {_		_		int numTaskManagers = 1__		int numSlotsPerTaskManager = 1__		int numExecutionRetries = 2__		int retryDelay = 500__		int checkpointingInterval = 100000000___		_		final Deadline deadline = new FiniteDuration(3, TimeUnit.MINUTES).fromNow()___		ForkableFlinkMiniCluster flink = null___		try {_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(1)__			env.enableCheckpointing(checkpointingInterval)__			env.setNumberOfExecutionRetries(numExecutionRetries)__			env.getConfig().setExecutionRetryDelay(retryDelay)___			DataStream<Integer> stream = env_					.addSource(new RestoreStateCountingAndFailingSource())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = false__			RestoreStateCountingAndFailingSource.numRestoreStateCalls = 0__			RestoreStateCountingAndFailingSource.checkpointCompleteLatch = new CountDownLatch(1)__			RestoreStateCountingAndFailingSource.emitted= 0___			stream.addSink(new DiscardingSink<Integer>())___			JobGraph jobGraph = env.getStreamGraph().getJobGraph()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = flink.getLeaderGateway(deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			flink.submitJobDetached(jobGraph)___			while (deadline.hasTimeLeft() && RestoreStateCountingAndFailingSource.emitted < 100) {_				Thread.sleep(100)__			}__			assertTrue("No progress", RestoreStateCountingAndFailingSource.emitted >= 100)___			_			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobGraph.getJobID()), deadline.timeLeft())___			Object resp = Await.result(savepointPathFuture, deadline.timeLeft())___			String savepointPath = null__			if (resp instanceof TriggerSavepointSuccess) {_				savepointPath = ((TriggerSavepointSuccess) resp).savepointPath()__				LOG.info("Retrieved savepoint path: " + savepointPath + ".")__			} else if (resp instanceof TriggerSavepointFailure) {_				fail("Received TriggerSavepointFailure: " + ((TriggerSavepointFailure) resp).cause().getMessage())__			} else {_				fail("Unexpected response of type  " + resp.getClass() + " " + resp)__			}__			_			RestoreStateCountingAndFailingSource.checkpointCompleteLatch.await()___			_			Future<?> cancelFuture = jobManager.ask(new CancelJob(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(cancelFuture, deadline.timeLeft())___			_			Future<?> removedFuture = jobManager.ask(new NotifyWhenJobRemoved(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(removedFuture, deadline.timeLeft())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = true__			jobGraph.setSavepointPath(savepointPath)___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				_				_				fail("Did not throw expected Exception")__			} catch (Exception ignored) {_			} finally {_				_				_				assertEquals(1 + numExecutionRetries, RestoreStateCountingAndFailingSource.numRestoreStateCalls)__			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};tests,that,a,restore,failure,is,retried,with,the,savepoint,state;test,public,void,test,restore,failure,throws,exception,int,num,task,managers,1,int,num,slots,per,task,manager,1,int,num,execution,retries,2,int,retry,delay,500,int,checkpointing,interval,100000000,final,deadline,deadline,new,finite,duration,3,time,unit,minutes,from,now,forkable,flink,mini,cluster,flink,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,1,env,enable,checkpointing,checkpointing,interval,env,set,number,of,execution,retries,num,execution,retries,env,get,config,set,execution,retry,delay,retry,delay,data,stream,integer,stream,env,add,source,new,restore,state,counting,and,failing,source,restore,state,counting,and,failing,source,fail,on,restore,state,call,false,restore,state,counting,and,failing,source,num,restore,state,calls,0,restore,state,counting,and,failing,source,checkpoint,complete,latch,new,count,down,latch,1,restore,state,counting,and,failing,source,emitted,0,stream,add,sink,new,discarding,sink,integer,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,flink,get,leader,gateway,deadline,time,left,log,info,job,manager,job,manager,flink,submit,job,detached,job,graph,while,deadline,has,time,left,restore,state,counting,and,failing,source,emitted,100,thread,sleep,100,assert,true,no,progress,restore,state,counting,and,failing,source,emitted,100,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,graph,get,job,id,deadline,time,left,object,resp,await,result,savepoint,path,future,deadline,time,left,string,savepoint,path,null,if,resp,instanceof,trigger,savepoint,success,savepoint,path,trigger,savepoint,success,resp,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,else,if,resp,instanceof,trigger,savepoint,failure,fail,received,trigger,savepoint,failure,trigger,savepoint,failure,resp,cause,get,message,else,fail,unexpected,response,of,type,resp,get,class,resp,restore,state,counting,and,failing,source,checkpoint,complete,latch,await,future,cancel,future,job,manager,ask,new,cancel,job,job,graph,get,job,id,deadline,time,left,await,ready,cancel,future,deadline,time,left,future,removed,future,job,manager,ask,new,notify,when,job,removed,job,graph,get,job,id,deadline,time,left,await,ready,removed,future,deadline,time,left,restore,state,counting,and,failing,source,fail,on,restore,state,call,true,job,graph,set,savepoint,path,savepoint,path,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,catch,exception,ignored,finally,assert,equals,1,num,execution,retries,restore,state,counting,and,failing,source,num,restore,state,calls,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testRestoreFailure() throws Exception;1460121606;Tests that a restore failure is retried with the savepoint state.;@Test_	public void testRestoreFailure() throws Exception {_		_		int numTaskManagers = 1__		int numSlotsPerTaskManager = 1__		int numExecutionRetries = 2__		int retryDelay = 500__		int checkpointingInterval = 100000000___		_		final Deadline deadline = new FiniteDuration(3, TimeUnit.MINUTES).fromNow()___		ForkableFlinkMiniCluster flink = null___		try {_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(1)__			env.enableCheckpointing(checkpointingInterval)__			env.setNumberOfExecutionRetries(numExecutionRetries)__			env.getConfig().setExecutionRetryDelay(retryDelay)___			DataStream<Integer> stream = env_					.addSource(new RestoreStateCountingAndFailingSource())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = false__			RestoreStateCountingAndFailingSource.numRestoreStateCalls = 0__			RestoreStateCountingAndFailingSource.checkpointCompleteLatch = new CountDownLatch(1)__			RestoreStateCountingAndFailingSource.emitted= 0___			stream.addSink(new DiscardingSink<Integer>())___			JobGraph jobGraph = env.getStreamGraph().getJobGraph()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = flink.getLeaderGateway(deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			flink.submitJobDetached(jobGraph)___			while (deadline.hasTimeLeft() && RestoreStateCountingAndFailingSource.emitted < 100) {_				Thread.sleep(100)__			}__			assertTrue("No progress", RestoreStateCountingAndFailingSource.emitted >= 100)___			_			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobGraph.getJobID()), deadline.timeLeft())___			Object resp = Await.result(savepointPathFuture, deadline.timeLeft())___			String savepointPath = null__			if (resp instanceof TriggerSavepointSuccess) {_				savepointPath = ((TriggerSavepointSuccess) resp).savepointPath()__				LOG.info("Retrieved savepoint path: " + savepointPath + ".")__			} else if (resp instanceof TriggerSavepointFailure) {_				fail("Received TriggerSavepointFailure: " + ((TriggerSavepointFailure) resp).cause().getMessage())__			} else {_				fail("Unexpected response of type  " + resp.getClass() + " " + resp)__			}__			_			RestoreStateCountingAndFailingSource.checkpointCompleteLatch.await()___			_			Future<?> cancelFuture = jobManager.ask(new CancelJob(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(cancelFuture, deadline.timeLeft())___			_			Future<?> removedFuture = jobManager.ask(new NotifyWhenJobRemoved(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(removedFuture, deadline.timeLeft())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = true__			jobGraph.setSavepointPath(savepointPath)___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				_				_				fail("Did not throw expected Exception")__			} catch (Exception ignored) {_			} finally {_				_				_				assertEquals(1 + numExecutionRetries, RestoreStateCountingAndFailingSource.numRestoreStateCalls)__			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};tests,that,a,restore,failure,is,retried,with,the,savepoint,state;test,public,void,test,restore,failure,throws,exception,int,num,task,managers,1,int,num,slots,per,task,manager,1,int,num,execution,retries,2,int,retry,delay,500,int,checkpointing,interval,100000000,final,deadline,deadline,new,finite,duration,3,time,unit,minutes,from,now,forkable,flink,mini,cluster,flink,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,1,env,enable,checkpointing,checkpointing,interval,env,set,number,of,execution,retries,num,execution,retries,env,get,config,set,execution,retry,delay,retry,delay,data,stream,integer,stream,env,add,source,new,restore,state,counting,and,failing,source,restore,state,counting,and,failing,source,fail,on,restore,state,call,false,restore,state,counting,and,failing,source,num,restore,state,calls,0,restore,state,counting,and,failing,source,checkpoint,complete,latch,new,count,down,latch,1,restore,state,counting,and,failing,source,emitted,0,stream,add,sink,new,discarding,sink,integer,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,flink,get,leader,gateway,deadline,time,left,log,info,job,manager,job,manager,flink,submit,job,detached,job,graph,while,deadline,has,time,left,restore,state,counting,and,failing,source,emitted,100,thread,sleep,100,assert,true,no,progress,restore,state,counting,and,failing,source,emitted,100,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,graph,get,job,id,deadline,time,left,object,resp,await,result,savepoint,path,future,deadline,time,left,string,savepoint,path,null,if,resp,instanceof,trigger,savepoint,success,savepoint,path,trigger,savepoint,success,resp,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,else,if,resp,instanceof,trigger,savepoint,failure,fail,received,trigger,savepoint,failure,trigger,savepoint,failure,resp,cause,get,message,else,fail,unexpected,response,of,type,resp,get,class,resp,restore,state,counting,and,failing,source,checkpoint,complete,latch,await,future,cancel,future,job,manager,ask,new,cancel,job,job,graph,get,job,id,deadline,time,left,await,ready,cancel,future,deadline,time,left,future,removed,future,job,manager,ask,new,notify,when,job,removed,job,graph,get,job,id,deadline,time,left,await,ready,removed,future,deadline,time,left,restore,state,counting,and,failing,source,fail,on,restore,state,call,true,job,graph,set,savepoint,path,savepoint,path,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,catch,exception,ignored,finally,assert,equals,1,num,execution,retries,restore,state,counting,and,failing,source,num,restore,state,calls,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testRestoreFailure() throws Exception;1465376364;Tests that a restore failure is retried with the savepoint state.;@Test_	public void testRestoreFailure() throws Exception {_		_		int numTaskManagers = 1__		int numSlotsPerTaskManager = 1__		int numExecutionRetries = 2__		int retryDelay = 500__		int checkpointingInterval = 100000000___		_		final Deadline deadline = new FiniteDuration(3, TimeUnit.MINUTES).fromNow()___		ForkableFlinkMiniCluster flink = null___		try {_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(1)__			env.enableCheckpointing(checkpointingInterval)__			env.setNumberOfExecutionRetries(numExecutionRetries)__			env.getConfig().setExecutionRetryDelay(retryDelay)___			DataStream<Integer> stream = env_					.addSource(new RestoreStateCountingAndFailingSource())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = false__			RestoreStateCountingAndFailingSource.numRestoreStateCalls = 0__			RestoreStateCountingAndFailingSource.checkpointCompleteLatch = new CountDownLatch(1)__			RestoreStateCountingAndFailingSource.emitted= 0___			stream.addSink(new DiscardingSink<Integer>())___			JobGraph jobGraph = env.getStreamGraph().getJobGraph()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = flink.getLeaderGateway(deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			flink.submitJobDetached(jobGraph)___			while (deadline.hasTimeLeft() && RestoreStateCountingAndFailingSource.emitted < 100) {_				Thread.sleep(100)__			}__			assertTrue("No progress", RestoreStateCountingAndFailingSource.emitted >= 100)___			_			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobGraph.getJobID()), deadline.timeLeft())___			Object resp = Await.result(savepointPathFuture, deadline.timeLeft())___			String savepointPath = null__			if (resp instanceof TriggerSavepointSuccess) {_				savepointPath = ((TriggerSavepointSuccess) resp).savepointPath()__				LOG.info("Retrieved savepoint path: " + savepointPath + ".")__			} else if (resp instanceof TriggerSavepointFailure) {_				fail("Received TriggerSavepointFailure: " + ((TriggerSavepointFailure) resp).cause().getMessage())__			} else {_				fail("Unexpected response of type  " + resp.getClass() + " " + resp)__			}__			_			RestoreStateCountingAndFailingSource.checkpointCompleteLatch.await()___			_			Future<?> cancelFuture = jobManager.ask(new CancelJob(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(cancelFuture, deadline.timeLeft())___			_			Future<?> removedFuture = jobManager.ask(new NotifyWhenJobRemoved(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(removedFuture, deadline.timeLeft())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = true__			jobGraph.setSavepointPath(savepointPath)___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				_				_				fail("Did not throw expected Exception")__			} catch (Exception ignored) {_			} finally {_				_				_				assertEquals(1 + numExecutionRetries, RestoreStateCountingAndFailingSource.numRestoreStateCalls)__			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};tests,that,a,restore,failure,is,retried,with,the,savepoint,state;test,public,void,test,restore,failure,throws,exception,int,num,task,managers,1,int,num,slots,per,task,manager,1,int,num,execution,retries,2,int,retry,delay,500,int,checkpointing,interval,100000000,final,deadline,deadline,new,finite,duration,3,time,unit,minutes,from,now,forkable,flink,mini,cluster,flink,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,1,env,enable,checkpointing,checkpointing,interval,env,set,number,of,execution,retries,num,execution,retries,env,get,config,set,execution,retry,delay,retry,delay,data,stream,integer,stream,env,add,source,new,restore,state,counting,and,failing,source,restore,state,counting,and,failing,source,fail,on,restore,state,call,false,restore,state,counting,and,failing,source,num,restore,state,calls,0,restore,state,counting,and,failing,source,checkpoint,complete,latch,new,count,down,latch,1,restore,state,counting,and,failing,source,emitted,0,stream,add,sink,new,discarding,sink,integer,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,flink,get,leader,gateway,deadline,time,left,log,info,job,manager,job,manager,flink,submit,job,detached,job,graph,while,deadline,has,time,left,restore,state,counting,and,failing,source,emitted,100,thread,sleep,100,assert,true,no,progress,restore,state,counting,and,failing,source,emitted,100,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,graph,get,job,id,deadline,time,left,object,resp,await,result,savepoint,path,future,deadline,time,left,string,savepoint,path,null,if,resp,instanceof,trigger,savepoint,success,savepoint,path,trigger,savepoint,success,resp,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,else,if,resp,instanceof,trigger,savepoint,failure,fail,received,trigger,savepoint,failure,trigger,savepoint,failure,resp,cause,get,message,else,fail,unexpected,response,of,type,resp,get,class,resp,restore,state,counting,and,failing,source,checkpoint,complete,latch,await,future,cancel,future,job,manager,ask,new,cancel,job,job,graph,get,job,id,deadline,time,left,await,ready,cancel,future,deadline,time,left,future,removed,future,job,manager,ask,new,notify,when,job,removed,job,graph,get,job,id,deadline,time,left,await,ready,removed,future,deadline,time,left,restore,state,counting,and,failing,source,fail,on,restore,state,call,true,job,graph,set,savepoint,path,savepoint,path,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,catch,exception,ignored,finally,assert,equals,1,num,execution,retries,restore,state,counting,and,failing,source,num,restore,state,calls,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testRestoreFailure() throws Exception;1466083944;Tests that a restore failure is retried with the savepoint state.;@Test_	public void testRestoreFailure() throws Exception {_		_		int numTaskManagers = 1__		int numSlotsPerTaskManager = 1__		int numExecutionRetries = 2__		int retryDelay = 500__		int checkpointingInterval = 100000000___		_		final Deadline deadline = new FiniteDuration(3, TimeUnit.MINUTES).fromNow()___		ForkableFlinkMiniCluster flink = null___		try {_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(1)__			env.enableCheckpointing(checkpointingInterval)__			env.setNumberOfExecutionRetries(numExecutionRetries)__			env.getConfig().setExecutionRetryDelay(retryDelay)___			DataStream<Integer> stream = env_					.addSource(new RestoreStateCountingAndFailingSource())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = false__			RestoreStateCountingAndFailingSource.numRestoreStateCalls = 0__			RestoreStateCountingAndFailingSource.checkpointCompleteLatch = new CountDownLatch(1)__			RestoreStateCountingAndFailingSource.emitted= 0___			stream.addSink(new DiscardingSink<Integer>())___			JobGraph jobGraph = env.getStreamGraph().getJobGraph()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = flink.getLeaderGateway(deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			flink.submitJobDetached(jobGraph)___			while (deadline.hasTimeLeft() && RestoreStateCountingAndFailingSource.emitted < 100) {_				Thread.sleep(100)__			}__			assertTrue("No progress", RestoreStateCountingAndFailingSource.emitted >= 100)___			_			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobGraph.getJobID()), deadline.timeLeft())___			Object resp = Await.result(savepointPathFuture, deadline.timeLeft())___			String savepointPath = null__			if (resp instanceof TriggerSavepointSuccess) {_				savepointPath = ((TriggerSavepointSuccess) resp).savepointPath()__				LOG.info("Retrieved savepoint path: " + savepointPath + ".")__			} else if (resp instanceof TriggerSavepointFailure) {_				fail("Received TriggerSavepointFailure: " + ((TriggerSavepointFailure) resp).cause().getMessage())__			} else {_				fail("Unexpected response of type  " + resp.getClass() + " " + resp)__			}__			_			RestoreStateCountingAndFailingSource.checkpointCompleteLatch.await()___			_			Future<?> cancelFuture = jobManager.ask(new CancelJob(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(cancelFuture, deadline.timeLeft())___			_			Future<?> removedFuture = jobManager.ask(new NotifyWhenJobRemoved(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(removedFuture, deadline.timeLeft())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = true__			jobGraph.setSavepointPath(savepointPath)___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				_				_				fail("Did not throw expected Exception")__			} catch (Exception ignored) {_			} finally {_				_				_				assertEquals(1 + numExecutionRetries, RestoreStateCountingAndFailingSource.numRestoreStateCalls)__			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};tests,that,a,restore,failure,is,retried,with,the,savepoint,state;test,public,void,test,restore,failure,throws,exception,int,num,task,managers,1,int,num,slots,per,task,manager,1,int,num,execution,retries,2,int,retry,delay,500,int,checkpointing,interval,100000000,final,deadline,deadline,new,finite,duration,3,time,unit,minutes,from,now,forkable,flink,mini,cluster,flink,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,1,env,enable,checkpointing,checkpointing,interval,env,set,number,of,execution,retries,num,execution,retries,env,get,config,set,execution,retry,delay,retry,delay,data,stream,integer,stream,env,add,source,new,restore,state,counting,and,failing,source,restore,state,counting,and,failing,source,fail,on,restore,state,call,false,restore,state,counting,and,failing,source,num,restore,state,calls,0,restore,state,counting,and,failing,source,checkpoint,complete,latch,new,count,down,latch,1,restore,state,counting,and,failing,source,emitted,0,stream,add,sink,new,discarding,sink,integer,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,flink,get,leader,gateway,deadline,time,left,log,info,job,manager,job,manager,flink,submit,job,detached,job,graph,while,deadline,has,time,left,restore,state,counting,and,failing,source,emitted,100,thread,sleep,100,assert,true,no,progress,restore,state,counting,and,failing,source,emitted,100,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,graph,get,job,id,deadline,time,left,object,resp,await,result,savepoint,path,future,deadline,time,left,string,savepoint,path,null,if,resp,instanceof,trigger,savepoint,success,savepoint,path,trigger,savepoint,success,resp,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,else,if,resp,instanceof,trigger,savepoint,failure,fail,received,trigger,savepoint,failure,trigger,savepoint,failure,resp,cause,get,message,else,fail,unexpected,response,of,type,resp,get,class,resp,restore,state,counting,and,failing,source,checkpoint,complete,latch,await,future,cancel,future,job,manager,ask,new,cancel,job,job,graph,get,job,id,deadline,time,left,await,ready,cancel,future,deadline,time,left,future,removed,future,job,manager,ask,new,notify,when,job,removed,job,graph,get,job,id,deadline,time,left,await,ready,removed,future,deadline,time,left,restore,state,counting,and,failing,source,fail,on,restore,state,call,true,job,graph,set,savepoint,path,savepoint,path,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,catch,exception,ignored,finally,assert,equals,1,num,execution,retries,restore,state,counting,and,failing,source,num,restore,state,calls,finally,if,flink,null,flink,shutdown
SavepointITCase -> @Test 	public void testRestoreFailure() throws Exception;1467296201;Tests that a restore failure is retried with the savepoint state.;@Test_	public void testRestoreFailure() throws Exception {_		_		int numTaskManagers = 1__		int numSlotsPerTaskManager = 1__		int numExecutionRetries = 2__		int retryDelay = 500__		int checkpointingInterval = 100000000___		_		final Deadline deadline = new FiniteDuration(3, TimeUnit.MINUTES).fromNow()___		ForkableFlinkMiniCluster flink = null___		try {_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(1)__			env.enableCheckpointing(checkpointingInterval)__			env.setNumberOfExecutionRetries(numExecutionRetries)__			env.getConfig().setExecutionRetryDelay(retryDelay)___			DataStream<Integer> stream = env_					.addSource(new RestoreStateCountingAndFailingSource())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = false__			RestoreStateCountingAndFailingSource.numRestoreStateCalls = 0__			RestoreStateCountingAndFailingSource.checkpointCompleteLatch = new CountDownLatch(1)__			RestoreStateCountingAndFailingSource.emitted= 0___			stream.addSink(new DiscardingSink<Integer>())___			JobGraph jobGraph = env.getStreamGraph().getJobGraph()___			_			final Configuration config = new Configuration()__			config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTaskManagers)__			config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, numSlotsPerTaskManager)__			LOG.info("Flink configuration: " + config + ".")___			_			flink = new ForkableFlinkMiniCluster(config)__			LOG.info("Starting Flink cluster.")__			flink.start()___			_			LOG.info("Retrieving JobManager.")__			ActorGateway jobManager = flink.getLeaderGateway(deadline.timeLeft())__			LOG.info("JobManager: " + jobManager + ".")___			_			flink.submitJobDetached(jobGraph)___			while (deadline.hasTimeLeft() && RestoreStateCountingAndFailingSource.emitted < 100) {_				Thread.sleep(100)__			}__			assertTrue("No progress", RestoreStateCountingAndFailingSource.emitted >= 100)___			_			Future<Object> savepointPathFuture = jobManager.ask(_					new TriggerSavepoint(jobGraph.getJobID()), deadline.timeLeft())___			Object resp = Await.result(savepointPathFuture, deadline.timeLeft())___			String savepointPath = null__			if (resp instanceof TriggerSavepointSuccess) {_				savepointPath = ((TriggerSavepointSuccess) resp).savepointPath()__				LOG.info("Retrieved savepoint path: " + savepointPath + ".")__			} else if (resp instanceof TriggerSavepointFailure) {_				fail("Received TriggerSavepointFailure: " + ((TriggerSavepointFailure) resp).cause().getMessage())__			} else {_				fail("Unexpected response of type  " + resp.getClass() + " " + resp)__			}__			_			RestoreStateCountingAndFailingSource.checkpointCompleteLatch.await()___			_			Future<?> cancelFuture = jobManager.ask(new CancelJob(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(cancelFuture, deadline.timeLeft())___			_			Future<?> removedFuture = jobManager.ask(new NotifyWhenJobRemoved(_					jobGraph.getJobID()), deadline.timeLeft())__			Await.ready(removedFuture, deadline.timeLeft())___			_			RestoreStateCountingAndFailingSource.failOnRestoreStateCall = true__			jobGraph.setSavepointPath(savepointPath)___			try {_				flink.submitJobAndWait(jobGraph, false, deadline.timeLeft())__				_				_				fail("Did not throw expected Exception")__			} catch (Exception ignored) {_			} finally {_				_				_				assertEquals(1 + numExecutionRetries, RestoreStateCountingAndFailingSource.numRestoreStateCalls)__			}_		}_		finally {_			if (flink != null) {_				flink.shutdown()__			}_		}_	};tests,that,a,restore,failure,is,retried,with,the,savepoint,state;test,public,void,test,restore,failure,throws,exception,int,num,task,managers,1,int,num,slots,per,task,manager,1,int,num,execution,retries,2,int,retry,delay,500,int,checkpointing,interval,100000000,final,deadline,deadline,new,finite,duration,3,time,unit,minutes,from,now,forkable,flink,mini,cluster,flink,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,parallelism,1,env,enable,checkpointing,checkpointing,interval,env,set,number,of,execution,retries,num,execution,retries,env,get,config,set,execution,retry,delay,retry,delay,data,stream,integer,stream,env,add,source,new,restore,state,counting,and,failing,source,restore,state,counting,and,failing,source,fail,on,restore,state,call,false,restore,state,counting,and,failing,source,num,restore,state,calls,0,restore,state,counting,and,failing,source,checkpoint,complete,latch,new,count,down,latch,1,restore,state,counting,and,failing,source,emitted,0,stream,add,sink,new,discarding,sink,integer,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,configuration,config,new,configuration,config,set,integer,config,constants,num,task,managers,config,set,integer,config,constants,num,slots,per,task,manager,log,info,flink,configuration,config,flink,new,forkable,flink,mini,cluster,config,log,info,starting,flink,cluster,flink,start,log,info,retrieving,job,manager,actor,gateway,job,manager,flink,get,leader,gateway,deadline,time,left,log,info,job,manager,job,manager,flink,submit,job,detached,job,graph,while,deadline,has,time,left,restore,state,counting,and,failing,source,emitted,100,thread,sleep,100,assert,true,no,progress,restore,state,counting,and,failing,source,emitted,100,future,object,savepoint,path,future,job,manager,ask,new,trigger,savepoint,job,graph,get,job,id,deadline,time,left,object,resp,await,result,savepoint,path,future,deadline,time,left,string,savepoint,path,null,if,resp,instanceof,trigger,savepoint,success,savepoint,path,trigger,savepoint,success,resp,savepoint,path,log,info,retrieved,savepoint,path,savepoint,path,else,if,resp,instanceof,trigger,savepoint,failure,fail,received,trigger,savepoint,failure,trigger,savepoint,failure,resp,cause,get,message,else,fail,unexpected,response,of,type,resp,get,class,resp,restore,state,counting,and,failing,source,checkpoint,complete,latch,await,future,cancel,future,job,manager,ask,new,cancel,job,job,graph,get,job,id,deadline,time,left,await,ready,cancel,future,deadline,time,left,future,removed,future,job,manager,ask,new,notify,when,job,removed,job,graph,get,job,id,deadline,time,left,await,ready,removed,future,deadline,time,left,restore,state,counting,and,failing,source,fail,on,restore,state,call,true,job,graph,set,savepoint,path,savepoint,path,try,flink,submit,job,and,wait,job,graph,false,deadline,time,left,fail,did,not,throw,expected,exception,catch,exception,ignored,finally,assert,equals,1,num,execution,retries,restore,state,counting,and,failing,source,num,restore,state,calls,finally,if,flink,null,flink,shutdown
