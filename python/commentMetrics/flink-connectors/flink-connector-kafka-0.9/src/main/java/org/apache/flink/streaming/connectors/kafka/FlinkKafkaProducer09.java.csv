# id;timestamp;commentText;codeText;commentWords;codeWords
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner);1495175928;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner);public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)___	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,flink,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner);1495175928;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner);public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)___	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,flink,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner);1495923077;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner);public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)___	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,flink,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner);1509723634;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner);public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)___	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,flink,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner);1511347989;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner);public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)___	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,flink,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema);1480685315;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema.;public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), getPropertiesFromBrokerList(brokerList), new FixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema;public,flink,kafka,producer09,string,broker,list,string,topic,id,serialization,schema,in,serialization,schema,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,get,properties,from,broker,list,broker,list,new,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema);1495175928;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema.;public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema;public,flink,kafka,producer09,string,broker,list,string,topic,id,serialization,schema,in,serialization,schema,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema);1495175928;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema.;public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema;public,flink,kafka,producer09,string,broker,list,string,topic,id,serialization,schema,in,serialization,schema,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema);1495923077;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema.;public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema;public,flink,kafka,producer09,string,broker,list,string,topic,id,serialization,schema,in,serialization,schema,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema);1509723634;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema.;public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema;public,flink,kafka,producer09,string,broker,list,string,topic,id,serialization,schema,in,serialization,schema,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema);1511347989;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema.;public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema;public,flink,kafka,producer09,string,broker,list,string,topic,id,serialization,schema,in,serialization,schema,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema);1515212142;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined key-less serialization schema.;public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,key,less,serialization,schema;public,flink,kafka,producer09,string,broker,list,string,topic,id,serialization,schema,in,serialization,schema,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema);1515212365;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined key-less serialization schema.;public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,key,less,serialization,schema;public,flink,kafka,producer09,string,broker,list,string,topic,id,serialization,schema,in,serialization,schema,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema);1515757409;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined key-less serialization schema.;public FlinkKafkaProducer09(String brokerList, String topicId, SerializationSchema<IN> serializationSchema) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,key,less,serialization,schema;public,flink,kafka,producer09,string,broker,list,string,topic,id,serialization,schema,in,serialization,schema,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09( 			String topicId, 			SerializationSchema<IN> serializationSchema, 			Properties producerConfig, 			@Nullable FlinkKafkaPartitioner<IN> customPartitioner);1515212142;Creates a FlinkKafkaProducer for a given topic. The sink produces its input to_the topic. It accepts a key-less {@link SerializationSchema} and possibly a custom {@link FlinkKafkaPartitioner}.__<p>Since a key-less {@link SerializationSchema} is used, all records sent to Kafka will not have an_attached key. Therefore, if a partitioner is also not provided, records will be distributed to Kafka_partitions in a round-robin fashion.__@param topicId The topic to write data to_@param serializationSchema A key-less serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions._If set to {@code null}, records will be distributed to Kafka partitions_in a round-robin fashion.;public FlinkKafkaProducer09(_			String topicId,_			SerializationSchema<IN> serializationSchema,_			Properties producerConfig,_			@Nullable FlinkKafkaPartitioner<IN> customPartitioner) {__		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)___	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,its,input,to,the,topic,it,accepts,a,key,less,link,serialization,schema,and,possibly,a,custom,link,flink,kafka,partitioner,p,since,a,key,less,link,serialization,schema,is,used,all,records,sent,to,kafka,will,not,have,an,attached,key,therefore,if,a,partitioner,is,also,not,provided,records,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,key,less,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,if,set,to,code,null,records,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,nullable,flink,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09( 			String topicId, 			SerializationSchema<IN> serializationSchema, 			Properties producerConfig, 			@Nullable FlinkKafkaPartitioner<IN> customPartitioner);1515212365;Creates a FlinkKafkaProducer for a given topic. The sink produces its input to_the topic. It accepts a key-less {@link SerializationSchema} and possibly a custom {@link FlinkKafkaPartitioner}.__<p>Since a key-less {@link SerializationSchema} is used, all records sent to Kafka will not have an_attached key. Therefore, if a partitioner is also not provided, records will be distributed to Kafka_partitions in a round-robin fashion.__@param topicId The topic to write data to_@param serializationSchema A key-less serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions._If set to {@code null}, records will be distributed to Kafka partitions_in a round-robin fashion.;public FlinkKafkaProducer09(_			String topicId,_			SerializationSchema<IN> serializationSchema,_			Properties producerConfig,_			@Nullable FlinkKafkaPartitioner<IN> customPartitioner) {__		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)___	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,its,input,to,the,topic,it,accepts,a,key,less,link,serialization,schema,and,possibly,a,custom,link,flink,kafka,partitioner,p,since,a,key,less,link,serialization,schema,is,used,all,records,sent,to,kafka,will,not,have,an,attached,key,therefore,if,a,partitioner,is,also,not,provided,records,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,key,less,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,if,set,to,code,null,records,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,nullable,flink,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09( 			String topicId, 			SerializationSchema<IN> serializationSchema, 			Properties producerConfig, 			@Nullable FlinkKafkaPartitioner<IN> customPartitioner);1515757409;Creates a FlinkKafkaProducer for a given topic. The sink produces its input to_the topic. It accepts a key-less {@link SerializationSchema} and possibly a custom {@link FlinkKafkaPartitioner}.__<p>Since a key-less {@link SerializationSchema} is used, all records sent to Kafka will not have an_attached key. Therefore, if a partitioner is also not provided, records will be distributed to Kafka_partitions in a round-robin fashion.__@param topicId The topic to write data to_@param serializationSchema A key-less serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions._If set to {@code null}, records will be distributed to Kafka partitions_in a round-robin fashion.;public FlinkKafkaProducer09(_			String topicId,_			SerializationSchema<IN> serializationSchema,_			Properties producerConfig,_			@Nullable FlinkKafkaPartitioner<IN> customPartitioner) {__		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)___	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,its,input,to,the,topic,it,accepts,a,key,less,link,serialization,schema,and,possibly,a,custom,link,flink,kafka,partitioner,p,since,a,key,less,link,serialization,schema,is,used,all,records,sent,to,kafka,will,not,have,an,attached,key,therefore,if,a,partitioner,is,also,not,provided,records,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,key,less,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,if,set,to,code,null,records,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,nullable,flink,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1495175928;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner)_@deprecated Use {@link FlinkKafkaProducer09#FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead;@Deprecated_	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)___	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner,deprecated,use,link,flink,kafka,producer09,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1495175928;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner)__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1495923077;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner)__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1509723634;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner)__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1511347989;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner)__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link #FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1515212142;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner)__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link #FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1515212365;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner)__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link #FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1515757409;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A (keyless) serializable serialization schema for turning user objects into a kafka-consumable byte[]_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions (when passing null, we'll use Kafka's partitioner)__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link #FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,keyless,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,when,passing,null,we,ll,use,kafka,s,partitioner,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner);1495175928;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,flink,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner);1495175928;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,flink,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner);1495923077;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,flink,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner);1509723634;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,flink,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner);1511347989;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,flink,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig);1480685315;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages_@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, serializationSchema, producerConfig, new FixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,serialization,schema,producer,config,new,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig);1495175928;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages_@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, serializationSchema, producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig);1495175928;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages_@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, serializationSchema, producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig);1495923077;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages_@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, serializationSchema, producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig);1509723634;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages_@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, serializationSchema, producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig);1511347989;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages_@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, serializationSchema, producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig);1515212142;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, KeyedSerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages_@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, serializationSchema, producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,keyed,serialization,schema,properties,flink,kafka,partitioner,instead,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig);1515212365;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, KeyedSerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages_@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, serializationSchema, producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,keyed,serialization,schema,properties,flink,kafka,partitioner,instead,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig);1515757409;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, KeyedSerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages_@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, serializationSchema, producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,keyed,serialization,schema,properties,flink,kafka,partitioner,instead,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1495175928;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions._@deprecated Use {@link FlinkKafkaProducer09#FlinkKafkaProducer09(String, KeyedSerializationSchema, Properties, FlinkKafkaPartitioner)} instead;@Deprecated_	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,deprecated,use,link,flink,kafka,producer09,flink,kafka,producer09,string,keyed,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1495175928;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link FlinkKafkaProducer09(String, org.apache.flink.streaming.util.serialization.KeyedDeserializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, new FlinkKafkaDelegatePartitioner<>(customPartitioner))__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,org,apache,flink,streaming,util,serialization,keyed,deserialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,new,flink,kafka,delegate,partitioner,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1495923077;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link FlinkKafkaProducer09(String, org.apache.flink.streaming.util.serialization.KeyedDeserializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, new FlinkKafkaDelegatePartitioner<>(customPartitioner))__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,org,apache,flink,streaming,util,serialization,keyed,deserialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,new,flink,kafka,delegate,partitioner,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1509723634;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link FlinkKafkaProducer09(String, org.apache.flink.streaming.util.serialization.KeyedDeserializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, new FlinkKafkaDelegatePartitioner<>(customPartitioner))__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,org,apache,flink,streaming,util,serialization,keyed,deserialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,new,flink,kafka,delegate,partitioner,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1511347989;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link #FlinkKafkaProducer09(String, org.apache.flink.streaming.util.serialization.KeyedDeserializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, new FlinkKafkaDelegatePartitioner<>(customPartitioner))__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,org,apache,flink,streaming,util,serialization,keyed,deserialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,new,flink,kafka,delegate,partitioner,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1515212142;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link #FlinkKafkaProducer09(String, org.apache.flink.streaming.util.serialization.KeyedDeserializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, new FlinkKafkaDelegatePartitioner<>(customPartitioner))__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,org,apache,flink,streaming,util,serialization,keyed,deserialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,new,flink,kafka,delegate,partitioner,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1515212365;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link #FlinkKafkaProducer09(String, KeyedSerializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, new FlinkKafkaDelegatePartitioner<>(customPartitioner))__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,keyed,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,new,flink,kafka,delegate,partitioner,custom,partitioner
FlinkKafkaProducer09 -> @Deprecated 	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner);1515757409;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions.__@deprecated This is a deprecated constructor that does not correctly handle partitioning when_producing to multiple topics. Use_{@link #FlinkKafkaProducer09(String, KeyedSerializationSchema, Properties, FlinkKafkaPartitioner)} instead.;@Deprecated_	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, KafkaPartitioner<IN> customPartitioner) {_		super(topicId, serializationSchema, producerConfig, new FlinkKafkaDelegatePartitioner<>(customPartitioner))__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,deprecated,this,is,a,deprecated,constructor,that,does,not,correctly,handle,partitioning,when,producing,to,multiple,topics,use,link,flink,kafka,producer09,string,keyed,serialization,schema,properties,flink,kafka,partitioner,instead;deprecated,public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,new,flink,kafka,delegate,partitioner,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09( 			String topicId, 			KeyedSerializationSchema<IN> serializationSchema, 			Properties producerConfig, 			@Nullable FlinkKafkaPartitioner<IN> customPartitioner);1515212142;Creates a FlinkKafkaProducer for a given topic. The sink produces its input to_the topic. It accepts a keyed {@link KeyedSerializationSchema} and possibly a custom {@link FlinkKafkaPartitioner}.__<p>If a partitioner is not provided, written records will be partitioned by the attached key of each_record (as determined by {@link KeyedSerializationSchema#serializeKey(Object)}). If written records do not_have a key (i.e., {@link KeyedSerializationSchema#serializeKey(Object)} returns {@code null}), they_will be distributed to Kafka partitions in a round-robin fashion.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions._If set to {@code null}, records will be partitioned by the key of each record_(determined by {@link KeyedSerializationSchema#serializeKey(Object)}). If the keys_are {@code null}, then records will be distributed to Kafka partitions in a_round-robin fashion.;public FlinkKafkaProducer09(_			String topicId,_			KeyedSerializationSchema<IN> serializationSchema,_			Properties producerConfig,_			@Nullable FlinkKafkaPartitioner<IN> customPartitioner) {__		super(topicId, serializationSchema, producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,its,input,to,the,topic,it,accepts,a,keyed,link,keyed,serialization,schema,and,possibly,a,custom,link,flink,kafka,partitioner,p,if,a,partitioner,is,not,provided,written,records,will,be,partitioned,by,the,attached,key,of,each,record,as,determined,by,link,keyed,serialization,schema,serialize,key,object,if,written,records,do,not,have,a,key,i,e,link,keyed,serialization,schema,serialize,key,object,returns,code,null,they,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,if,set,to,code,null,records,will,be,partitioned,by,the,key,of,each,record,determined,by,link,keyed,serialization,schema,serialize,key,object,if,the,keys,are,code,null,then,records,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,nullable,flink,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09( 			String topicId, 			KeyedSerializationSchema<IN> serializationSchema, 			Properties producerConfig, 			@Nullable FlinkKafkaPartitioner<IN> customPartitioner);1515212365;Creates a FlinkKafkaProducer for a given topic. The sink produces its input to_the topic. It accepts a keyed {@link KeyedSerializationSchema} and possibly a custom {@link FlinkKafkaPartitioner}.__<p>If a partitioner is not provided, written records will be partitioned by the attached key of each_record (as determined by {@link KeyedSerializationSchema#serializeKey(Object)}). If written records do not_have a key (i.e., {@link KeyedSerializationSchema#serializeKey(Object)} returns {@code null}), they_will be distributed to Kafka partitions in a round-robin fashion.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions._If set to {@code null}, records will be partitioned by the key of each record_(determined by {@link KeyedSerializationSchema#serializeKey(Object)}). If the keys_are {@code null}, then records will be distributed to Kafka partitions in a_round-robin fashion.;public FlinkKafkaProducer09(_			String topicId,_			KeyedSerializationSchema<IN> serializationSchema,_			Properties producerConfig,_			@Nullable FlinkKafkaPartitioner<IN> customPartitioner) {__		super(topicId, serializationSchema, producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,its,input,to,the,topic,it,accepts,a,keyed,link,keyed,serialization,schema,and,possibly,a,custom,link,flink,kafka,partitioner,p,if,a,partitioner,is,not,provided,written,records,will,be,partitioned,by,the,attached,key,of,each,record,as,determined,by,link,keyed,serialization,schema,serialize,key,object,if,written,records,do,not,have,a,key,i,e,link,keyed,serialization,schema,serialize,key,object,returns,code,null,they,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,if,set,to,code,null,records,will,be,partitioned,by,the,key,of,each,record,determined,by,link,keyed,serialization,schema,serialize,key,object,if,the,keys,are,code,null,then,records,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,nullable,flink,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09( 			String topicId, 			KeyedSerializationSchema<IN> serializationSchema, 			Properties producerConfig, 			@Nullable FlinkKafkaPartitioner<IN> customPartitioner);1515757409;Creates a FlinkKafkaProducer for a given topic. The sink produces its input to_the topic. It accepts a keyed {@link KeyedSerializationSchema} and possibly a custom {@link FlinkKafkaPartitioner}.__<p>If a partitioner is not provided, written records will be partitioned by the attached key of each_record (as determined by {@link KeyedSerializationSchema#serializeKey(Object)}). If written records do not_have a key (i.e., {@link KeyedSerializationSchema#serializeKey(Object)} returns {@code null}), they_will be distributed to Kafka partitions in a round-robin fashion.__@param topicId The topic to write data to_@param serializationSchema A serializable serialization schema for turning user objects into a kafka-consumable byte[] supporting key/value messages_@param producerConfig Configuration properties for the KafkaProducer. 'bootstrap.servers.' is the only required argument._@param customPartitioner A serializable partitioner for assigning messages to Kafka partitions._If set to {@code null}, records will be partitioned by the key of each record_(determined by {@link KeyedSerializationSchema#serializeKey(Object)}). If the keys_are {@code null}, then records will be distributed to Kafka partitions in a_round-robin fashion.;public FlinkKafkaProducer09(_			String topicId,_			KeyedSerializationSchema<IN> serializationSchema,_			Properties producerConfig,_			@Nullable FlinkKafkaPartitioner<IN> customPartitioner) {__		super(topicId, serializationSchema, producerConfig, customPartitioner)__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,its,input,to,the,topic,it,accepts,a,keyed,link,keyed,serialization,schema,and,possibly,a,custom,link,flink,kafka,partitioner,p,if,a,partitioner,is,not,provided,written,records,will,be,partitioned,by,the,attached,key,of,each,record,as,determined,by,link,keyed,serialization,schema,serialize,key,object,if,written,records,do,not,have,a,key,i,e,link,keyed,serialization,schema,serialize,key,object,returns,code,null,they,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion,param,topic,id,the,topic,to,write,data,to,param,serialization,schema,a,serializable,serialization,schema,for,turning,user,objects,into,a,kafka,consumable,byte,supporting,key,value,messages,param,producer,config,configuration,properties,for,the,kafka,producer,bootstrap,servers,is,the,only,required,argument,param,custom,partitioner,a,serializable,partitioner,for,assigning,messages,to,kafka,partitions,if,set,to,code,null,records,will,be,partitioned,by,the,key,of,each,record,determined,by,link,keyed,serialization,schema,serialize,key,object,if,the,keys,are,code,null,then,records,will,be,distributed,to,kafka,partitions,in,a,round,robin,fashion;public,flink,kafka,producer09,string,topic,id,keyed,serialization,schema,in,serialization,schema,properties,producer,config,nullable,flink,kafka,partitioner,in,custom,partitioner,super,topic,id,serialization,schema,producer,config,custom,partitioner
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig);1480685315;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema._@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, new FixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,new,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig);1495175928;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema._@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig);1495175928;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema._@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig);1495923077;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema._@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig);1509723634;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema._@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig);1511347989;Creates a FlinkKafkaProducer for a given topic. the sink produces a DataStream to_the topic.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined (keyless) serialization schema._@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,keyless,serialization,schema,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig);1515212142;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined key-less serialization schema._@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,key,less,serialization,schema,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig);1515212365;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined key-less serialization schema._@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,key,less,serialization,schema,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig);1515757409;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, SerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param topicId_ID of the Kafka topic._@param serializationSchema_User defined key-less serialization schema._@param producerConfig_Properties with the producer configuration.;public FlinkKafkaProducer09(String topicId, SerializationSchema<IN> serializationSchema, Properties producerConfig) {_		this(topicId, new KeyedSerializationSchemaWrapper<>(serializationSchema), producerConfig, new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,serialization,schema,properties,flink,kafka,partitioner,instead,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,key,less,serialization,schema,param,producer,config,properties,with,the,producer,configuration;public,flink,kafka,producer09,string,topic,id,serialization,schema,in,serialization,schema,properties,producer,config,this,topic,id,new,keyed,serialization,schema,wrapper,serialization,schema,producer,config,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema);1480685315;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages;public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema) {_		this(topicId, serializationSchema, getPropertiesFromBrokerList(brokerList), new FixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages;public,flink,kafka,producer09,string,broker,list,string,topic,id,keyed,serialization,schema,in,serialization,schema,this,topic,id,serialization,schema,get,properties,from,broker,list,broker,list,new,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema);1495175928;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages;public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema) {_		this(topicId, serializationSchema, getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages;public,flink,kafka,producer09,string,broker,list,string,topic,id,keyed,serialization,schema,in,serialization,schema,this,topic,id,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema);1495175928;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages;public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema) {_		this(topicId, serializationSchema, getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages;public,flink,kafka,producer09,string,broker,list,string,topic,id,keyed,serialization,schema,in,serialization,schema,this,topic,id,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema);1495923077;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages;public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema) {_		this(topicId, serializationSchema, getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages;public,flink,kafka,producer09,string,broker,list,string,topic,id,keyed,serialization,schema,in,serialization,schema,this,topic,id,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema);1509723634;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages;public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema) {_		this(topicId, serializationSchema, getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages;public,flink,kafka,producer09,string,broker,list,string,topic,id,keyed,serialization,schema,in,serialization,schema,this,topic,id,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema);1511347989;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages;public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema) {_		this(topicId, serializationSchema, getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages;public,flink,kafka,producer09,string,broker,list,string,topic,id,keyed,serialization,schema,in,serialization,schema,this,topic,id,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema);1515212142;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, KeyedSerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages;public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema) {_		this(topicId, serializationSchema, getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,keyed,serialization,schema,properties,flink,kafka,partitioner,instead,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages;public,flink,kafka,producer09,string,broker,list,string,topic,id,keyed,serialization,schema,in,serialization,schema,this,topic,id,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema);1515212365;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, KeyedSerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages;public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema) {_		this(topicId, serializationSchema, getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,keyed,serialization,schema,properties,flink,kafka,partitioner,instead,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages;public,flink,kafka,producer09,string,broker,list,string,topic,id,keyed,serialization,schema,in,serialization,schema,this,topic,id,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
FlinkKafkaProducer09 -> public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema);1515757409;Creates a FlinkKafkaProducer for a given topic. The sink produces a DataStream to_the topic.__<p>Using this constructor, the default {@link FlinkFixedPartitioner} will be used as_the partitioner. This default partitioner maps each sink subtask to a single Kafka_partition (i.e. all records received by a sink subtask will end up in the same_Kafka partition).__<p>To use a custom partitioner, please use_{@link #FlinkKafkaProducer09(String, KeyedSerializationSchema, Properties, FlinkKafkaPartitioner)} instead.__@param brokerList_Comma separated addresses of the brokers_@param topicId_ID of the Kafka topic._@param serializationSchema_User defined serialization schema supporting key/value messages;public FlinkKafkaProducer09(String brokerList, String topicId, KeyedSerializationSchema<IN> serializationSchema) {_		this(topicId, serializationSchema, getPropertiesFromBrokerList(brokerList), new FlinkFixedPartitioner<IN>())__	};creates,a,flink,kafka,producer,for,a,given,topic,the,sink,produces,a,data,stream,to,the,topic,p,using,this,constructor,the,default,link,flink,fixed,partitioner,will,be,used,as,the,partitioner,this,default,partitioner,maps,each,sink,subtask,to,a,single,kafka,partition,i,e,all,records,received,by,a,sink,subtask,will,end,up,in,the,same,kafka,partition,p,to,use,a,custom,partitioner,please,use,link,flink,kafka,producer09,string,keyed,serialization,schema,properties,flink,kafka,partitioner,instead,param,broker,list,comma,separated,addresses,of,the,brokers,param,topic,id,id,of,the,kafka,topic,param,serialization,schema,user,defined,serialization,schema,supporting,key,value,messages;public,flink,kafka,producer09,string,broker,list,string,topic,id,keyed,serialization,schema,in,serialization,schema,this,topic,id,serialization,schema,get,properties,from,broker,list,broker,list,new,flink,fixed,partitioner,in
