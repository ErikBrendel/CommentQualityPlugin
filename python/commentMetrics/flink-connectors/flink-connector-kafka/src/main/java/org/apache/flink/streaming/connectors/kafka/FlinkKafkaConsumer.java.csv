# id;timestamp;commentText;codeText;commentWords;codeWords
FlinkKafkaConsumer -> public FlinkKafkaConsumer(List<String> topics, KeyedDeserializationSchema<T> deserializer, Properties props);1539704473;Creates a new Kafka streaming source consumer.__<p>This constructor allows passing multiple topics and a key/value deserialization schema.__@param topics       The Kafka topics to read from._@param deserializer The keyed de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(List<String> topics, KeyedDeserializationSchema<T> deserializer, Properties props) {_		this(topics, null, deserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,p,this,constructor,allows,passing,multiple,topics,and,a,key,value,deserialization,schema,param,topics,the,kafka,topics,to,read,from,param,deserializer,the,keyed,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,list,string,topics,keyed,deserialization,schema,t,deserializer,properties,props,this,topics,null,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(List<String> topics, KeyedDeserializationSchema<T> deserializer, Properties props);1548860009;Creates a new Kafka streaming source consumer.__<p>This constructor allows passing multiple topics and a key/value deserialization schema.__@param topics       The Kafka topics to read from._@param deserializer The keyed de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(List<String> topics, KeyedDeserializationSchema<T> deserializer, Properties props) {_		this(topics, null, deserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,p,this,constructor,allows,passing,multiple,topics,and,a,key,value,deserialization,schema,param,topics,the,kafka,topics,to,read,from,param,deserializer,the,keyed,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,list,string,topics,keyed,deserialization,schema,t,deserializer,properties,props,this,topics,null,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(List<String> topics, KeyedDeserializationSchema<T> deserializer, Properties props);1550834388;Creates a new Kafka streaming source consumer.__<p>This constructor allows passing multiple topics and a key/value deserialization schema.__@param topics       The Kafka topics to read from._@param deserializer The keyed de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(List<String> topics, KeyedDeserializationSchema<T> deserializer, Properties props) {_		this(topics, null, deserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,p,this,constructor,allows,passing,multiple,topics,and,a,key,value,deserialization,schema,param,topics,the,kafka,topics,to,read,from,param,deserializer,the,keyed,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,list,string,topics,keyed,deserialization,schema,t,deserializer,properties,props,this,topics,null,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(List<String> topics, DeserializationSchema<T> deserializer, Properties props);1539704473;Creates a new Kafka streaming source consumer.__<p>This constructor allows passing multiple topics to the consumer.__@param topics       The Kafka topics to read from._@param deserializer The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(List<String> topics, DeserializationSchema<T> deserializer, Properties props) {_		this(topics, new KeyedDeserializationSchemaWrapper<>(deserializer), props)__	};creates,a,new,kafka,streaming,source,consumer,p,this,constructor,allows,passing,multiple,topics,to,the,consumer,param,topics,the,kafka,topics,to,read,from,param,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,list,string,topics,deserialization,schema,t,deserializer,properties,props,this,topics,new,keyed,deserialization,schema,wrapper,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(List<String> topics, DeserializationSchema<T> deserializer, Properties props);1548860009;Creates a new Kafka streaming source consumer.__<p>This constructor allows passing multiple topics to the consumer.__@param topics       The Kafka topics to read from._@param deserializer The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(List<String> topics, DeserializationSchema<T> deserializer, Properties props) {_		this(topics, new KeyedDeserializationSchemaWrapper<>(deserializer), props)__	};creates,a,new,kafka,streaming,source,consumer,p,this,constructor,allows,passing,multiple,topics,to,the,consumer,param,topics,the,kafka,topics,to,read,from,param,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,list,string,topics,deserialization,schema,t,deserializer,properties,props,this,topics,new,keyed,deserialization,schema,wrapper,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(List<String> topics, DeserializationSchema<T> deserializer, Properties props);1550834388;Creates a new Kafka streaming source consumer.__<p>This constructor allows passing multiple topics to the consumer.__@param topics       The Kafka topics to read from._@param deserializer The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(List<String> topics, DeserializationSchema<T> deserializer, Properties props) {_		this(topics, new KeyedDeserializationSchemaWrapper<>(deserializer), props)__	};creates,a,new,kafka,streaming,source,consumer,p,this,constructor,allows,passing,multiple,topics,to,the,consumer,param,topics,the,kafka,topics,to,read,from,param,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,list,string,topics,deserialization,schema,t,deserializer,properties,props,this,topics,new,keyed,deserialization,schema,wrapper,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(List<String> topics, DeserializationSchema<T> deserializer, Properties props);1550834396;Creates a new Kafka streaming source consumer.__<p>This constructor allows passing multiple topics to the consumer.__@param topics       The Kafka topics to read from._@param deserializer The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(List<String> topics, DeserializationSchema<T> deserializer, Properties props) {_		this(topics, new KafkaDeserializationSchemaWrapper<>(deserializer), props)__	};creates,a,new,kafka,streaming,source,consumer,p,this,constructor,allows,passing,multiple,topics,to,the,consumer,param,topics,the,kafka,topics,to,read,from,param,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,list,string,topics,deserialization,schema,t,deserializer,properties,props,this,topics,new,kafka,deserialization,schema,wrapper,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(Pattern subscriptionPattern, DeserializationSchema<T> valueDeserializer, Properties props);1539704473;Creates a new Kafka streaming source consumer. Use this constructor to_subscribe to multiple topics based on a regular expression pattern.__<p>If partition discovery is enabled (by setting a non-negative value for_{@link FlinkKafkaConsumer#KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS} in the properties), topics_with names matching the pattern will also be subscribed to as they are created on the fly.__@param subscriptionPattern The regular expression for a pattern of topic names to subscribe to._@param valueDeserializer   The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(Pattern subscriptionPattern, DeserializationSchema<T> valueDeserializer, Properties props) {_		this(null, subscriptionPattern, new KeyedDeserializationSchemaWrapper<>(valueDeserializer), props)__	};creates,a,new,kafka,streaming,source,consumer,use,this,constructor,to,subscribe,to,multiple,topics,based,on,a,regular,expression,pattern,p,if,partition,discovery,is,enabled,by,setting,a,non,negative,value,for,link,flink,kafka,consumer,in,the,properties,topics,with,names,matching,the,pattern,will,also,be,subscribed,to,as,they,are,created,on,the,fly,param,subscription,pattern,the,regular,expression,for,a,pattern,of,topic,names,to,subscribe,to,param,value,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,pattern,subscription,pattern,deserialization,schema,t,value,deserializer,properties,props,this,null,subscription,pattern,new,keyed,deserialization,schema,wrapper,value,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(Pattern subscriptionPattern, DeserializationSchema<T> valueDeserializer, Properties props);1548860009;Creates a new Kafka streaming source consumer. Use this constructor to_subscribe to multiple topics based on a regular expression pattern.__<p>If partition discovery is enabled (by setting a non-negative value for_{@link FlinkKafkaConsumer#KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS} in the properties), topics_with names matching the pattern will also be subscribed to as they are created on the fly.__@param subscriptionPattern The regular expression for a pattern of topic names to subscribe to._@param valueDeserializer   The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(Pattern subscriptionPattern, DeserializationSchema<T> valueDeserializer, Properties props) {_		this(null, subscriptionPattern, new KeyedDeserializationSchemaWrapper<>(valueDeserializer), props)__	};creates,a,new,kafka,streaming,source,consumer,use,this,constructor,to,subscribe,to,multiple,topics,based,on,a,regular,expression,pattern,p,if,partition,discovery,is,enabled,by,setting,a,non,negative,value,for,link,flink,kafka,consumer,in,the,properties,topics,with,names,matching,the,pattern,will,also,be,subscribed,to,as,they,are,created,on,the,fly,param,subscription,pattern,the,regular,expression,for,a,pattern,of,topic,names,to,subscribe,to,param,value,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,pattern,subscription,pattern,deserialization,schema,t,value,deserializer,properties,props,this,null,subscription,pattern,new,keyed,deserialization,schema,wrapper,value,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(Pattern subscriptionPattern, DeserializationSchema<T> valueDeserializer, Properties props);1550834388;Creates a new Kafka streaming source consumer. Use this constructor to_subscribe to multiple topics based on a regular expression pattern.__<p>If partition discovery is enabled (by setting a non-negative value for_{@link FlinkKafkaConsumer#KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS} in the properties), topics_with names matching the pattern will also be subscribed to as they are created on the fly.__@param subscriptionPattern The regular expression for a pattern of topic names to subscribe to._@param valueDeserializer   The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(Pattern subscriptionPattern, DeserializationSchema<T> valueDeserializer, Properties props) {_		this(null, subscriptionPattern, new KeyedDeserializationSchemaWrapper<>(valueDeserializer), props)__	};creates,a,new,kafka,streaming,source,consumer,use,this,constructor,to,subscribe,to,multiple,topics,based,on,a,regular,expression,pattern,p,if,partition,discovery,is,enabled,by,setting,a,non,negative,value,for,link,flink,kafka,consumer,in,the,properties,topics,with,names,matching,the,pattern,will,also,be,subscribed,to,as,they,are,created,on,the,fly,param,subscription,pattern,the,regular,expression,for,a,pattern,of,topic,names,to,subscribe,to,param,value,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,pattern,subscription,pattern,deserialization,schema,t,value,deserializer,properties,props,this,null,subscription,pattern,new,keyed,deserialization,schema,wrapper,value,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(Pattern subscriptionPattern, DeserializationSchema<T> valueDeserializer, Properties props);1550834396;Creates a new Kafka streaming source consumer. Use this constructor to_subscribe to multiple topics based on a regular expression pattern.__<p>If partition discovery is enabled (by setting a non-negative value for_{@link FlinkKafkaConsumer#KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS} in the properties), topics_with names matching the pattern will also be subscribed to as they are created on the fly.__@param subscriptionPattern The regular expression for a pattern of topic names to subscribe to._@param valueDeserializer   The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(Pattern subscriptionPattern, DeserializationSchema<T> valueDeserializer, Properties props) {_		this(null, subscriptionPattern, new KafkaDeserializationSchemaWrapper<>(valueDeserializer), props)__	};creates,a,new,kafka,streaming,source,consumer,use,this,constructor,to,subscribe,to,multiple,topics,based,on,a,regular,expression,pattern,p,if,partition,discovery,is,enabled,by,setting,a,non,negative,value,for,link,flink,kafka,consumer,in,the,properties,topics,with,names,matching,the,pattern,will,also,be,subscribed,to,as,they,are,created,on,the,fly,param,subscription,pattern,the,regular,expression,for,a,pattern,of,topic,names,to,subscribe,to,param,value,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,pattern,subscription,pattern,deserialization,schema,t,value,deserializer,properties,props,this,null,subscription,pattern,new,kafka,deserialization,schema,wrapper,value,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(Pattern subscriptionPattern, KeyedDeserializationSchema<T> deserializer, Properties props);1539704473;Creates a new Kafka streaming source consumer. Use this constructor to_subscribe to multiple topics based on a regular expression pattern.__<p>If partition discovery is enabled (by setting a non-negative value for_{@link FlinkKafkaConsumer#KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS} in the properties), topics_with names matching the pattern will also be subscribed to as they are created on the fly.__<p>This constructor allows passing a {@see KeyedDeserializationSchema} for reading key/value_pairs, offsets, and topic names from Kafka.__@param subscriptionPattern The regular expression for a pattern of topic names to subscribe to._@param deserializer        The keyed de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(Pattern subscriptionPattern, KeyedDeserializationSchema<T> deserializer, Properties props) {_		this(null, subscriptionPattern, deserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,use,this,constructor,to,subscribe,to,multiple,topics,based,on,a,regular,expression,pattern,p,if,partition,discovery,is,enabled,by,setting,a,non,negative,value,for,link,flink,kafka,consumer,in,the,properties,topics,with,names,matching,the,pattern,will,also,be,subscribed,to,as,they,are,created,on,the,fly,p,this,constructor,allows,passing,a,see,keyed,deserialization,schema,for,reading,key,value,pairs,offsets,and,topic,names,from,kafka,param,subscription,pattern,the,regular,expression,for,a,pattern,of,topic,names,to,subscribe,to,param,deserializer,the,keyed,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,pattern,subscription,pattern,keyed,deserialization,schema,t,deserializer,properties,props,this,null,subscription,pattern,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(Pattern subscriptionPattern, KeyedDeserializationSchema<T> deserializer, Properties props);1548860009;Creates a new Kafka streaming source consumer. Use this constructor to_subscribe to multiple topics based on a regular expression pattern.__<p>If partition discovery is enabled (by setting a non-negative value for_{@link FlinkKafkaConsumer#KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS} in the properties), topics_with names matching the pattern will also be subscribed to as they are created on the fly.__<p>This constructor allows passing a {@see KeyedDeserializationSchema} for reading key/value_pairs, offsets, and topic names from Kafka.__@param subscriptionPattern The regular expression for a pattern of topic names to subscribe to._@param deserializer        The keyed de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(Pattern subscriptionPattern, KeyedDeserializationSchema<T> deserializer, Properties props) {_		this(null, subscriptionPattern, deserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,use,this,constructor,to,subscribe,to,multiple,topics,based,on,a,regular,expression,pattern,p,if,partition,discovery,is,enabled,by,setting,a,non,negative,value,for,link,flink,kafka,consumer,in,the,properties,topics,with,names,matching,the,pattern,will,also,be,subscribed,to,as,they,are,created,on,the,fly,p,this,constructor,allows,passing,a,see,keyed,deserialization,schema,for,reading,key,value,pairs,offsets,and,topic,names,from,kafka,param,subscription,pattern,the,regular,expression,for,a,pattern,of,topic,names,to,subscribe,to,param,deserializer,the,keyed,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,pattern,subscription,pattern,keyed,deserialization,schema,t,deserializer,properties,props,this,null,subscription,pattern,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(Pattern subscriptionPattern, KeyedDeserializationSchema<T> deserializer, Properties props);1550834388;Creates a new Kafka streaming source consumer. Use this constructor to_subscribe to multiple topics based on a regular expression pattern.__<p>If partition discovery is enabled (by setting a non-negative value for_{@link FlinkKafkaConsumer#KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS} in the properties), topics_with names matching the pattern will also be subscribed to as they are created on the fly.__<p>This constructor allows passing a {@see KeyedDeserializationSchema} for reading key/value_pairs, offsets, and topic names from Kafka.__@param subscriptionPattern The regular expression for a pattern of topic names to subscribe to._@param deserializer        The keyed de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(Pattern subscriptionPattern, KeyedDeserializationSchema<T> deserializer, Properties props) {_		this(null, subscriptionPattern, deserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,use,this,constructor,to,subscribe,to,multiple,topics,based,on,a,regular,expression,pattern,p,if,partition,discovery,is,enabled,by,setting,a,non,negative,value,for,link,flink,kafka,consumer,in,the,properties,topics,with,names,matching,the,pattern,will,also,be,subscribed,to,as,they,are,created,on,the,fly,p,this,constructor,allows,passing,a,see,keyed,deserialization,schema,for,reading,key,value,pairs,offsets,and,topic,names,from,kafka,param,subscription,pattern,the,regular,expression,for,a,pattern,of,topic,names,to,subscribe,to,param,deserializer,the,keyed,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,pattern,subscription,pattern,keyed,deserialization,schema,t,deserializer,properties,props,this,null,subscription,pattern,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(String topic, KeyedDeserializationSchema<T> deserializer, Properties props);1539704473;Creates a new Kafka streaming source consumer.__<p>This constructor allows passing a {@see KeyedDeserializationSchema} for reading key/value_pairs, offsets, and topic names from Kafka.__@param topic        The name of the topic that should be consumed._@param deserializer The keyed de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(String topic, KeyedDeserializationSchema<T> deserializer, Properties props) {_		this(Collections.singletonList(topic), deserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,p,this,constructor,allows,passing,a,see,keyed,deserialization,schema,for,reading,key,value,pairs,offsets,and,topic,names,from,kafka,param,topic,the,name,of,the,topic,that,should,be,consumed,param,deserializer,the,keyed,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,string,topic,keyed,deserialization,schema,t,deserializer,properties,props,this,collections,singleton,list,topic,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(String topic, KeyedDeserializationSchema<T> deserializer, Properties props);1548860009;Creates a new Kafka streaming source consumer.__<p>This constructor allows passing a {@see KeyedDeserializationSchema} for reading key/value_pairs, offsets, and topic names from Kafka.__@param topic        The name of the topic that should be consumed._@param deserializer The keyed de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(String topic, KeyedDeserializationSchema<T> deserializer, Properties props) {_		this(Collections.singletonList(topic), deserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,p,this,constructor,allows,passing,a,see,keyed,deserialization,schema,for,reading,key,value,pairs,offsets,and,topic,names,from,kafka,param,topic,the,name,of,the,topic,that,should,be,consumed,param,deserializer,the,keyed,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,string,topic,keyed,deserialization,schema,t,deserializer,properties,props,this,collections,singleton,list,topic,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(String topic, KeyedDeserializationSchema<T> deserializer, Properties props);1550834388;Creates a new Kafka streaming source consumer.__<p>This constructor allows passing a {@see KeyedDeserializationSchema} for reading key/value_pairs, offsets, and topic names from Kafka.__@param topic        The name of the topic that should be consumed._@param deserializer The keyed de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(String topic, KeyedDeserializationSchema<T> deserializer, Properties props) {_		this(Collections.singletonList(topic), deserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,p,this,constructor,allows,passing,a,see,keyed,deserialization,schema,for,reading,key,value,pairs,offsets,and,topic,names,from,kafka,param,topic,the,name,of,the,topic,that,should,be,consumed,param,deserializer,the,keyed,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,string,topic,keyed,deserialization,schema,t,deserializer,properties,props,this,collections,singleton,list,topic,deserializer,props
FlinkKafkaConsumer -> private static void setDeserializer(Properties props);1539704473;Makes sure that the ByteArrayDeserializer is registered in the Kafka properties.__@param props The Kafka properties to register the serializer in.;private static void setDeserializer(Properties props) {_		final String deSerName = ByteArrayDeserializer.class.getName()___		Object keyDeSer = props.get(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG)__		Object valDeSer = props.get(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG)___		if (keyDeSer != null && !keyDeSer.equals(deSerName)) {_			LOG.warn("Ignoring configured key DeSerializer ({})", ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG)__		}_		if (valDeSer != null && !valDeSer.equals(deSerName)) {_			LOG.warn("Ignoring configured value DeSerializer ({})", ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG)__		}__		props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, deSerName)__		props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, deSerName)__	};makes,sure,that,the,byte,array,deserializer,is,registered,in,the,kafka,properties,param,props,the,kafka,properties,to,register,the,serializer,in;private,static,void,set,deserializer,properties,props,final,string,de,ser,name,byte,array,deserializer,class,get,name,object,key,de,ser,props,get,consumer,config,object,val,de,ser,props,get,consumer,config,if,key,de,ser,null,key,de,ser,equals,de,ser,name,log,warn,ignoring,configured,key,de,serializer,consumer,config,if,val,de,ser,null,val,de,ser,equals,de,ser,name,log,warn,ignoring,configured,value,de,serializer,consumer,config,props,put,consumer,config,de,ser,name,props,put,consumer,config,de,ser,name
FlinkKafkaConsumer -> private static void setDeserializer(Properties props);1548860009;Makes sure that the ByteArrayDeserializer is registered in the Kafka properties.__@param props The Kafka properties to register the serializer in.;private static void setDeserializer(Properties props) {_		final String deSerName = ByteArrayDeserializer.class.getName()___		Object keyDeSer = props.get(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG)__		Object valDeSer = props.get(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG)___		if (keyDeSer != null && !keyDeSer.equals(deSerName)) {_			LOG.warn("Ignoring configured key DeSerializer ({})", ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG)__		}_		if (valDeSer != null && !valDeSer.equals(deSerName)) {_			LOG.warn("Ignoring configured value DeSerializer ({})", ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG)__		}__		props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, deSerName)__		props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, deSerName)__	};makes,sure,that,the,byte,array,deserializer,is,registered,in,the,kafka,properties,param,props,the,kafka,properties,to,register,the,serializer,in;private,static,void,set,deserializer,properties,props,final,string,de,ser,name,byte,array,deserializer,class,get,name,object,key,de,ser,props,get,consumer,config,object,val,de,ser,props,get,consumer,config,if,key,de,ser,null,key,de,ser,equals,de,ser,name,log,warn,ignoring,configured,key,de,serializer,consumer,config,if,val,de,ser,null,val,de,ser,equals,de,ser,name,log,warn,ignoring,configured,value,de,serializer,consumer,config,props,put,consumer,config,de,ser,name,props,put,consumer,config,de,ser,name
FlinkKafkaConsumer -> private static void setDeserializer(Properties props);1550834388;Makes sure that the ByteArrayDeserializer is registered in the Kafka properties.__@param props The Kafka properties to register the serializer in.;private static void setDeserializer(Properties props) {_		final String deSerName = ByteArrayDeserializer.class.getName()___		Object keyDeSer = props.get(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG)__		Object valDeSer = props.get(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG)___		if (keyDeSer != null && !keyDeSer.equals(deSerName)) {_			LOG.warn("Ignoring configured key DeSerializer ({})", ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG)__		}_		if (valDeSer != null && !valDeSer.equals(deSerName)) {_			LOG.warn("Ignoring configured value DeSerializer ({})", ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG)__		}__		props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, deSerName)__		props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, deSerName)__	};makes,sure,that,the,byte,array,deserializer,is,registered,in,the,kafka,properties,param,props,the,kafka,properties,to,register,the,serializer,in;private,static,void,set,deserializer,properties,props,final,string,de,ser,name,byte,array,deserializer,class,get,name,object,key,de,ser,props,get,consumer,config,object,val,de,ser,props,get,consumer,config,if,key,de,ser,null,key,de,ser,equals,de,ser,name,log,warn,ignoring,configured,key,de,serializer,consumer,config,if,val,de,ser,null,val,de,ser,equals,de,ser,name,log,warn,ignoring,configured,value,de,serializer,consumer,config,props,put,consumer,config,de,ser,name,props,put,consumer,config,de,ser,name
FlinkKafkaConsumer -> private static void setDeserializer(Properties props);1550834396;Makes sure that the ByteArrayDeserializer is registered in the Kafka properties.__@param props The Kafka properties to register the serializer in.;private static void setDeserializer(Properties props) {_		final String deSerName = ByteArrayDeserializer.class.getName()___		Object keyDeSer = props.get(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG)__		Object valDeSer = props.get(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG)___		if (keyDeSer != null && !keyDeSer.equals(deSerName)) {_			LOG.warn("Ignoring configured key DeSerializer ({})", ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG)__		}_		if (valDeSer != null && !valDeSer.equals(deSerName)) {_			LOG.warn("Ignoring configured value DeSerializer ({})", ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG)__		}__		props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, deSerName)__		props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, deSerName)__	};makes,sure,that,the,byte,array,deserializer,is,registered,in,the,kafka,properties,param,props,the,kafka,properties,to,register,the,serializer,in;private,static,void,set,deserializer,properties,props,final,string,de,ser,name,byte,array,deserializer,class,get,name,object,key,de,ser,props,get,consumer,config,object,val,de,ser,props,get,consumer,config,if,key,de,ser,null,key,de,ser,equals,de,ser,name,log,warn,ignoring,configured,key,de,serializer,consumer,config,if,val,de,ser,null,val,de,ser,equals,de,ser,name,log,warn,ignoring,configured,value,de,serializer,consumer,config,props,put,consumer,config,de,ser,name,props,put,consumer,config,de,ser,name
FlinkKafkaConsumer -> public FlinkKafkaConsumer(String topic, DeserializationSchema<T> valueDeserializer, Properties props);1539704473;Creates a new Kafka streaming source consumer.__@param topic             The name of the topic that should be consumed._@param valueDeserializer The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(String topic, DeserializationSchema<T> valueDeserializer, Properties props) {_		this(Collections.singletonList(topic), valueDeserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,param,topic,the,name,of,the,topic,that,should,be,consumed,param,value,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,string,topic,deserialization,schema,t,value,deserializer,properties,props,this,collections,singleton,list,topic,value,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(String topic, DeserializationSchema<T> valueDeserializer, Properties props);1548860009;Creates a new Kafka streaming source consumer.__@param topic             The name of the topic that should be consumed._@param valueDeserializer The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(String topic, DeserializationSchema<T> valueDeserializer, Properties props) {_		this(Collections.singletonList(topic), valueDeserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,param,topic,the,name,of,the,topic,that,should,be,consumed,param,value,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,string,topic,deserialization,schema,t,value,deserializer,properties,props,this,collections,singleton,list,topic,value,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(String topic, DeserializationSchema<T> valueDeserializer, Properties props);1550834388;Creates a new Kafka streaming source consumer.__@param topic             The name of the topic that should be consumed._@param valueDeserializer The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(String topic, DeserializationSchema<T> valueDeserializer, Properties props) {_		this(Collections.singletonList(topic), valueDeserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,param,topic,the,name,of,the,topic,that,should,be,consumed,param,value,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,string,topic,deserialization,schema,t,value,deserializer,properties,props,this,collections,singleton,list,topic,value,deserializer,props
FlinkKafkaConsumer -> public FlinkKafkaConsumer(String topic, DeserializationSchema<T> valueDeserializer, Properties props);1550834396;Creates a new Kafka streaming source consumer.__@param topic             The name of the topic that should be consumed._@param valueDeserializer The de-/serializer used to convert between Kafka's byte messages and Flink's objects._@param props;public FlinkKafkaConsumer(String topic, DeserializationSchema<T> valueDeserializer, Properties props) {_		this(Collections.singletonList(topic), valueDeserializer, props)__	};creates,a,new,kafka,streaming,source,consumer,param,topic,the,name,of,the,topic,that,should,be,consumed,param,value,deserializer,the,de,serializer,used,to,convert,between,kafka,s,byte,messages,and,flink,s,objects,param,props;public,flink,kafka,consumer,string,topic,deserialization,schema,t,value,deserializer,properties,props,this,collections,singleton,list,topic,value,deserializer,props
