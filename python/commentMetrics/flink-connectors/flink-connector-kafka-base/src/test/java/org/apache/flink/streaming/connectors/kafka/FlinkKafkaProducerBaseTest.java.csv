# id;timestamp;commentText;codeText;commentWords;codeWords
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout=5000) 	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable;1487783817;This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,_the snapshot method does indeed finishes without waiting for pending records__we set a timeout because the test will not finish if the logic is broken;@SuppressWarnings("unchecked")_	@Test(timeout=5000)_	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), null)__		producer.setFlushOnCheckpoint(false)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg"))___		_		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class))___		_		testHarness.snapshot(123L, 123L)___		testHarness.close()__	};this,test,is,meant,to,assure,that,test,at,least,once,producer,is,valid,by,testing,that,if,flushing,is,disabled,the,snapshot,method,does,indeed,finishes,without,waiting,for,pending,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,5000,public,void,test,does,not,wait,for,pending,records,if,flushing,disabled,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,null,producer,set,flush,on,checkpoint,false,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,verify,mock,producer,times,1,send,any,producer,record,class,any,callback,class,test,harness,snapshot,123l,123l,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout=5000) 	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable;1495175928;This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,_the snapshot method does indeed finishes without waiting for pending records__we set a timeout because the test will not finish if the logic is broken;@SuppressWarnings("unchecked")_	@Test(timeout=5000)_	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(false)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg"))___		_		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class))___		_		testHarness.snapshot(123L, 123L)___		testHarness.close()__	};this,test,is,meant,to,assure,that,test,at,least,once,producer,is,valid,by,testing,that,if,flushing,is,disabled,the,snapshot,method,does,indeed,finishes,without,waiting,for,pending,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,5000,public,void,test,does,not,wait,for,pending,records,if,flushing,disabled,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,false,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,verify,mock,producer,times,1,send,any,producer,record,class,any,callback,class,test,harness,snapshot,123l,123l,test,harness,close
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable;1487783817;Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown;@Test_	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.snapshot(123L, 123L)__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,a,snapshot,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,checkpoint,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,snapshot,123l,123l,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable;1495175928;Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown;@Test_	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.snapshot(123L, 123L)__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,a,snapshot,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,checkpoint,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,snapshot,123l,123l,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable;1495923077;Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.snapshot(123L, 123L)__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,a,snapshot,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,checkpoint,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,snapshot,123l,123l,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable;1505994377;Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.snapshot(123L, 123L)__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,a,snapshot,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,checkpoint,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,snapshot,123l,123l,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable;1509723634;Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.snapshot(123L, 123L)__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,a,snapshot,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,checkpoint,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,snapshot,123l,123l,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable;1515177485;Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.snapshot(123L, 123L)__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,a,snapshot,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,checkpoint,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,snapshot,123l,123l,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable;1518770239;Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.snapshot(123L, 123L)__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,a,snapshot,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,checkpoint,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,snapshot,123l,123l,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable;1520440672;Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.snapshot(123L, 123L)__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,a,snapshot,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,checkpoint,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,snapshot,123l,123l,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable;1538998760;Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.snapshot(123L, 123L)__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,a,snapshot,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,checkpoint,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,snapshot,123l,123l,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnInvoke() throws Throwable;1487783817;Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown;@Test_	public void testAsyncErrorRethrownOnInvoke() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.processElement(new StreamRecord<>("msg-2"))__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,invoke,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,invoke,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,process,element,new,stream,record,msg,2,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnInvoke() throws Throwable;1495175928;Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown;@Test_	public void testAsyncErrorRethrownOnInvoke() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.processElement(new StreamRecord<>("msg-2"))__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,invoke,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,invoke,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,process,element,new,stream,record,msg,2,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnInvoke() throws Throwable;1495923077;Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnInvoke() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.processElement(new StreamRecord<>("msg-2"))__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,invoke,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,invoke,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,process,element,new,stream,record,msg,2,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnInvoke() throws Throwable;1505994377;Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnInvoke() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.processElement(new StreamRecord<>("msg-2"))__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,invoke,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,invoke,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,process,element,new,stream,record,msg,2,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnInvoke() throws Throwable;1509723634;Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnInvoke() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.processElement(new StreamRecord<>("msg-2"))__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,invoke,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,invoke,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,process,element,new,stream,record,msg,2,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnInvoke() throws Throwable;1515177485;Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnInvoke() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.processElement(new StreamRecord<>("msg-2"))__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,invoke,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,invoke,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,process,element,new,stream,record,msg,2,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnInvoke() throws Throwable;1518770239;Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnInvoke() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.processElement(new StreamRecord<>("msg-2"))__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,invoke,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,invoke,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,process,element,new,stream,record,msg,2,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnInvoke() throws Throwable;1520440672;Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnInvoke() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.processElement(new StreamRecord<>("msg-2"))__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,invoke,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,invoke,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,process,element,new,stream,record,msg,2,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testAsyncErrorRethrownOnInvoke() throws Throwable;1538998760;Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown.;@Test_	public void testAsyncErrorRethrownOnInvoke() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception("artificial async exception"))___		try {_			testHarness.processElement(new StreamRecord<>("msg-2"))__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async exception"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,invoke,call,happens,right,after,an,async,exception,is,caught,it,should,be,rethrown;test,public,void,test,async,error,rethrown,on,invoke,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,producer,get,pending,callbacks,get,0,on,completion,null,new,exception,artificial,async,exception,try,test,harness,process,element,new,stream,record,msg,2,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,exception,return,assert,fail
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable;1495923077;Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,_it should be rethrown_ we set a timeout because the test will not finish if the logic is broken.__<p>Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds._The test for that is covered in testAtLeastOnceProducer.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)___		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception("artificial async failure for 2nd message"))__		producer.getPendingCallbacks().get(2).onCompletion(null, null)___		try {_			snapshotThread.sync()__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async failure for 2nd message"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,async,exception,is,caught,for,one,of,the,flushed,requests,on,checkpoint,it,should,be,rethrown,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken,p,note,that,this,test,does,not,test,the,snapshot,method,is,blocked,correctly,when,there,are,pending,recorrds,the,test,for,that,is,covered,in,test,at,least,once,producer;suppress,warnings,unchecked,test,timeout,5000,public,void,test,async,error,rethrown,on,checkpoint,after,flush,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,producer,get,pending,callbacks,get,0,on,completion,null,null,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,get,pending,callbacks,get,1,on,completion,null,new,exception,artificial,async,failure,for,2nd,message,producer,get,pending,callbacks,get,2,on,completion,null,null,try,snapshot,thread,sync,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,failure,for,2nd,message,return,assert,fail
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable;1505994377;Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,_it should be rethrown_ we set a timeout because the test will not finish if the logic is broken.__<p>Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds._The test for that is covered in testAtLeastOnceProducer.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)___		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception("artificial async failure for 2nd message"))__		producer.getPendingCallbacks().get(2).onCompletion(null, null)___		try {_			snapshotThread.sync()__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async failure for 2nd message"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,async,exception,is,caught,for,one,of,the,flushed,requests,on,checkpoint,it,should,be,rethrown,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken,p,note,that,this,test,does,not,test,the,snapshot,method,is,blocked,correctly,when,there,are,pending,recorrds,the,test,for,that,is,covered,in,test,at,least,once,producer;suppress,warnings,unchecked,test,timeout,5000,public,void,test,async,error,rethrown,on,checkpoint,after,flush,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,producer,get,pending,callbacks,get,0,on,completion,null,null,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,get,pending,callbacks,get,1,on,completion,null,new,exception,artificial,async,failure,for,2nd,message,producer,get,pending,callbacks,get,2,on,completion,null,null,try,snapshot,thread,sync,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,failure,for,2nd,message,return,assert,fail
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable;1509723634;Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,_it should be rethrown_ we set a timeout because the test will not finish if the logic is broken.__<p>Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds._The test for that is covered in testAtLeastOnceProducer.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)___		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception("artificial async failure for 2nd message"))__		producer.getPendingCallbacks().get(2).onCompletion(null, null)___		try {_			snapshotThread.sync()__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async failure for 2nd message"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,async,exception,is,caught,for,one,of,the,flushed,requests,on,checkpoint,it,should,be,rethrown,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken,p,note,that,this,test,does,not,test,the,snapshot,method,is,blocked,correctly,when,there,are,pending,recorrds,the,test,for,that,is,covered,in,test,at,least,once,producer;suppress,warnings,unchecked,test,timeout,5000,public,void,test,async,error,rethrown,on,checkpoint,after,flush,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,producer,get,pending,callbacks,get,0,on,completion,null,null,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,get,pending,callbacks,get,1,on,completion,null,new,exception,artificial,async,failure,for,2nd,message,producer,get,pending,callbacks,get,2,on,completion,null,null,try,snapshot,thread,sync,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,failure,for,2nd,message,return,assert,fail
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable;1515177485;Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,_it should be rethrown_ we set a timeout because the test will not finish if the logic is broken.__<p>Note that this test does not test the snapshot method is blocked correctly when there are pending records._The test for that is covered in testAtLeastOnceProducer.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)___		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception("artificial async failure for 2nd message"))__		producer.getPendingCallbacks().get(2).onCompletion(null, null)___		try {_			snapshotThread.sync()__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async failure for 2nd message"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,async,exception,is,caught,for,one,of,the,flushed,requests,on,checkpoint,it,should,be,rethrown,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken,p,note,that,this,test,does,not,test,the,snapshot,method,is,blocked,correctly,when,there,are,pending,records,the,test,for,that,is,covered,in,test,at,least,once,producer;suppress,warnings,unchecked,test,timeout,5000,public,void,test,async,error,rethrown,on,checkpoint,after,flush,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,producer,get,pending,callbacks,get,0,on,completion,null,null,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,get,pending,callbacks,get,1,on,completion,null,new,exception,artificial,async,failure,for,2nd,message,producer,get,pending,callbacks,get,2,on,completion,null,null,try,snapshot,thread,sync,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,failure,for,2nd,message,return,assert,fail
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable;1518770239;Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,_it should be rethrown_ we set a timeout because the test will not finish if the logic is broken.__<p>Note that this test does not test the snapshot method is blocked correctly when there are pending records._The test for that is covered in testAtLeastOnceProducer.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)___		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception("artificial async failure for 2nd message"))__		producer.getPendingCallbacks().get(2).onCompletion(null, null)___		try {_			snapshotThread.sync()__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async failure for 2nd message"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,async,exception,is,caught,for,one,of,the,flushed,requests,on,checkpoint,it,should,be,rethrown,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken,p,note,that,this,test,does,not,test,the,snapshot,method,is,blocked,correctly,when,there,are,pending,records,the,test,for,that,is,covered,in,test,at,least,once,producer;suppress,warnings,unchecked,test,timeout,5000,public,void,test,async,error,rethrown,on,checkpoint,after,flush,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,producer,get,pending,callbacks,get,0,on,completion,null,null,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,get,pending,callbacks,get,1,on,completion,null,new,exception,artificial,async,failure,for,2nd,message,producer,get,pending,callbacks,get,2,on,completion,null,null,try,snapshot,thread,sync,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,failure,for,2nd,message,return,assert,fail
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable;1520440672;Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,_it should be rethrown_ we set a timeout because the test will not finish if the logic is broken.__<p>Note that this test does not test the snapshot method is blocked correctly when there are pending records._The test for that is covered in testAtLeastOnceProducer.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)___		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception("artificial async failure for 2nd message"))__		producer.getPendingCallbacks().get(2).onCompletion(null, null)___		try {_			snapshotThread.sync()__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async failure for 2nd message"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,async,exception,is,caught,for,one,of,the,flushed,requests,on,checkpoint,it,should,be,rethrown,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken,p,note,that,this,test,does,not,test,the,snapshot,method,is,blocked,correctly,when,there,are,pending,records,the,test,for,that,is,covered,in,test,at,least,once,producer;suppress,warnings,unchecked,test,timeout,5000,public,void,test,async,error,rethrown,on,checkpoint,after,flush,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,producer,get,pending,callbacks,get,0,on,completion,null,null,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,get,pending,callbacks,get,1,on,completion,null,new,exception,artificial,async,failure,for,2nd,message,producer,get,pending,callbacks,get,2,on,completion,null,null,try,snapshot,thread,sync,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,failure,for,2nd,message,return,assert,fail
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable;1538998760;Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,_it should be rethrown_ we set a timeout because the test will not finish if the logic is broken.__<p>Note that this test does not test the snapshot method is blocked correctly when there are pending records._The test for that is covered in testAtLeastOnceProducer.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)___		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception("artificial async failure for 2nd message"))__		producer.getPendingCallbacks().get(2).onCompletion(null, null)___		try {_			snapshotThread.sync()__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async failure for 2nd message"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,async,exception,is,caught,for,one,of,the,flushed,requests,on,checkpoint,it,should,be,rethrown,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken,p,note,that,this,test,does,not,test,the,snapshot,method,is,blocked,correctly,when,there,are,pending,records,the,test,for,that,is,covered,in,test,at,least,once,producer;suppress,warnings,unchecked,test,timeout,5000,public,void,test,async,error,rethrown,on,checkpoint,after,flush,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,producer,get,pending,callbacks,get,0,on,completion,null,null,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,get,pending,callbacks,get,1,on,completion,null,new,exception,artificial,async,failure,for,2nd,message,producer,get,pending,callbacks,get,2,on,completion,null,null,try,snapshot,thread,sync,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,failure,for,2nd,message,return,assert,fail
FlinkKafkaProducerBaseTest -> @Test 	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception;1480685315;Tests that partitions list is determinate and correctly provided to custom partitioner;@Test_	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {_		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class)__		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class)__		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0)__		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1)___		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(_			FakeStandardProducerConfig.get(), mockPartitioner)__		producer.setRuntimeContext(mockRuntimeContext)___		producer.open(new Configuration())___		_		_		int[] correctPartitionList = {0, 1, 2, 3}__		verify(mockPartitioner).open(0, 1, correctPartitionList)__	};tests,that,partitions,list,is,determinate,and,correctly,provided,to,custom,partitioner;test,public,void,test,partitioner,opened,with,determinate,partition,list,throws,exception,kafka,partitioner,mock,partitioner,mock,kafka,partitioner,class,runtime,context,mock,runtime,context,mock,runtime,context,class,when,mock,runtime,context,get,index,of,this,subtask,then,return,0,when,mock,runtime,context,get,number,of,parallel,subtasks,then,return,1,dummy,flink,kafka,producer,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,mock,partitioner,producer,set,runtime,context,mock,runtime,context,producer,open,new,configuration,int,correct,partition,list,0,1,2,3,verify,mock,partitioner,open,0,1,correct,partition,list
FlinkKafkaProducerBaseTest -> @Test 	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception;1487783817;Tests that partitions list is determinate and correctly provided to custom partitioner;@Test_	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {_		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class)___		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class)__		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0)__		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1)__		_		_		List<PartitionInfo> mockPartitionsList = new ArrayList<>(4)__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null))___		final DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(_			FakeStandardProducerConfig.get(), mockPartitioner)__		producer.setRuntimeContext(mockRuntimeContext)___		final KafkaProducer mockProducer = producer.getMockKafkaProducer()__		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList)__		when(mockProducer.metrics()).thenReturn(null)___		producer.open(new Configuration())___		_		int[] correctPartitionList = {0, 1, 2, 3}__		verify(mockPartitioner).open(0, 1, correctPartitionList)__	};tests,that,partitions,list,is,determinate,and,correctly,provided,to,custom,partitioner;test,public,void,test,partitioner,opened,with,determinate,partition,list,throws,exception,kafka,partitioner,mock,partitioner,mock,kafka,partitioner,class,runtime,context,mock,runtime,context,mock,runtime,context,class,when,mock,runtime,context,get,index,of,this,subtask,then,return,0,when,mock,runtime,context,get,number,of,parallel,subtasks,then,return,1,list,partition,info,mock,partitions,list,new,array,list,4,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,3,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,1,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,0,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,2,null,null,null,final,dummy,flink,kafka,producer,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,mock,partitioner,producer,set,runtime,context,mock,runtime,context,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,when,mock,producer,partitions,for,any,string,then,return,mock,partitions,list,when,mock,producer,metrics,then,return,null,producer,open,new,configuration,int,correct,partition,list,0,1,2,3,verify,mock,partitioner,open,0,1,correct,partition,list
FlinkKafkaProducerBaseTest -> @Test(expected = IllegalArgumentException.class) 	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception;1480685315;Tests that the constructor eagerly checks bootstrap servers are set in config;@Test(expected = IllegalArgumentException.class)_	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception {_		_		Properties props = new Properties()__		_		new DummyFlinkKafkaProducer<>(props, null)__	};tests,that,the,constructor,eagerly,checks,bootstrap,servers,are,set,in,config;test,expected,illegal,argument,exception,class,public,void,test,instantiation,fails,when,bootstrap,servers,missing,throws,exception,properties,props,new,properties,new,dummy,flink,kafka,producer,props,null
FlinkKafkaProducerBaseTest -> @Test(expected = IllegalArgumentException.class) 	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception;1487783817;Tests that the constructor eagerly checks bootstrap servers are set in config;@Test(expected = IllegalArgumentException.class)_	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception {_		_		Properties props = new Properties()__		_		new DummyFlinkKafkaProducer<>(props, null)__	};tests,that,the,constructor,eagerly,checks,bootstrap,servers,are,set,in,config;test,expected,illegal,argument,exception,class,public,void,test,instantiation,fails,when,bootstrap,servers,missing,throws,exception,properties,props,new,properties,new,dummy,flink,kafka,producer,props,null
FlinkKafkaProducerBaseTest -> @Test(expected = IllegalArgumentException.class) 	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception;1495175928;Tests that the constructor eagerly checks bootstrap servers are set in config;@Test(expected = IllegalArgumentException.class)_	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception {_		_		Properties props = new Properties()__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__	};tests,that,the,constructor,eagerly,checks,bootstrap,servers,are,set,in,config;test,expected,illegal,argument,exception,class,public,void,test,instantiation,fails,when,bootstrap,servers,missing,throws,exception,properties,props,new,properties,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null
FlinkKafkaProducerBaseTest -> @Test(expected = IllegalArgumentException.class) 	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception;1495923077;Tests that the constructor eagerly checks bootstrap servers are set in config.;@Test(expected = IllegalArgumentException.class)_	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception {_		_		Properties props = new Properties()__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__	};tests,that,the,constructor,eagerly,checks,bootstrap,servers,are,set,in,config;test,expected,illegal,argument,exception,class,public,void,test,instantiation,fails,when,bootstrap,servers,missing,throws,exception,properties,props,new,properties,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null
FlinkKafkaProducerBaseTest -> @Test(expected = IllegalArgumentException.class) 	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception;1505994377;Tests that the constructor eagerly checks bootstrap servers are set in config.;@Test(expected = IllegalArgumentException.class)_	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception {_		_		Properties props = new Properties()__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__	};tests,that,the,constructor,eagerly,checks,bootstrap,servers,are,set,in,config;test,expected,illegal,argument,exception,class,public,void,test,instantiation,fails,when,bootstrap,servers,missing,throws,exception,properties,props,new,properties,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null
FlinkKafkaProducerBaseTest -> @Test(expected = IllegalArgumentException.class) 	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception;1509723634;Tests that the constructor eagerly checks bootstrap servers are set in config.;@Test(expected = IllegalArgumentException.class)_	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception {_		_		Properties props = new Properties()__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__	};tests,that,the,constructor,eagerly,checks,bootstrap,servers,are,set,in,config;test,expected,illegal,argument,exception,class,public,void,test,instantiation,fails,when,bootstrap,servers,missing,throws,exception,properties,props,new,properties,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null
FlinkKafkaProducerBaseTest -> @Test(expected = IllegalArgumentException.class) 	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception;1515177485;Tests that the constructor eagerly checks bootstrap servers are set in config.;@Test(expected = IllegalArgumentException.class)_	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception {_		_		Properties props = new Properties()__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__	};tests,that,the,constructor,eagerly,checks,bootstrap,servers,are,set,in,config;test,expected,illegal,argument,exception,class,public,void,test,instantiation,fails,when,bootstrap,servers,missing,throws,exception,properties,props,new,properties,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null
FlinkKafkaProducerBaseTest -> @Test(expected = IllegalArgumentException.class) 	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception;1518770239;Tests that the constructor eagerly checks bootstrap servers are set in config.;@Test(expected = IllegalArgumentException.class)_	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception {_		_		Properties props = new Properties()__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__	};tests,that,the,constructor,eagerly,checks,bootstrap,servers,are,set,in,config;test,expected,illegal,argument,exception,class,public,void,test,instantiation,fails,when,bootstrap,servers,missing,throws,exception,properties,props,new,properties,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null
FlinkKafkaProducerBaseTest -> @Test(expected = IllegalArgumentException.class) 	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception;1520440672;Tests that the constructor eagerly checks bootstrap servers are set in config.;@Test(expected = IllegalArgumentException.class)_	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception {_		_		Properties props = new Properties()__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__	};tests,that,the,constructor,eagerly,checks,bootstrap,servers,are,set,in,config;test,expected,illegal,argument,exception,class,public,void,test,instantiation,fails,when,bootstrap,servers,missing,throws,exception,properties,props,new,properties,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null
FlinkKafkaProducerBaseTest -> @Test(expected = IllegalArgumentException.class) 	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception;1538998760;Tests that the constructor eagerly checks bootstrap servers are set in config.;@Test(expected = IllegalArgumentException.class)_	public void testInstantiationFailsWhenBootstrapServersMissing() throws Exception {_		_		Properties props = new Properties()__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__	};tests,that,the,constructor,eagerly,checks,bootstrap,servers,are,set,in,config;test,expected,illegal,argument,exception,class,public,void,test,instantiation,fails,when,bootstrap,servers,missing,throws,exception,properties,props,new,properties,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 10000) 	public void testAtLeastOnceProducer() throws Throwable;1495923077;Test ensuring that the producer is not dropping buffered records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 10000)_	public void testAtLeastOnceProducer() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))__		Assert.assertEquals(3, producer.getPendingSize())___		_		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		_		producer.waitUntilFlushStarted()__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(2, producer.getPendingSize())___		producer.getPendingCallbacks().get(1).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(1, producer.getPendingSize())___		producer.getPendingCallbacks().get(2).onCompletion(null, null)__		Assert.assertEquals(0, producer.getPendingSize())___		_		snapshotThread.sync()___		testHarness.close()__	};test,ensuring,that,the,producer,is,not,dropping,buffered,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,10000,public,void,test,at,least,once,producer,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,assert,assert,equals,3,producer,get,pending,size,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,wait,until,flush,started,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,producer,get,pending,callbacks,get,0,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,2,producer,get,pending,size,producer,get,pending,callbacks,get,1,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,1,producer,get,pending,size,producer,get,pending,callbacks,get,2,on,completion,null,null,assert,assert,equals,0,producer,get,pending,size,snapshot,thread,sync,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 10000) 	public void testAtLeastOnceProducer() throws Throwable;1505994377;Test ensuring that the producer is not dropping buffered records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 10000)_	public void testAtLeastOnceProducer() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))__		Assert.assertEquals(3, producer.getPendingSize())___		_		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		_		producer.waitUntilFlushStarted()__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(2, producer.getPendingSize())___		producer.getPendingCallbacks().get(1).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(1, producer.getPendingSize())___		producer.getPendingCallbacks().get(2).onCompletion(null, null)__		Assert.assertEquals(0, producer.getPendingSize())___		_		snapshotThread.sync()___		testHarness.close()__	};test,ensuring,that,the,producer,is,not,dropping,buffered,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,10000,public,void,test,at,least,once,producer,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,assert,assert,equals,3,producer,get,pending,size,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,wait,until,flush,started,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,producer,get,pending,callbacks,get,0,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,2,producer,get,pending,size,producer,get,pending,callbacks,get,1,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,1,producer,get,pending,size,producer,get,pending,callbacks,get,2,on,completion,null,null,assert,assert,equals,0,producer,get,pending,size,snapshot,thread,sync,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 10000) 	public void testAtLeastOnceProducer() throws Throwable;1509723634;Test ensuring that the producer is not dropping buffered records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 10000)_	public void testAtLeastOnceProducer() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))__		Assert.assertEquals(3, producer.getPendingSize())___		_		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		_		producer.waitUntilFlushStarted()__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(2, producer.getPendingSize())___		producer.getPendingCallbacks().get(1).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(1, producer.getPendingSize())___		producer.getPendingCallbacks().get(2).onCompletion(null, null)__		Assert.assertEquals(0, producer.getPendingSize())___		_		snapshotThread.sync()___		testHarness.close()__	};test,ensuring,that,the,producer,is,not,dropping,buffered,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,10000,public,void,test,at,least,once,producer,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,assert,assert,equals,3,producer,get,pending,size,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,wait,until,flush,started,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,producer,get,pending,callbacks,get,0,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,2,producer,get,pending,size,producer,get,pending,callbacks,get,1,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,1,producer,get,pending,size,producer,get,pending,callbacks,get,2,on,completion,null,null,assert,assert,equals,0,producer,get,pending,size,snapshot,thread,sync,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 10000) 	public void testAtLeastOnceProducer() throws Throwable;1515177485;Test ensuring that the producer is not dropping buffered records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 10000)_	public void testAtLeastOnceProducer() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))__		Assert.assertEquals(3, producer.getPendingSize())___		_		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		_		producer.waitUntilFlushStarted()__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(2, producer.getPendingSize())___		producer.getPendingCallbacks().get(1).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(1, producer.getPendingSize())___		producer.getPendingCallbacks().get(2).onCompletion(null, null)__		Assert.assertEquals(0, producer.getPendingSize())___		_		snapshotThread.sync()___		testHarness.close()__	};test,ensuring,that,the,producer,is,not,dropping,buffered,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,10000,public,void,test,at,least,once,producer,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,assert,assert,equals,3,producer,get,pending,size,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,wait,until,flush,started,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,producer,get,pending,callbacks,get,0,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,2,producer,get,pending,size,producer,get,pending,callbacks,get,1,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,1,producer,get,pending,size,producer,get,pending,callbacks,get,2,on,completion,null,null,assert,assert,equals,0,producer,get,pending,size,snapshot,thread,sync,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 10000) 	public void testAtLeastOnceProducer() throws Throwable;1518770239;Test ensuring that the producer is not dropping buffered records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 10000)_	public void testAtLeastOnceProducer() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))__		Assert.assertEquals(3, producer.getPendingSize())___		_		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		_		producer.waitUntilFlushStarted()__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(2, producer.getPendingSize())___		producer.getPendingCallbacks().get(1).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(1, producer.getPendingSize())___		producer.getPendingCallbacks().get(2).onCompletion(null, null)__		Assert.assertEquals(0, producer.getPendingSize())___		_		snapshotThread.sync()___		testHarness.close()__	};test,ensuring,that,the,producer,is,not,dropping,buffered,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,10000,public,void,test,at,least,once,producer,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,assert,assert,equals,3,producer,get,pending,size,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,wait,until,flush,started,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,producer,get,pending,callbacks,get,0,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,2,producer,get,pending,size,producer,get,pending,callbacks,get,1,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,1,producer,get,pending,size,producer,get,pending,callbacks,get,2,on,completion,null,null,assert,assert,equals,0,producer,get,pending,size,snapshot,thread,sync,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 10000) 	public void testAtLeastOnceProducer() throws Throwable;1520440672;Test ensuring that the producer is not dropping buffered records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 10000)_	public void testAtLeastOnceProducer() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))__		Assert.assertEquals(3, producer.getPendingSize())___		_		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		_		producer.waitUntilFlushStarted()__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(2, producer.getPendingSize())___		producer.getPendingCallbacks().get(1).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(1, producer.getPendingSize())___		producer.getPendingCallbacks().get(2).onCompletion(null, null)__		Assert.assertEquals(0, producer.getPendingSize())___		_		snapshotThread.sync()___		testHarness.close()__	};test,ensuring,that,the,producer,is,not,dropping,buffered,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,10000,public,void,test,at,least,once,producer,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,assert,assert,equals,3,producer,get,pending,size,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,wait,until,flush,started,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,producer,get,pending,callbacks,get,0,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,2,producer,get,pending,size,producer,get,pending,callbacks,get,1,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,1,producer,get,pending,size,producer,get,pending,callbacks,get,2,on,completion,null,null,assert,assert,equals,0,producer,get,pending,size,snapshot,thread,sync,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 10000) 	public void testAtLeastOnceProducer() throws Throwable;1538998760;Test ensuring that the producer is not dropping buffered records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 10000)_	public void testAtLeastOnceProducer() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))__		Assert.assertEquals(3, producer.getPendingSize())___		_		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		_		producer.waitUntilFlushStarted()__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(2, producer.getPendingSize())___		producer.getPendingCallbacks().get(1).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(1, producer.getPendingSize())___		producer.getPendingCallbacks().get(2).onCompletion(null, null)__		Assert.assertEquals(0, producer.getPendingSize())___		_		snapshotThread.sync()___		testHarness.close()__	};test,ensuring,that,the,producer,is,not,dropping,buffered,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,10000,public,void,test,at,least,once,producer,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,assert,assert,equals,3,producer,get,pending,size,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,wait,until,flush,started,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,producer,get,pending,callbacks,get,0,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,2,producer,get,pending,size,producer,get,pending,callbacks,get,1,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,1,producer,get,pending,size,producer,get,pending,callbacks,get,2,on,completion,null,null,assert,assert,equals,0,producer,get,pending,size,snapshot,thread,sync,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable;1495923077;This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,_the snapshot method does indeed finishes without waiting for pending records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(false)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg"))___		_		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class))___		_		testHarness.snapshot(123L, 123L)___		testHarness.close()__	};this,test,is,meant,to,assure,that,test,at,least,once,producer,is,valid,by,testing,that,if,flushing,is,disabled,the,snapshot,method,does,indeed,finishes,without,waiting,for,pending,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,5000,public,void,test,does,not,wait,for,pending,records,if,flushing,disabled,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,false,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,verify,mock,producer,times,1,send,any,producer,record,class,any,callback,class,test,harness,snapshot,123l,123l,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable;1505994377;This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,_the snapshot method does indeed finishes without waiting for pending records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(false)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg"))___		_		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class))___		_		testHarness.snapshot(123L, 123L)___		testHarness.close()__	};this,test,is,meant,to,assure,that,test,at,least,once,producer,is,valid,by,testing,that,if,flushing,is,disabled,the,snapshot,method,does,indeed,finishes,without,waiting,for,pending,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,5000,public,void,test,does,not,wait,for,pending,records,if,flushing,disabled,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,false,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,verify,mock,producer,times,1,send,any,producer,record,class,any,callback,class,test,harness,snapshot,123l,123l,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable;1509723634;This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,_the snapshot method does indeed finishes without waiting for pending records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(false)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg"))___		_		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class))___		_		testHarness.snapshot(123L, 123L)___		testHarness.close()__	};this,test,is,meant,to,assure,that,test,at,least,once,producer,is,valid,by,testing,that,if,flushing,is,disabled,the,snapshot,method,does,indeed,finishes,without,waiting,for,pending,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,5000,public,void,test,does,not,wait,for,pending,records,if,flushing,disabled,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,false,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,verify,mock,producer,times,1,send,any,producer,record,class,any,callback,class,test,harness,snapshot,123l,123l,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable;1515177485;This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,_the snapshot method does indeed finishes without waiting for pending records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(false)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg"))___		_		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class))___		_		testHarness.snapshot(123L, 123L)___		testHarness.close()__	};this,test,is,meant,to,assure,that,test,at,least,once,producer,is,valid,by,testing,that,if,flushing,is,disabled,the,snapshot,method,does,indeed,finishes,without,waiting,for,pending,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,5000,public,void,test,does,not,wait,for,pending,records,if,flushing,disabled,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,false,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,verify,mock,producer,times,1,send,any,producer,record,class,any,callback,class,test,harness,snapshot,123l,123l,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable;1518770239;This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,_the snapshot method does indeed finishes without waiting for pending records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(false)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg"))___		_		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class))___		_		testHarness.snapshot(123L, 123L)___		testHarness.close()__	};this,test,is,meant,to,assure,that,test,at,least,once,producer,is,valid,by,testing,that,if,flushing,is,disabled,the,snapshot,method,does,indeed,finishes,without,waiting,for,pending,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,5000,public,void,test,does,not,wait,for,pending,records,if,flushing,disabled,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,false,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,verify,mock,producer,times,1,send,any,producer,record,class,any,callback,class,test,harness,snapshot,123l,123l,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable;1520440672;This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,_the snapshot method does indeed finishes without waiting for pending records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(false)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg"))___		_		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class))___		_		testHarness.snapshot(123L, 123L)___		testHarness.close()__	};this,test,is,meant,to,assure,that,test,at,least,once,producer,is,valid,by,testing,that,if,flushing,is,disabled,the,snapshot,method,does,indeed,finishes,without,waiting,for,pending,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,5000,public,void,test,does,not,wait,for,pending,records,if,flushing,disabled,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,false,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,verify,mock,producer,times,1,send,any,producer,record,class,any,callback,class,test,harness,snapshot,123l,123l,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout = 5000) 	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable;1538998760;This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,_the snapshot method does indeed finishes without waiting for pending records__we set a timeout because the test will not finish if the logic is broken.;@SuppressWarnings("unchecked")_	@Test(timeout = 5000)_	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(false)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg"))___		_		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class))___		_		testHarness.snapshot(123L, 123L)___		testHarness.close()__	};this,test,is,meant,to,assure,that,test,at,least,once,producer,is,valid,by,testing,that,if,flushing,is,disabled,the,snapshot,method,does,indeed,finishes,without,waiting,for,pending,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,5000,public,void,test,does,not,wait,for,pending,records,if,flushing,disabled,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,false,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,verify,mock,producer,times,1,send,any,producer,record,class,any,callback,class,test,harness,snapshot,123l,123l,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout=10000) 	public void testAtLeastOnceProducer() throws Throwable;1487783817;Test ensuring that the producer is not dropping buffered records__we set a timeout because the test will not finish if the logic is broken;@SuppressWarnings("unchecked")_	@Test(timeout=10000)_	public void testAtLeastOnceProducer() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))__		Assert.assertEquals(3, producer.getPendingSize())___		_		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		_		producer.waitUntilFlushStarted()__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(2, producer.getPendingSize())___		producer.getPendingCallbacks().get(1).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(1, producer.getPendingSize())___		producer.getPendingCallbacks().get(2).onCompletion(null, null)__		Assert.assertEquals(0, producer.getPendingSize())___		_		snapshotThread.sync()___		testHarness.close()__	};test,ensuring,that,the,producer,is,not,dropping,buffered,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,10000,public,void,test,at,least,once,producer,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,assert,assert,equals,3,producer,get,pending,size,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,wait,until,flush,started,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,producer,get,pending,callbacks,get,0,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,2,producer,get,pending,size,producer,get,pending,callbacks,get,1,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,1,producer,get,pending,size,producer,get,pending,callbacks,get,2,on,completion,null,null,assert,assert,equals,0,producer,get,pending,size,snapshot,thread,sync,test,harness,close
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout=10000) 	public void testAtLeastOnceProducer() throws Throwable;1495175928;Test ensuring that the producer is not dropping buffered records__we set a timeout because the test will not finish if the logic is broken;@SuppressWarnings("unchecked")_	@Test(timeout=10000)_	public void testAtLeastOnceProducer() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))__		Assert.assertEquals(3, producer.getPendingSize())___		_		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		_		producer.waitUntilFlushStarted()__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(2, producer.getPendingSize())___		producer.getPendingCallbacks().get(1).onCompletion(null, null)__		Assert.assertTrue("Snapshot returned before all records were flushed", snapshotThread.isAlive())__		Assert.assertEquals(1, producer.getPendingSize())___		producer.getPendingCallbacks().get(2).onCompletion(null, null)__		Assert.assertEquals(0, producer.getPendingSize())___		_		snapshotThread.sync()___		testHarness.close()__	};test,ensuring,that,the,producer,is,not,dropping,buffered,records,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken;suppress,warnings,unchecked,test,timeout,10000,public,void,test,at,least,once,producer,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,assert,assert,equals,3,producer,get,pending,size,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,wait,until,flush,started,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,producer,get,pending,callbacks,get,0,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,2,producer,get,pending,size,producer,get,pending,callbacks,get,1,on,completion,null,null,assert,assert,true,snapshot,returned,before,all,records,were,flushed,snapshot,thread,is,alive,assert,assert,equals,1,producer,get,pending,size,producer,get,pending,callbacks,get,2,on,completion,null,null,assert,assert,equals,0,producer,get,pending,size,snapshot,thread,sync,test,harness,close
FlinkKafkaProducerBaseTest -> @Test 	public void testKeyValueDeserializersSetIfMissing() throws Exception;1480685315;Tests that constructor defaults to key value serializers in config to byte array deserializers if not set;@Test_	public void testKeyValueDeserializersSetIfMissing() throws Exception {_		Properties props = new Properties()__		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:12345")__		_		new DummyFlinkKafkaProducer<>(props, null)___		assertTrue(props.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__	};tests,that,constructor,defaults,to,key,value,serializers,in,config,to,byte,array,deserializers,if,not,set;test,public,void,test,key,value,deserializers,set,if,missing,throws,exception,properties,props,new,properties,props,set,property,producer,config,localhost,12345,new,dummy,flink,kafka,producer,props,null,assert,true,props,contains,key,producer,config,assert,true,props,contains,key,producer,config,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name
FlinkKafkaProducerBaseTest -> @Test 	public void testKeyValueDeserializersSetIfMissing() throws Exception;1487783817;Tests that constructor defaults to key value serializers in config to byte array deserializers if not set;@Test_	public void testKeyValueDeserializersSetIfMissing() throws Exception {_		Properties props = new Properties()__		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:12345")__		_		new DummyFlinkKafkaProducer<>(props, null)___		assertTrue(props.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__	};tests,that,constructor,defaults,to,key,value,serializers,in,config,to,byte,array,deserializers,if,not,set;test,public,void,test,key,value,deserializers,set,if,missing,throws,exception,properties,props,new,properties,props,set,property,producer,config,localhost,12345,new,dummy,flink,kafka,producer,props,null,assert,true,props,contains,key,producer,config,assert,true,props,contains,key,producer,config,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name
FlinkKafkaProducerBaseTest -> @Test 	public void testKeyValueDeserializersSetIfMissing() throws Exception;1495175928;Tests that constructor defaults to key value serializers in config to byte array deserializers if not set;@Test_	public void testKeyValueDeserializersSetIfMissing() throws Exception {_		Properties props = new Properties()__		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:12345")__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		assertTrue(props.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__	};tests,that,constructor,defaults,to,key,value,serializers,in,config,to,byte,array,deserializers,if,not,set;test,public,void,test,key,value,deserializers,set,if,missing,throws,exception,properties,props,new,properties,props,set,property,producer,config,localhost,12345,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,assert,true,props,contains,key,producer,config,assert,true,props,contains,key,producer,config,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name
FlinkKafkaProducerBaseTest -> @Test 	public void testKeyValueDeserializersSetIfMissing() throws Exception;1495923077;Tests that constructor defaults to key value serializers in config to byte array deserializers if not set.;@Test_	public void testKeyValueDeserializersSetIfMissing() throws Exception {_		Properties props = new Properties()__		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:12345")__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		assertTrue(props.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__	};tests,that,constructor,defaults,to,key,value,serializers,in,config,to,byte,array,deserializers,if,not,set;test,public,void,test,key,value,deserializers,set,if,missing,throws,exception,properties,props,new,properties,props,set,property,producer,config,localhost,12345,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,assert,true,props,contains,key,producer,config,assert,true,props,contains,key,producer,config,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name
FlinkKafkaProducerBaseTest -> @Test 	public void testKeyValueDeserializersSetIfMissing() throws Exception;1505994377;Tests that constructor defaults to key value serializers in config to byte array deserializers if not set.;@Test_	public void testKeyValueDeserializersSetIfMissing() throws Exception {_		Properties props = new Properties()__		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:12345")__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		assertTrue(props.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__	};tests,that,constructor,defaults,to,key,value,serializers,in,config,to,byte,array,deserializers,if,not,set;test,public,void,test,key,value,deserializers,set,if,missing,throws,exception,properties,props,new,properties,props,set,property,producer,config,localhost,12345,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,assert,true,props,contains,key,producer,config,assert,true,props,contains,key,producer,config,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name
FlinkKafkaProducerBaseTest -> @Test 	public void testKeyValueDeserializersSetIfMissing() throws Exception;1509723634;Tests that constructor defaults to key value serializers in config to byte array deserializers if not set.;@Test_	public void testKeyValueDeserializersSetIfMissing() throws Exception {_		Properties props = new Properties()__		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:12345")__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		assertTrue(props.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__	};tests,that,constructor,defaults,to,key,value,serializers,in,config,to,byte,array,deserializers,if,not,set;test,public,void,test,key,value,deserializers,set,if,missing,throws,exception,properties,props,new,properties,props,set,property,producer,config,localhost,12345,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,assert,true,props,contains,key,producer,config,assert,true,props,contains,key,producer,config,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name
FlinkKafkaProducerBaseTest -> @Test 	public void testKeyValueDeserializersSetIfMissing() throws Exception;1515177485;Tests that constructor defaults to key value serializers in config to byte array deserializers if not set.;@Test_	public void testKeyValueDeserializersSetIfMissing() throws Exception {_		Properties props = new Properties()__		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:12345")__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		assertTrue(props.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__	};tests,that,constructor,defaults,to,key,value,serializers,in,config,to,byte,array,deserializers,if,not,set;test,public,void,test,key,value,deserializers,set,if,missing,throws,exception,properties,props,new,properties,props,set,property,producer,config,localhost,12345,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,assert,true,props,contains,key,producer,config,assert,true,props,contains,key,producer,config,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name
FlinkKafkaProducerBaseTest -> @Test 	public void testKeyValueDeserializersSetIfMissing() throws Exception;1518770239;Tests that constructor defaults to key value serializers in config to byte array deserializers if not set.;@Test_	public void testKeyValueDeserializersSetIfMissing() throws Exception {_		Properties props = new Properties()__		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:12345")__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		assertTrue(props.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getCanonicalName()))__	};tests,that,constructor,defaults,to,key,value,serializers,in,config,to,byte,array,deserializers,if,not,set;test,public,void,test,key,value,deserializers,set,if,missing,throws,exception,properties,props,new,properties,props,set,property,producer,config,localhost,12345,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,assert,true,props,contains,key,producer,config,assert,true,props,contains,key,producer,config,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,canonical,name
FlinkKafkaProducerBaseTest -> @Test 	public void testKeyValueDeserializersSetIfMissing() throws Exception;1520440672;Tests that constructor defaults to key value serializers in config to byte array deserializers if not set.;@Test_	public void testKeyValueDeserializersSetIfMissing() throws Exception {_		Properties props = new Properties()__		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:12345")__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		assertTrue(props.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getName()))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getName()))__	};tests,that,constructor,defaults,to,key,value,serializers,in,config,to,byte,array,deserializers,if,not,set;test,public,void,test,key,value,deserializers,set,if,missing,throws,exception,properties,props,new,properties,props,set,property,producer,config,localhost,12345,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,assert,true,props,contains,key,producer,config,assert,true,props,contains,key,producer,config,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,name,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,name
FlinkKafkaProducerBaseTest -> @Test 	public void testKeyValueDeserializersSetIfMissing() throws Exception;1538998760;Tests that constructor defaults to key value serializers in config to byte array deserializers if not set.;@Test_	public void testKeyValueDeserializersSetIfMissing() throws Exception {_		Properties props = new Properties()__		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:12345")__		_		new DummyFlinkKafkaProducer<>(props, new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)___		assertTrue(props.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getName()))__		assertTrue(props.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).equals(ByteArraySerializer.class.getName()))__	};tests,that,constructor,defaults,to,key,value,serializers,in,config,to,byte,array,deserializers,if,not,set;test,public,void,test,key,value,deserializers,set,if,missing,throws,exception,properties,props,new,properties,props,set,property,producer,config,localhost,12345,new,dummy,flink,kafka,producer,props,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,assert,true,props,contains,key,producer,config,assert,true,props,contains,key,producer,config,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,name,assert,true,props,get,property,producer,config,equals,byte,array,serializer,class,get,name
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout=5000) 	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable;1487783817;Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,_it should be rethrown_ we set a timeout because the test will not finish if the logic is broken.__Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds._The test for that is covered in testAtLeastOnceProducer.;@SuppressWarnings("unchecked")_	@Test(timeout=5000)_	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)___		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception("artificial async failure for 2nd message"))__		producer.getPendingCallbacks().get(2).onCompletion(null, null)___		try {_			snapshotThread.sync()__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async failure for 2nd message"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,async,exception,is,caught,for,one,of,the,flushed,requests,on,checkpoint,it,should,be,rethrown,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken,note,that,this,test,does,not,test,the,snapshot,method,is,blocked,correctly,when,there,are,pending,recorrds,the,test,for,that,is,covered,in,test,at,least,once,producer;suppress,warnings,unchecked,test,timeout,5000,public,void,test,async,error,rethrown,on,checkpoint,after,flush,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,producer,get,pending,callbacks,get,0,on,completion,null,null,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,get,pending,callbacks,get,1,on,completion,null,new,exception,artificial,async,failure,for,2nd,message,producer,get,pending,callbacks,get,2,on,completion,null,null,try,snapshot,thread,sync,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,failure,for,2nd,message,return,assert,fail
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test(timeout=5000) 	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable;1495175928;Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,_it should be rethrown_ we set a timeout because the test will not finish if the logic is broken.__Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds._The test for that is covered in testAtLeastOnceProducer.;@SuppressWarnings("unchecked")_	@Test(timeout=5000)_	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {_		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), null)__		producer.setFlushOnCheckpoint(true)___		final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer()___		final OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer))___		testHarness.open()___		testHarness.processElement(new StreamRecord<>("msg-1"))__		testHarness.processElement(new StreamRecord<>("msg-2"))__		testHarness.processElement(new StreamRecord<>("msg-3"))___		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class))___		_		producer.getPendingCallbacks().get(0).onCompletion(null, null)___		CheckedThread snapshotThread = new CheckedThread() {_			@Override_			public void go() throws Exception {_				_				testHarness.snapshot(123L, 123L)__			}_		}__		snapshotThread.start()___		_		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception("artificial async failure for 2nd message"))__		producer.getPendingCallbacks().get(2).onCompletion(null, null)___		try {_			snapshotThread.sync()__		} catch (Exception e) {_			_			Assert.assertTrue(e.getCause().getMessage().contains("artificial async failure for 2nd message"))___			_			return__		}__		Assert.fail()__	};test,ensuring,that,if,an,async,exception,is,caught,for,one,of,the,flushed,requests,on,checkpoint,it,should,be,rethrown,we,set,a,timeout,because,the,test,will,not,finish,if,the,logic,is,broken,note,that,this,test,does,not,test,the,snapshot,method,is,blocked,correctly,when,there,are,pending,recorrds,the,test,for,that,is,covered,in,test,at,least,once,producer;suppress,warnings,unchecked,test,timeout,5000,public,void,test,async,error,rethrown,on,checkpoint,after,flush,throws,throwable,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,null,producer,set,flush,on,checkpoint,true,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,final,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,producer,test,harness,open,test,harness,process,element,new,stream,record,msg,1,test,harness,process,element,new,stream,record,msg,2,test,harness,process,element,new,stream,record,msg,3,verify,mock,producer,times,3,send,any,producer,record,class,any,callback,class,producer,get,pending,callbacks,get,0,on,completion,null,null,checked,thread,snapshot,thread,new,checked,thread,override,public,void,go,throws,exception,test,harness,snapshot,123l,123l,snapshot,thread,start,producer,get,pending,callbacks,get,1,on,completion,null,new,exception,artificial,async,failure,for,2nd,message,producer,get,pending,callbacks,get,2,on,completion,null,null,try,snapshot,thread,sync,catch,exception,e,assert,assert,true,e,get,cause,get,message,contains,artificial,async,failure,for,2nd,message,return,assert,fail
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test 	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception;1495175928;Tests that partitions list is determinate and correctly provided to custom partitioner;@SuppressWarnings("unchecked")_	@Test_	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception {_		FlinkKafkaPartitioner<String> mockPartitioner = mock(FlinkKafkaPartitioner.class)___		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class)__		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0)__		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1)__		_		_		List<PartitionInfo> mockPartitionsList = new ArrayList<>(4)__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null))___		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), mockPartitioner)__		producer.setRuntimeContext(mockRuntimeContext)___		final KafkaProducer mockProducer = producer.getMockKafkaProducer()__		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList)__		when(mockProducer.metrics()).thenReturn(null)___		producer.open(new Configuration())__		verify(mockPartitioner, times(1)).open(0, 1)___		producer.invoke("foobar")__		verify(mockPartitioner, times(1)).partition(_			"foobar", null, "foobar".getBytes(), DummyFlinkKafkaProducer.DUMMY_TOPIC, new int[] {0, 1, 2, 3})__	};tests,that,partitions,list,is,determinate,and,correctly,provided,to,custom,partitioner;suppress,warnings,unchecked,test,public,void,test,partitioner,invoked,with,determinate,partition,list,throws,exception,flink,kafka,partitioner,string,mock,partitioner,mock,flink,kafka,partitioner,class,runtime,context,mock,runtime,context,mock,runtime,context,class,when,mock,runtime,context,get,index,of,this,subtask,then,return,0,when,mock,runtime,context,get,number,of,parallel,subtasks,then,return,1,list,partition,info,mock,partitions,list,new,array,list,4,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,3,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,1,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,0,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,2,null,null,null,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,mock,partitioner,producer,set,runtime,context,mock,runtime,context,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,when,mock,producer,partitions,for,any,string,then,return,mock,partitions,list,when,mock,producer,metrics,then,return,null,producer,open,new,configuration,verify,mock,partitioner,times,1,open,0,1,producer,invoke,foobar,verify,mock,partitioner,times,1,partition,foobar,null,foobar,get,bytes,dummy,flink,kafka,producer,new,int,0,1,2,3
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test 	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception;1495923077;Tests that partitions list is determinate and correctly provided to custom partitioner.;@SuppressWarnings("unchecked")_	@Test_	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception {_		FlinkKafkaPartitioner<String> mockPartitioner = mock(FlinkKafkaPartitioner.class)___		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class)__		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0)__		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1)___		_		List<PartitionInfo> mockPartitionsList = new ArrayList<>(4)__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null))___		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), mockPartitioner)__		producer.setRuntimeContext(mockRuntimeContext)___		final KafkaProducer mockProducer = producer.getMockKafkaProducer()__		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList)__		when(mockProducer.metrics()).thenReturn(null)___		producer.open(new Configuration())__		verify(mockPartitioner, times(1)).open(0, 1)___		producer.invoke("foobar")__		verify(mockPartitioner, times(1)).partition(_			"foobar", null, "foobar".getBytes(), DummyFlinkKafkaProducer.DUMMY_TOPIC, new int[] {0, 1, 2, 3})__	};tests,that,partitions,list,is,determinate,and,correctly,provided,to,custom,partitioner;suppress,warnings,unchecked,test,public,void,test,partitioner,invoked,with,determinate,partition,list,throws,exception,flink,kafka,partitioner,string,mock,partitioner,mock,flink,kafka,partitioner,class,runtime,context,mock,runtime,context,mock,runtime,context,class,when,mock,runtime,context,get,index,of,this,subtask,then,return,0,when,mock,runtime,context,get,number,of,parallel,subtasks,then,return,1,list,partition,info,mock,partitions,list,new,array,list,4,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,3,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,1,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,0,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,2,null,null,null,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,mock,partitioner,producer,set,runtime,context,mock,runtime,context,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,when,mock,producer,partitions,for,any,string,then,return,mock,partitions,list,when,mock,producer,metrics,then,return,null,producer,open,new,configuration,verify,mock,partitioner,times,1,open,0,1,producer,invoke,foobar,verify,mock,partitioner,times,1,partition,foobar,null,foobar,get,bytes,dummy,flink,kafka,producer,new,int,0,1,2,3
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test 	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception;1505994377;Tests that partitions list is determinate and correctly provided to custom partitioner.;@SuppressWarnings("unchecked")_	@Test_	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception {_		FlinkKafkaPartitioner<String> mockPartitioner = mock(FlinkKafkaPartitioner.class)___		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class)__		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0)__		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1)___		_		List<PartitionInfo> mockPartitionsList = new ArrayList<>(4)__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null))___		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), mockPartitioner)__		producer.setRuntimeContext(mockRuntimeContext)___		final KafkaProducer mockProducer = producer.getMockKafkaProducer()__		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList)__		when(mockProducer.metrics()).thenReturn(null)___		producer.open(new Configuration())__		verify(mockPartitioner, times(1)).open(0, 1)___		producer.invoke("foobar", SinkContextUtil.forTimestamp(0))__		verify(mockPartitioner, times(1)).partition(_			"foobar", null, "foobar".getBytes(), DummyFlinkKafkaProducer.DUMMY_TOPIC, new int[] {0, 1, 2, 3})__	};tests,that,partitions,list,is,determinate,and,correctly,provided,to,custom,partitioner;suppress,warnings,unchecked,test,public,void,test,partitioner,invoked,with,determinate,partition,list,throws,exception,flink,kafka,partitioner,string,mock,partitioner,mock,flink,kafka,partitioner,class,runtime,context,mock,runtime,context,mock,runtime,context,class,when,mock,runtime,context,get,index,of,this,subtask,then,return,0,when,mock,runtime,context,get,number,of,parallel,subtasks,then,return,1,list,partition,info,mock,partitions,list,new,array,list,4,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,3,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,1,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,0,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,2,null,null,null,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,mock,partitioner,producer,set,runtime,context,mock,runtime,context,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,when,mock,producer,partitions,for,any,string,then,return,mock,partitions,list,when,mock,producer,metrics,then,return,null,producer,open,new,configuration,verify,mock,partitioner,times,1,open,0,1,producer,invoke,foobar,sink,context,util,for,timestamp,0,verify,mock,partitioner,times,1,partition,foobar,null,foobar,get,bytes,dummy,flink,kafka,producer,new,int,0,1,2,3
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test 	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception;1509723634;Tests that partitions list is determinate and correctly provided to custom partitioner.;@SuppressWarnings("unchecked")_	@Test_	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception {_		FlinkKafkaPartitioner<String> mockPartitioner = mock(FlinkKafkaPartitioner.class)___		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class)__		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0)__		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1)___		_		List<PartitionInfo> mockPartitionsList = new ArrayList<>(4)__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null))___		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), mockPartitioner)__		producer.setRuntimeContext(mockRuntimeContext)___		final KafkaProducer mockProducer = producer.getMockKafkaProducer()__		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList)__		when(mockProducer.metrics()).thenReturn(null)___		producer.open(new Configuration())__		verify(mockPartitioner, times(1)).open(0, 1)___		producer.invoke("foobar", SinkContextUtil.forTimestamp(0))__		verify(mockPartitioner, times(1)).partition(_			"foobar", null, "foobar".getBytes(), DummyFlinkKafkaProducer.DUMMY_TOPIC, new int[] {0, 1, 2, 3})__	};tests,that,partitions,list,is,determinate,and,correctly,provided,to,custom,partitioner;suppress,warnings,unchecked,test,public,void,test,partitioner,invoked,with,determinate,partition,list,throws,exception,flink,kafka,partitioner,string,mock,partitioner,mock,flink,kafka,partitioner,class,runtime,context,mock,runtime,context,mock,runtime,context,class,when,mock,runtime,context,get,index,of,this,subtask,then,return,0,when,mock,runtime,context,get,number,of,parallel,subtasks,then,return,1,list,partition,info,mock,partitions,list,new,array,list,4,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,3,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,1,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,0,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,2,null,null,null,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,mock,partitioner,producer,set,runtime,context,mock,runtime,context,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,when,mock,producer,partitions,for,any,string,then,return,mock,partitions,list,when,mock,producer,metrics,then,return,null,producer,open,new,configuration,verify,mock,partitioner,times,1,open,0,1,producer,invoke,foobar,sink,context,util,for,timestamp,0,verify,mock,partitioner,times,1,partition,foobar,null,foobar,get,bytes,dummy,flink,kafka,producer,new,int,0,1,2,3
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test 	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception;1515177485;Tests that partitions list is determinate and correctly provided to custom partitioner.;@SuppressWarnings("unchecked")_	@Test_	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception {_		FlinkKafkaPartitioner<String> mockPartitioner = mock(FlinkKafkaPartitioner.class)___		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class)__		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0)__		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1)___		_		List<PartitionInfo> mockPartitionsList = new ArrayList<>(4)__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null))___		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), mockPartitioner)__		producer.setRuntimeContext(mockRuntimeContext)___		final KafkaProducer mockProducer = producer.getMockKafkaProducer()__		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList)__		when(mockProducer.metrics()).thenReturn(null)___		producer.open(new Configuration())__		verify(mockPartitioner, times(1)).open(0, 1)___		producer.invoke("foobar", SinkContextUtil.forTimestamp(0))__		verify(mockPartitioner, times(1)).partition(_			"foobar", null, "foobar".getBytes(), DummyFlinkKafkaProducer.DUMMY_TOPIC, new int[] {0, 1, 2, 3})__	};tests,that,partitions,list,is,determinate,and,correctly,provided,to,custom,partitioner;suppress,warnings,unchecked,test,public,void,test,partitioner,invoked,with,determinate,partition,list,throws,exception,flink,kafka,partitioner,string,mock,partitioner,mock,flink,kafka,partitioner,class,runtime,context,mock,runtime,context,mock,runtime,context,class,when,mock,runtime,context,get,index,of,this,subtask,then,return,0,when,mock,runtime,context,get,number,of,parallel,subtasks,then,return,1,list,partition,info,mock,partitions,list,new,array,list,4,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,3,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,1,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,0,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,2,null,null,null,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,mock,partitioner,producer,set,runtime,context,mock,runtime,context,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,when,mock,producer,partitions,for,any,string,then,return,mock,partitions,list,when,mock,producer,metrics,then,return,null,producer,open,new,configuration,verify,mock,partitioner,times,1,open,0,1,producer,invoke,foobar,sink,context,util,for,timestamp,0,verify,mock,partitioner,times,1,partition,foobar,null,foobar,get,bytes,dummy,flink,kafka,producer,new,int,0,1,2,3
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test 	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception;1518770239;Tests that partitions list is determinate and correctly provided to custom partitioner.;@SuppressWarnings("unchecked")_	@Test_	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception {_		FlinkKafkaPartitioner<String> mockPartitioner = mock(FlinkKafkaPartitioner.class)___		RuntimeContext mockRuntimeContext = mock(StreamingRuntimeContext.class)__		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0)__		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1)___		_		List<PartitionInfo> mockPartitionsList = new ArrayList<>(4)__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null))___		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), mockPartitioner)__		producer.setRuntimeContext(mockRuntimeContext)___		final KafkaProducer mockProducer = producer.getMockKafkaProducer()__		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList)__		when(mockProducer.metrics()).thenReturn(null)___		producer.open(new Configuration())__		verify(mockPartitioner, times(1)).open(0, 1)___		producer.invoke("foobar", SinkContextUtil.forTimestamp(0))__		verify(mockPartitioner, times(1)).partition(_			"foobar", null, "foobar".getBytes(), DummyFlinkKafkaProducer.DUMMY_TOPIC, new int[] {0, 1, 2, 3})__	};tests,that,partitions,list,is,determinate,and,correctly,provided,to,custom,partitioner;suppress,warnings,unchecked,test,public,void,test,partitioner,invoked,with,determinate,partition,list,throws,exception,flink,kafka,partitioner,string,mock,partitioner,mock,flink,kafka,partitioner,class,runtime,context,mock,runtime,context,mock,streaming,runtime,context,class,when,mock,runtime,context,get,index,of,this,subtask,then,return,0,when,mock,runtime,context,get,number,of,parallel,subtasks,then,return,1,list,partition,info,mock,partitions,list,new,array,list,4,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,3,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,1,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,0,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,2,null,null,null,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,mock,partitioner,producer,set,runtime,context,mock,runtime,context,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,when,mock,producer,partitions,for,any,string,then,return,mock,partitions,list,when,mock,producer,metrics,then,return,null,producer,open,new,configuration,verify,mock,partitioner,times,1,open,0,1,producer,invoke,foobar,sink,context,util,for,timestamp,0,verify,mock,partitioner,times,1,partition,foobar,null,foobar,get,bytes,dummy,flink,kafka,producer,new,int,0,1,2,3
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test 	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception;1520440672;Tests that partitions list is determinate and correctly provided to custom partitioner.;@SuppressWarnings("unchecked")_	@Test_	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception {_		FlinkKafkaPartitioner<String> mockPartitioner = mock(FlinkKafkaPartitioner.class)___		RuntimeContext mockRuntimeContext = mock(StreamingRuntimeContext.class)__		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0)__		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1)___		_		List<PartitionInfo> mockPartitionsList = new ArrayList<>(4)__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null))___		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), mockPartitioner)__		producer.setRuntimeContext(mockRuntimeContext)___		final KafkaProducer mockProducer = producer.getMockKafkaProducer()__		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList)__		when(mockProducer.metrics()).thenReturn(null)___		producer.open(new Configuration())__		verify(mockPartitioner, times(1)).open(0, 1)___		producer.invoke("foobar", SinkContextUtil.forTimestamp(0))__		verify(mockPartitioner, times(1)).partition(_			"foobar", null, "foobar".getBytes(), DummyFlinkKafkaProducer.DUMMY_TOPIC, new int[] {0, 1, 2, 3})__	};tests,that,partitions,list,is,determinate,and,correctly,provided,to,custom,partitioner;suppress,warnings,unchecked,test,public,void,test,partitioner,invoked,with,determinate,partition,list,throws,exception,flink,kafka,partitioner,string,mock,partitioner,mock,flink,kafka,partitioner,class,runtime,context,mock,runtime,context,mock,streaming,runtime,context,class,when,mock,runtime,context,get,index,of,this,subtask,then,return,0,when,mock,runtime,context,get,number,of,parallel,subtasks,then,return,1,list,partition,info,mock,partitions,list,new,array,list,4,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,3,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,1,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,0,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,2,null,null,null,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,mock,partitioner,producer,set,runtime,context,mock,runtime,context,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,when,mock,producer,partitions,for,any,string,then,return,mock,partitions,list,when,mock,producer,metrics,then,return,null,producer,open,new,configuration,verify,mock,partitioner,times,1,open,0,1,producer,invoke,foobar,sink,context,util,for,timestamp,0,verify,mock,partitioner,times,1,partition,foobar,null,foobar,get,bytes,dummy,flink,kafka,producer,new,int,0,1,2,3
FlinkKafkaProducerBaseTest -> @SuppressWarnings("unchecked") 	@Test 	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception;1538998760;Tests that partitions list is determinate and correctly provided to custom partitioner.;@SuppressWarnings("unchecked")_	@Test_	public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception {_		FlinkKafkaPartitioner<String> mockPartitioner = mock(FlinkKafkaPartitioner.class)___		RuntimeContext mockRuntimeContext = mock(StreamingRuntimeContext.class)__		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0)__		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1)___		_		List<PartitionInfo> mockPartitionsList = new ArrayList<>(4)__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null))__		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null))___		final DummyFlinkKafkaProducer<String> producer = new DummyFlinkKafkaProducer<>(_			FakeStandardProducerConfig.get(), new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()), mockPartitioner)__		producer.setRuntimeContext(mockRuntimeContext)___		final KafkaProducer mockProducer = producer.getMockKafkaProducer()__		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList)__		when(mockProducer.metrics()).thenReturn(null)___		producer.open(new Configuration())__		verify(mockPartitioner, times(1)).open(0, 1)___		producer.invoke("foobar", SinkContextUtil.forTimestamp(0))__		verify(mockPartitioner, times(1)).partition(_			"foobar", null, "foobar".getBytes(), DummyFlinkKafkaProducer.DUMMY_TOPIC, new int[] {0, 1, 2, 3})__	};tests,that,partitions,list,is,determinate,and,correctly,provided,to,custom,partitioner;suppress,warnings,unchecked,test,public,void,test,partitioner,invoked,with,determinate,partition,list,throws,exception,flink,kafka,partitioner,string,mock,partitioner,mock,flink,kafka,partitioner,class,runtime,context,mock,runtime,context,mock,streaming,runtime,context,class,when,mock,runtime,context,get,index,of,this,subtask,then,return,0,when,mock,runtime,context,get,number,of,parallel,subtasks,then,return,1,list,partition,info,mock,partitions,list,new,array,list,4,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,3,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,1,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,0,null,null,null,mock,partitions,list,add,new,partition,info,dummy,flink,kafka,producer,2,null,null,null,final,dummy,flink,kafka,producer,string,producer,new,dummy,flink,kafka,producer,fake,standard,producer,config,get,new,keyed,serialization,schema,wrapper,new,simple,string,schema,mock,partitioner,producer,set,runtime,context,mock,runtime,context,final,kafka,producer,mock,producer,producer,get,mock,kafka,producer,when,mock,producer,partitions,for,any,string,then,return,mock,partitions,list,when,mock,producer,metrics,then,return,null,producer,open,new,configuration,verify,mock,partitioner,times,1,open,0,1,producer,invoke,foobar,sink,context,util,for,timestamp,0,verify,mock,partitioner,times,1,partition,foobar,null,foobar,get,bytes,dummy,flink,kafka,producer,new,int,0,1,2,3
